Title,Summary,Authors,Published,Updated,PDF_URL,Primary_Category,Categories,text
Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams,"Multi-dimensional data streams, prevalent in applications like IoT, financial
markets, and real-time analytics, pose significant challenges due to their high
velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding
window techniques are critical for processing such streams, but fixed-size
windows struggle to adapt to dynamic changes like concept drift or bursty
patterns. This paper proposes a novel reinforcement learning (RL)-based
approach to dynamically optimize sliding window sizes for multi-dimensional
data streams. By formulating window size selection as an RL problem, we enable
an agent to learn an adaptive policy based on stream characteristics, such as
variance, correlations, and temporal trends. Our method, RL-Window, leverages a
Dueling Deep Q-Network (DQN) with prioritized experience replay to handle
non-stationarity and high-dimensionality. Evaluations on benchmark datasets
(UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms
state-of-the-art methods like ADWIN and CNN-Adaptive in classification
accuracy, drift robustness, and computational efficiency. Additional
qualitative analyses, extended metrics (e.g., energy efficiency, latency), and
a comprehensive dataset characterization further highlight its adaptability and
stability, making it suitable for real-time applications.","['Abolfazl Zarghani', 'Sadegh Abedi']",2025-07-09 14:40:35+00:00,2025-07-09 14:40:35+00:00,http://arxiv.org/pdf/2507.06901v1,cs.LG,['cs.LG'],"designing adaptive algorithms based on reinforcement learning for dynamic optimization of sliding window size in multi-dimensional data streams multi-dimensional data streams, prevalent in applications like iot, financial
markets, and real-time analytics, pose significant challenges due to their high
velocity, unbounded nature, and complex inter-dimensional dependencies. sliding
window techniques are critical for processing such streams, but fixed-size
windows struggle to adapt to dynamic changes like concept drift or bursty
patterns. this paper proposes a novel reinforcement learning (rl)-based
approach to dynamically optimize sliding window sizes for multi-dimensional
data streams. by formulating window size selection as an rl problem, we enable
an agent to learn an adaptive policy based on stream characteristics, such as
variance, correlations, and temporal trends. our method, rl-window, leverages a
dueling deep q-network (dqn) with prioritized experience replay to handle
non-stationarity and high-dimensionality. evaluations on benchmark datasets
(uci har, pamap2, yahoo! finance stream) demonstrate that rl-window outperforms
state-of-the-art methods like adwin and cnn-adaptive in classification
accuracy, drift robustness, and computational efficiency. additional
qualitative analyses, extended metrics (e.g., energy efficiency, latency), and
a comprehensive dataset characterization further highlight its adaptability and
stability, making it suitable for real-time applications."
