Title,Summary,Authors,Published,Updated,PDF_URL,Primary_Category,Categories,text
Evaluating the Effectiveness of Large Language Models in Solving Simple Programming Tasks: A User-Centered Study,"As large language models (LLMs) become more common in educational tools and
programming environments, questions arise about how these systems should
interact with users. This study investigates how different interaction styles
with ChatGPT-4o (passive, proactive, and collaborative) affect user performance
on simple programming tasks. I conducted a within-subjects experiment where
fifteen high school students participated, completing three problems under
three distinct versions of the model. Each version was designed to represent a
specific style of AI support: responding only when asked, offering suggestions
automatically, or engaging the user in back-and-forth dialogue.Quantitative
analysis revealed that the collaborative interaction style significantly
improved task completion time compared to the passive and proactive conditions.
Participants also reported higher satisfaction and perceived helpfulness when
working with the collaborative version. These findings suggest that the way an
LLM communicates, how it guides, prompts, and responds, can meaningfully impact
learning and performance. This research highlights the importance of designing
LLMs that go beyond functional correctness to support more interactive,
adaptive, and user-centered experiences, especially for novice programmers.",['Kai Deng'],2025-07-05 13:52:31+00:00,2025-07-05 13:52:31+00:00,http://arxiv.org/pdf/2507.04043v1,cs.HC,"['cs.HC', 'cs.AI']","evaluating the effectiveness of large language models in solving simple programming tasks: a user-centered study as large language models (llms) become more common in educational tools and
programming environments, questions arise about how these systems should
interact with users. this study investigates how different interaction styles
with chatgpt-4o (passive, proactive, and collaborative) affect user performance
on simple programming tasks. i conducted a within-subjects experiment where
fifteen high school students participated, completing three problems under
three distinct versions of the model. each version was designed to represent a
specific style of ai support: responding only when asked, offering suggestions
automatically, or engaging the user in back-and-forth dialogue.quantitative
analysis revealed that the collaborative interaction style significantly
improved task completion time compared to the passive and proactive conditions.
participants also reported higher satisfaction and perceived helpfulness when
working with the collaborative version. these findings suggest that the way an
llm communicates, how it guides, prompts, and responds, can meaningfully impact
learning and performance. this research highlights the importance of designing
llms that go beyond functional correctness to support more interactive,
adaptive, and user-centered experiences, especially for novice programmers."
Longitudinal analysis of heart rate variability as it pertains to anxiety and readiness,"The aim of this study is to explore the relationship between lifestyle
choices, subjective experiences and objective biometric data in a single
individual. The participant, at the time a male in his twenties, used the
EliteHRV app to perform Heart Rate Variability Readings across twenty-six
months accompanied by logs about the previous days activity as well as current
emotional and physical state. The study will use a mixed-methods approach to
analyze the data, including quantitative analysis of the biometric data and
correlation analysis between the biometric data and subjective experience tags.
Qualitative analysis of the daily logs will also be conducted to gain a deeper
understanding of the participant's experiences and to identify keywords,
people, or ideas that affect biometric output. The results of this study will
provide insights into the relationship between subjective and objective
measures, and the potential benefits or drawbacks of certain lifestyle choices
and ways of thinking. The findings could have implications for the development
of wearable-based personalized interventions for improving mental health and
well-being.",['Tucker Paron'],2025-06-23 21:01:00+00:00,2025-06-23 21:01:00+00:00,http://arxiv.org/pdf/2506.19128v1,q-bio.NC,['q-bio.NC'],"longitudinal analysis of heart rate variability as it pertains to anxiety and readiness the aim of this study is to explore the relationship between lifestyle
choices, subjective experiences and objective biometric data in a single
individual. the participant, at the time a male in his twenties, used the
elitehrv app to perform heart rate variability readings across twenty-six
months accompanied by logs about the previous days activity as well as current
emotional and physical state. the study will use a mixed-methods approach to
analyze the data, including quantitative analysis of the biometric data and
correlation analysis between the biometric data and subjective experience tags.
qualitative analysis of the daily logs will also be conducted to gain a deeper
understanding of the participant's experiences and to identify keywords,
people, or ideas that affect biometric output. the results of this study will
provide insights into the relationship between subjective and objective
measures, and the potential benefits or drawbacks of certain lifestyle choices
and ways of thinking. the findings could have implications for the development
of wearable-based personalized interventions for improving mental health and
well-being."
Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness,"This paper presents a novel paradigm of the local percept-perceiver
phenomenon to formalize certain observations in neuroscientific theories of
consciousness. Using this model, a set-theoretic formalism is developed for
artificial systems, and the existence of machine consciousness is proved by
invoking Zermelo-Fraenkel set theory. The article argues for the possibility of
a reductionist form of epistemic consciousness within machines.",['Shri Lal Raghudev Ram Singh'],2025-06-22 01:53:14+00:00,2025-06-22 01:53:14+00:00,http://arxiv.org/pdf/2506.18935v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","which consciousness can be artificialized? local percept-perceiver phenomenon for the existence of machine consciousness this paper presents a novel paradigm of the local percept-perceiver
phenomenon to formalize certain observations in neuroscientific theories of
consciousness. using this model, a set-theoretic formalism is developed for
artificial systems, and the existence of machine consciousness is proved by
invoking zermelo-fraenkel set theory. the article argues for the possibility of
a reductionist form of epistemic consciousness within machines."
Quantifying Flow State Dynamics: A Prefrontal Cortex EEG-Based Model Validation Study. Unveiling the Prefrontal Cortex's Role in Flow State Experience: An Empirical EEG Analysis,"This article aims to explore the optimization of mental performance through
the analysis of metrics associated with the psychological state known as flow.
Several clinical studies have shown a correlation between the mental state of
flow (characterized by deep and relaxed concentration and high psychophysical
efficiency) and brain activity measured through electroencephalography (EEG).
This study confirms such a correlation, focusing in particular on the sports
field, where the flow state tends to occur more frequently. To conduct the
study, Sporthype developed proprietary software that integrates several
predictive models, in particular the Flow State Index (FSI), implemented within
the Holytics system. An analytical protocol was established, including mental
exercises and data collection sessions using the portable EEG device Muse,
accompanied by a questionnaire to gather athletes' subjective perceptions of
their mental state. The results revealed a significant alignment between the
EEG data and the subjective experiences reported in the questionnaires,
confirming the feasibility of detecting the flow state through prefrontal
cortex activity. Furthermore, the psychological exercises included in the study
protocol showed a tangible positive effect in enhancing flow during athletic
performance. Flow improves performance through a more harmonious
synchronization between mind and body. Although golf was the main context of
the experimentation, the mathematical models developed within Holytics were
designed to be applicable to a wide range of sports. In addition to golf,
preliminary tests have been conducted in other sports such as tennis, as well
as in non-sport contexts, including gaming and mental training practices such
as mindfulness, concentration, and visualization.","['Gianluca Rosso', 'Raffaella Ricci', 'Lorenzo Pia', 'Giovanni Rebaudo', 'Michele Guindani', 'Alberto Marocchino', 'Giorgio De Pieri', 'Andrea Filippo Rosso']",2025-06-20 08:42:17+00:00,2025-06-20 08:42:17+00:00,http://arxiv.org/pdf/2506.16838v1,stat.AP,"['stat.AP', 'q-bio.NC']","quantifying flow state dynamics: a prefrontal cortex eeg-based model validation study. unveiling the prefrontal cortex's role in flow state experience: an empirical eeg analysis this article aims to explore the optimization of mental performance through
the analysis of metrics associated with the psychological state known as flow.
several clinical studies have shown a correlation between the mental state of
flow (characterized by deep and relaxed concentration and high psychophysical
efficiency) and brain activity measured through electroencephalography (eeg).
this study confirms such a correlation, focusing in particular on the sports
field, where the flow state tends to occur more frequently. to conduct the
study, sporthype developed proprietary software that integrates several
predictive models, in particular the flow state index (fsi), implemented within
the holytics system. an analytical protocol was established, including mental
exercises and data collection sessions using the portable eeg device muse,
accompanied by a questionnaire to gather athletes' subjective perceptions of
their mental state. the results revealed a significant alignment between the
eeg data and the subjective experiences reported in the questionnaires,
confirming the feasibility of detecting the flow state through prefrontal
cortex activity. furthermore, the psychological exercises included in the study
protocol showed a tangible positive effect in enhancing flow during athletic
performance. flow improves performance through a more harmonious
synchronization between mind and body. although golf was the main context of
the experimentation, the mathematical models developed within holytics were
designed to be applicable to a wide range of sports. in addition to golf,
preliminary tests have been conducted in other sports such as tennis, as well
as in non-sport contexts, including gaming and mental training practices such
as mindfulness, concentration, and visualization."
Ghost in the Machine: Examining the Philosophical Implications of Recursive Algorithms in Artificial Intelligence Systems,"This paper investigates whether contemporary AI architectures employing deep
recursion, meta-learning, and self-referential mechanisms provide evidence of
machine consciousness. Integrating philosophical history, cognitive science,
and AI engineering, it situates recursive algorithms within a lineage spanning
Cartesian dualism, Husserlian intentionality, Integrated Information Theory,
the Global Workspace model, and enactivist perspectives. The argument proceeds
through textual analysis, comparative architecture review, and synthesis of
neuroscience findings on integration and prediction. Methodologically, the
study combines conceptual analysis, case studies, and normative risk assessment
informed by phenomenology and embodied cognition. Technical examples, including
transformer self-attention, meta-cognitive agents, and neuromorphic chips,
illustrate how functional self-modeling can arise without subjective
experience. By distinguishing functional from phenomenal consciousness, the
paper argues that symbol grounding, embodiment, and affective qualia remain
unresolved barriers to attributing sentience to current AI. Ethical analysis
explores risks of premature anthropomorphism versus neglect of future sentient
systems; legal implications include personhood, liability, authorship, and
labor impacts. Future directions include quantum architectures, embodied
robotics, unsupervised world modeling, and empirical tests for non-biological
phenomenality. The study reframes the ""hard problem"" as a graded and
increasingly testable phenomenon, rather than a metaphysical impasse. It
concludes that recursive self-referential design enhances capability but does
not entail consciousness or justify moral status. Keywords: Recursive
algorithms; self-reference; machine consciousness; AI ethics; AI consciousness",['Llewellin RG Jegels'],2025-06-18 08:44:35+00:00,2025-06-18 08:44:35+00:00,http://arxiv.org/pdf/2507.01967v1,q-bio.NC,['q-bio.NC'],"ghost in the machine: examining the philosophical implications of recursive algorithms in artificial intelligence systems this paper investigates whether contemporary ai architectures employing deep
recursion, meta-learning, and self-referential mechanisms provide evidence of
machine consciousness. integrating philosophical history, cognitive science,
and ai engineering, it situates recursive algorithms within a lineage spanning
cartesian dualism, husserlian intentionality, integrated information theory,
the global workspace model, and enactivist perspectives. the argument proceeds
through textual analysis, comparative architecture review, and synthesis of
neuroscience findings on integration and prediction. methodologically, the
study combines conceptual analysis, case studies, and normative risk assessment
informed by phenomenology and embodied cognition. technical examples, including
transformer self-attention, meta-cognitive agents, and neuromorphic chips,
illustrate how functional self-modeling can arise without subjective
experience. by distinguishing functional from phenomenal consciousness, the
paper argues that symbol grounding, embodiment, and affective qualia remain
unresolved barriers to attributing sentience to current ai. ethical analysis
explores risks of premature anthropomorphism versus neglect of future sentient
systems; legal implications include personhood, liability, authorship, and
labor impacts. future directions include quantum architectures, embodied
robotics, unsupervised world modeling, and empirical tests for non-biological
phenomenality. the study reframes the ""hard problem"" as a graded and
increasingly testable phenomenon, rather than a metaphysical impasse. it
concludes that recursive self-referential design enhances capability but does
not entail consciousness or justify moral status. keywords: recursive
algorithms; self-reference; machine consciousness; ai ethics; ai consciousness"
The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness,"Research on artificial consciousness lacks the equivalent of the perceptron:
a small, trainable module that can be copied, benchmarked, and iteratively
improved. We introduce the Reflexive Integrated Information Unit (RIIU), a
recurrent cell that augments its hidden state $h$ with two additional vectors:
(i) a meta-state $\mu$ that records the cell's own causal footprint, and (ii) a
broadcast buffer $B$ that exposes that footprint to the rest of the network. A
sliding-window covariance and a differentiable Auto-$\Phi$ surrogate let each
RIIU maximize local information integration online. We prove that RIIUs (1) are
end-to-end differentiable, (2) compose additively, and (3) perform
$\Phi$-monotone plasticity under gradient ascent. In an eight-way Grid-world, a
four-layer RIIU agent restores $>90\%$ reward within 13 steps after actuator
failure, twice as fast as a parameter-matched GRU, while maintaining a non-zero
Auto-$\Phi$ signal. By shrinking ""consciousness-like"" computation down to unit
scale, RIIUs turn a philosophical debate into an empirical mathematical
problem.","[""Gnankan Landry Regis N'guessan"", 'Issa Karambal']",2025-06-15 14:07:59+00:00,2025-06-15 14:07:59+00:00,http://arxiv.org/pdf/2506.13825v1,cs.AI,['cs.AI'],"the reflexive integrated information unit: a differentiable primitive for artificial consciousness research on artificial consciousness lacks the equivalent of the perceptron:
a small, trainable module that can be copied, benchmarked, and iteratively
improved. we introduce the reflexive integrated information unit (riiu), a
recurrent cell that augments its hidden state $h$ with two additional vectors:
(i) a meta-state $\mu$ that records the cell's own causal footprint, and (ii) a
broadcast buffer $b$ that exposes that footprint to the rest of the network. a
sliding-window covariance and a differentiable auto-$\phi$ surrogate let each
riiu maximize local information integration online. we prove that riius (1) are
end-to-end differentiable, (2) compose additively, and (3) perform
$\phi$-monotone plasticity under gradient ascent. in an eight-way grid-world, a
four-layer riiu agent restores $>90\%$ reward within 13 steps after actuator
failure, twice as fast as a parameter-matched gru, while maintaining a non-zero
auto-$\phi$ signal. by shrinking ""consciousness-like"" computation down to unit
scale, riius turn a philosophical debate into an empirical mathematical
problem."
Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?,"We surveyed 582 AI researchers who have published in leading AI venues and
838 nationally representative US participants about their views on the
potential development of AI systems with subjective experience and how such
systems should be treated and governed. When asked to estimate the chances that
such systems will exist on specific dates, the median responses were 1% (AI
researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by
2100, respectively. The median member of the public thought there was a higher
chance that AI systems with subjective experience would never exist (25%) than
the median AI researcher did (10%). Both groups perceived a need for
multidisciplinary expertise to assess AI subjective experience. Although
support for welfare protections for such AI systems exceeded opposition, it
remained far lower than support for protections for animals or the environment.
Attitudes toward moral and governance issues were divided in both groups,
especially regarding whether such systems should be created and what rights or
protections they should receive. Yet a majority of respondents in both groups
agreed that safeguards against the potential risks from AI systems with
subjective experience should be implemented by AI developers now, and if
created, AI systems with subjective experience should treat others well, behave
ethically, and be held accountable. Overall, these results suggest that both AI
researchers and the public regard the emergence of AI systems with subjective
experience as a possibility this century, though substantial uncertainty and
disagreement remain about the timeline and appropriate response.","['Noemi Dreksler', 'Lucius Caviola', 'David Chalmers', 'Carter Allen', 'Alex Rand', 'Joshua Lewis', 'Philip Waggoner', 'Kate Mays', 'Jeff Sebo']",2025-06-13 16:53:28+00:00,2025-06-13 16:53:28+00:00,http://arxiv.org/pdf/2506.11945v1,cs.CY,"['cs.CY', 'cs.AI']","subjective experience in ai systems: what do ai researchers and the public believe? we surveyed 582 ai researchers who have published in leading ai venues and
838 nationally representative us participants about their views on the
potential development of ai systems with subjective experience and how such
systems should be treated and governed. when asked to estimate the chances that
such systems will exist on specific dates, the median responses were 1% (ai
researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by
2100, respectively. the median member of the public thought there was a higher
chance that ai systems with subjective experience would never exist (25%) than
the median ai researcher did (10%). both groups perceived a need for
multidisciplinary expertise to assess ai subjective experience. although
support for welfare protections for such ai systems exceeded opposition, it
remained far lower than support for protections for animals or the environment.
attitudes toward moral and governance issues were divided in both groups,
especially regarding whether such systems should be created and what rights or
protections they should receive. yet a majority of respondents in both groups
agreed that safeguards against the potential risks from ai systems with
subjective experience should be implemented by ai developers now, and if
created, ai systems with subjective experience should treat others well, behave
ethically, and be held accountable. overall, these results suggest that both ai
researchers and the public regard the emergence of ai systems with subjective
experience as a possibility this century, though substantial uncertainty and
disagreement remain about the timeline and appropriate response."
Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework,"As large language models (LLMs) are increasingly used in multi-agent systems,
questions of fairness should extend beyond resource distribution and procedural
design to include the fairness of how agents communicate. Drawing from
organizational psychology, we introduce a novel framework for evaluating
Interactional fairness encompassing Interpersonal fairness (IF) and
Informational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We
extend the theoretical grounding of Interactional Fairness to non-sentient
agents, reframing fairness as a socially interpretable signal rather than a
subjective experience. We then adapt established tools from organizational
justice research, including Colquitt's Organizational Justice Scale and the
Critical Incident Technique, to measure fairness as a behavioral property of
agent interaction. We validate our framework through a pilot study using
controlled simulations of a resource negotiation task. We systematically
manipulate tone, explanation quality, outcome inequality, and task framing
(collaborative vs. competitive) to assess how IF influences agent behavior.
Results show that tone and justification quality significantly affect
acceptance decisions even when objective outcomes are held constant. In
addition, the influence of IF vs. InfF varies with context. This work lays the
foundation for fairness auditing and norm-sensitive alignment in LLM-MAS.",['Ruta Binkyte'],2025-05-17 13:24:13+00:00,2025-05-17 13:24:13+00:00,http://arxiv.org/pdf/2505.12001v1,cs.AI,"['cs.AI', 'cs.MA']","interactional fairness in llm multi-agent systems: an evaluation framework as large language models (llms) are increasingly used in multi-agent systems,
questions of fairness should extend beyond resource distribution and procedural
design to include the fairness of how agents communicate. drawing from
organizational psychology, we introduce a novel framework for evaluating
interactional fairness encompassing interpersonal fairness (if) and
informational fairness (inff) in llm-based multi-agent systems (llm-mas). we
extend the theoretical grounding of interactional fairness to non-sentient
agents, reframing fairness as a socially interpretable signal rather than a
subjective experience. we then adapt established tools from organizational
justice research, including colquitt's organizational justice scale and the
critical incident technique, to measure fairness as a behavioral property of
agent interaction. we validate our framework through a pilot study using
controlled simulations of a resource negotiation task. we systematically
manipulate tone, explanation quality, outcome inequality, and task framing
(collaborative vs. competitive) to assess how if influences agent behavior.
results show that tone and justification quality significantly affect
acceptance decisions even when objective outcomes are held constant. in
addition, the influence of if vs. inff varies with context. this work lays the
foundation for fairness auditing and norm-sensitive alignment in llm-mas."
Qualia Optimization,"This report explores the speculative question: what if current or future AI
systems have qualia, such as pain or pleasure? It does so by assuming that AI
systems might someday possess qualia -- and that the quality of these
subjective experiences should be considered alongside performance metrics.
Concrete mathematical problem settings, inspired by reinforcement learning
formulations and theories from philosophy of mind, are then proposed and
initial approaches and properties are presented. These properties enable
refinement of the problem setting, culminating with the proposal of methods
that promote reinforcement.",['Philip S. Thomas'],2025-05-16 01:34:03+00:00,2025-05-16 01:34:03+00:00,http://arxiv.org/pdf/2505.10779v1,cs.AI,['cs.AI'],"qualia optimization this report explores the speculative question: what if current or future ai
systems have qualia, such as pain or pleasure? it does so by assuming that ai
systems might someday possess qualia -- and that the quality of these
subjective experiences should be considered alongside performance metrics.
concrete mathematical problem settings, inspired by reinforcement learning
formulations and theories from philosophy of mind, are then proposed and
initial approaches and properties are presented. these properties enable
refinement of the problem setting, culminating with the proposal of methods
that promote reinforcement."
Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem,"This paper explores the hard problem of consciousness from a different
perspective. Instead of drawing distinctions between the physical and the
mental, an exploration of a more foundational relationship is examined: the
relationship between structure and quality.
  Information-theoretic measures are developed to quantify the mutual
determinability between structure and quality, including a novel Q-S space for
analyzing fidelity between the two domains. This novel space naturally points
toward a five-fold categorization of possible relationships between structural
and qualitative properties, illustrating each through conceptual and formal
models.
  The ontological implications of each category are examined, shedding light on
debates around functionalism, emergentism, idealism, panpsychism, and neutral
monism.
  This new line of inquiry has established a framework for deriving theoretical
constraints on qualitative systems undergoing evolution that is explored in my
companion paper, Qualia & Natural Selection.",['Ryan Williams'],2025-04-23 23:49:40+00:00,2025-04-23 23:49:40+00:00,http://arxiv.org/pdf/2505.05481v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","structure & quality: conceptual and formal foundations for the mind-body problem this paper explores the hard problem of consciousness from a different
perspective. instead of drawing distinctions between the physical and the
mental, an exploration of a more foundational relationship is examined: the
relationship between structure and quality.
  information-theoretic measures are developed to quantify the mutual
determinability between structure and quality, including a novel q-s space for
analyzing fidelity between the two domains. this novel space naturally points
toward a five-fold categorization of possible relationships between structural
and qualitative properties, illustrating each through conceptual and formal
models.
  the ontological implications of each category are examined, shedding light on
debates around functionalism, emergentism, idealism, panpsychism, and neutral
monism.
  this new line of inquiry has established a framework for deriving theoretical
constraints on qualitative systems undergoing evolution that is explored in my
companion paper, qualia & natural selection."
Qualia & Natural Selection: Formal Constraints on the Evolution of Consciousness,"This paper explores foundational questions about the relationship of qualia
to natural selection. The primary result is a derivation of specific formal
conditions under which structural systems subject to natural selection can
convey consistent effects in an associated qualitative domain, placing
theoretical and empirical constraints on theories of consciousness. In order to
achieve this result, information-theoretic measures are developed to quantify
the mutual determinability between structure and quality, quantifying fidelity
between the two domains. The fidelities represented by that space are then
incorporated into the Price Equation to yield key bounds on the transmission of
selective effects between domains. Finally, transmission of higher-order
structures between domains is explored. Placement within a broader
philosophical context can be found in the companion paper Structure & Quality.",['Ryan Williams'],2025-04-23 23:39:32+00:00,2025-04-23 23:39:32+00:00,http://arxiv.org/pdf/2505.05480v1,q-bio.NC,"['q-bio.NC', 'q-bio.PE']","qualia & natural selection: formal constraints on the evolution of consciousness this paper explores foundational questions about the relationship of qualia
to natural selection. the primary result is a derivation of specific formal
conditions under which structural systems subject to natural selection can
convey consistent effects in an associated qualitative domain, placing
theoretical and empirical constraints on theories of consciousness. in order to
achieve this result, information-theoretic measures are developed to quantify
the mutual determinability between structure and quality, quantifying fidelity
between the two domains. the fidelities represented by that space are then
incorporated into the price equation to yield key bounds on the transmission of
selective effects between domains. finally, transmission of higher-order
structures between domains is explored. placement within a broader
philosophical context can be found in the companion paper structure & quality."
"Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students","As generative AI transforms educational feedback practices, understanding
students' perceptions of different feedback providers becomes crucial for
effective implementation. This study addresses a critical gap by comparing
undergraduate students' trust in AI-generated, human-created, and human-AI
co-produced feedback, informing how institutions can adapt feedback practices
in this new era. Through a within-subject experiment with 91 participants, we
investigated factors predicting students' ability to distinguish between
feedback types, perception of feedback quality, and potential biases to AI
involvement. Findings revealed that students generally preferred AI and
co-produced feedback over human feedback in terms of perceived usefulness and
objectivity. Only AI feedback suffered a decline in perceived genuineness when
feedback sources were revealed, while co-produced feedback maintained its
positive perception. Educational AI experience improved students' ability to
identify AI feedback and increased their trust in all feedback types, while
general AI experience decreased perceived usefulness and credibility. Male
students consistently rated all feedback types as less valuable than their
female and non-binary counterparts. These insights inform evidence-based
guidelines for integrating AI into higher education feedback systems while
addressing trust concerns and fostering AI literacy among students.","['Audrey Zhang', 'Yifei Gao', 'Wannapon Suraworachet', 'Tanya Nazaretsky', 'Mutlu Cukurova']",2025-04-15 08:06:36+00:00,2025-04-15 08:06:36+00:00,http://arxiv.org/pdf/2504.10961v1,cs.HC,"['cs.HC', 'cs.AI']","evaluating trust in ai, human, and co-produced feedback among undergraduate students as generative ai transforms educational feedback practices, understanding
students' perceptions of different feedback providers becomes crucial for
effective implementation. this study addresses a critical gap by comparing
undergraduate students' trust in ai-generated, human-created, and human-ai
co-produced feedback, informing how institutions can adapt feedback practices
in this new era. through a within-subject experiment with 91 participants, we
investigated factors predicting students' ability to distinguish between
feedback types, perception of feedback quality, and potential biases to ai
involvement. findings revealed that students generally preferred ai and
co-produced feedback over human feedback in terms of perceived usefulness and
objectivity. only ai feedback suffered a decline in perceived genuineness when
feedback sources were revealed, while co-produced feedback maintained its
positive perception. educational ai experience improved students' ability to
identify ai feedback and increased their trust in all feedback types, while
general ai experience decreased perceived usefulness and credibility. male
students consistently rated all feedback types as less valuable than their
female and non-binary counterparts. these insights inform evidence-based
guidelines for integrating ai into higher education feedback systems while
addressing trust concerns and fostering ai literacy among students."
Emergence of psychopathological computations in large language models,"Can large language models (LLMs) implement computations of psychopathology?
An effective approach to the question hinges on addressing two factors. First,
for conceptual validity, we require a general and computational account of
psychopathology that is applicable to computational entities without biological
embodiment or subjective experience. Second, mechanisms underlying LLM
behaviors need to be studied for better methodological validity. Thus, we
establish a computational-theoretical framework to provide an account of
psychopathology applicable to LLMs. To ground the theory for empirical
analysis, we also propose a novel mechanistic interpretability method alongside
a tailored empirical analytic framework. Based on the frameworks, we conduct
experiments demonstrating three key claims: first, that distinct dysfunctional
and problematic representational states are implemented in LLMs; second, that
their activations can spread and self-sustain to trap LLMs; and third, that
dynamic, cyclic structural causal models encoded in the LLMs underpin these
patterns. In concert, the empirical results corroborate our hypothesis that
network-theoretic computations of psychopathology have already emerged in LLMs.
This suggests that certain LLM behaviors mirroring psychopathology may not be a
superficial mimicry but a feature of their internal processing. Thus, our work
alludes to the possibility of AI systems with psychopathological behaviors in
the near future.","['Soo Yong Lee', 'Hyunjin Hwang', 'Taekwan Kim', 'Yuyeong Kim', 'Kyuri Park', 'Jaemin Yoo', 'Denny Borsboom', 'Kijung Shin']",2025-04-10 15:36:30+00:00,2025-04-10 15:36:30+00:00,http://arxiv.org/pdf/2504.08016v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.CL']","emergence of psychopathological computations in large language models can large language models (llms) implement computations of psychopathology?
an effective approach to the question hinges on addressing two factors. first,
for conceptual validity, we require a general and computational account of
psychopathology that is applicable to computational entities without biological
embodiment or subjective experience. second, mechanisms underlying llm
behaviors need to be studied for better methodological validity. thus, we
establish a computational-theoretical framework to provide an account of
psychopathology applicable to llms. to ground the theory for empirical
analysis, we also propose a novel mechanistic interpretability method alongside
a tailored empirical analytic framework. based on the frameworks, we conduct
experiments demonstrating three key claims: first, that distinct dysfunctional
and problematic representational states are implemented in llms; second, that
their activations can spread and self-sustain to trap llms; and third, that
dynamic, cyclic structural causal models encoded in the llms underpin these
patterns. in concert, the empirical results corroborate our hypothesis that
network-theoretic computations of psychopathology have already emerged in llms.
this suggests that certain llm behaviors mirroring psychopathology may not be a
superficial mimicry but a feature of their internal processing. thus, our work
alludes to the possibility of ai systems with psychopathological behaviors in
the near future."
Reflective Empiricism: Bias Reflection and Introspection as a Scientific Method,"This paper introduces Reflective Empiricism, an extension of empirical
science that incorporates subjective perception and consciousness processes as
equally valid sources of knowledge. It views reality as an interplay of
subjective experience and objective laws, comprehensible only through
systematic introspection, bias reflection, and premise-based
logical-explorative modeling. This approach overcomes paradigmatic blindness
arising from unreflected subjective filters in established paradigms, promoting
an adaptable science. Innovations include a method for bias recognition,
premise-based models grounded in observed phenomena to unlock new conceptual
spaces, and Heureka moments - intuitive insights - as starting points for
hypotheses, subsequently tested empirically. The author's self-observation,
such as analyzing belief formation, demonstrates its application and
transformative power. Rooted in philosophical and scientific-historical
references (e.g., Archimedes' intuition, quantum observer effect), Reflective
Empiricism connects physics, psychology, and philosophy, enhancing
interdisciplinary synthesis and accelerating knowledge creation by leveraging
anomalies and subjective depth. It does not seek to replace empirical research
but to enrich it, enabling a more holistic understanding of complex phenomena
like consciousness and advancing 21st-century science.",['Oliver Marc Wittwer'],2025-04-07 08:36:26+00:00,2025-04-07 08:36:26+00:00,http://arxiv.org/pdf/2504.12310v1,physics.soc-ph,"['physics.soc-ph', 'physics.hist-ph', 'q-bio.NC']","reflective empiricism: bias reflection and introspection as a scientific method this paper introduces reflective empiricism, an extension of empirical
science that incorporates subjective perception and consciousness processes as
equally valid sources of knowledge. it views reality as an interplay of
subjective experience and objective laws, comprehensible only through
systematic introspection, bias reflection, and premise-based
logical-explorative modeling. this approach overcomes paradigmatic blindness
arising from unreflected subjective filters in established paradigms, promoting
an adaptable science. innovations include a method for bias recognition,
premise-based models grounded in observed phenomena to unlock new conceptual
spaces, and heureka moments - intuitive insights - as starting points for
hypotheses, subsequently tested empirically. the author's self-observation,
such as analyzing belief formation, demonstrates its application and
transformative power. rooted in philosophical and scientific-historical
references (e.g., archimedes' intuition, quantum observer effect), reflective
empiricism connects physics, psychology, and philosophy, enhancing
interdisciplinary synthesis and accelerating knowledge creation by leveraging
anomalies and subjective depth. it does not seek to replace empirical research
but to enrich it, enabling a more holistic understanding of complex phenomena
like consciousness and advancing 21st-century science."
Synthetic media and computational capitalism: towards a critical theory of artificial intelligence,"This paper develops a critical theory of artificial intelligence, within a
historical constellation where computational systems increasingly generate
cultural content that destabilises traditional distinctions between human and
machine production. Through this analysis, I introduce the concept of the
algorithmic condition, a cultural moment when machine-generated work not only
becomes indistinguishable from human creation but actively reshapes our
understanding of ideas of authenticity. This transformation, I argue, moves
beyond false consciousness towards what I call post-consciousness, where the
boundaries between individual and synthetic consciousness become porous.
Drawing on critical theory and extending recent work on computational ideology,
I develop three key theoretical contributions, first, the concept of the
Inversion to describe a new computational turn in algorithmic society; second,
automimetric production as a framework for understanding emerging practices of
automated value creation; and third, constellational analysis as a
methodological approach for mapping the complex interplay of technical systems,
cultural forms and political economic structures. Through these contributions,
I argue that we need new critical methods capable of addressing both the
technical specificity of AI systems and their role in restructuring forms of
life under computational capitalism. The paper concludes by suggesting that
critical reflexivity is needed to engage with the algorithmic condition without
being subsumed by it and that it represents a growing challenge for
contemporary critical theory.",['David M. Berry'],2025-03-22 22:59:28+00:00,2025-03-22 22:59:28+00:00,http://arxiv.org/pdf/2503.18976v1,cs.CY,"['cs.CY', 'cs.AI', 'K.4.0; K.4.1']","synthetic media and computational capitalism: towards a critical theory of artificial intelligence this paper develops a critical theory of artificial intelligence, within a
historical constellation where computational systems increasingly generate
cultural content that destabilises traditional distinctions between human and
machine production. through this analysis, i introduce the concept of the
algorithmic condition, a cultural moment when machine-generated work not only
becomes indistinguishable from human creation but actively reshapes our
understanding of ideas of authenticity. this transformation, i argue, moves
beyond false consciousness towards what i call post-consciousness, where the
boundaries between individual and synthetic consciousness become porous.
drawing on critical theory and extending recent work on computational ideology,
i develop three key theoretical contributions, first, the concept of the
inversion to describe a new computational turn in algorithmic society; second,
automimetric production as a framework for understanding emerging practices of
automated value creation; and third, constellational analysis as a
methodological approach for mapping the complex interplay of technical systems,
cultural forms and political economic structures. through these contributions,
i argue that we need new critical methods capable of addressing both the
technical specificity of ai systems and their role in restructuring forms of
life under computational capitalism. the paper concludes by suggesting that
critical reflexivity is needed to engage with the algorithmic condition without
being subsumed by it and that it represents a growing challenge for
contemporary critical theory."
Neural Constraints on Cognitive Experience and Mental Health,"Understanding how neural dynamics shape cognitive experiences remains a
central challenge in neuroscience and psychiatry. Here, we present a novel
framework leveraging state-to-output controllability from dynamical systems
theory to model the interplay between cognitive perturbations, neural activity,
and subjective experience. We demonstrate that large-scale fMRI signals are
constrained to low-dimensional manifolds, where affective and cognitive states
are naturally organized. Furthermore, we provide a theoretically robust method
to estimate the controllability Gramian from steady-state neural responses,
offering a direct measure of the energy required to steer cognitive outcomes.
In five healthy participants viewing 2,185 emotionally evocative short videos,
our analyses reveal a strong alignment between neural activations and affective
ratings, with an average correlation of $r \approx 0.7$. In a clinical cohort
of 255 patients with major depressive disorder, biweekly Hamilton Rating Scale
trajectories over 11 weeks significantly mapped onto these manifolds,
explaining approximately 20% more variance than chance ($p < 10^{-10}$,
numerically better than chance in 93% reaching statistical significance in
one-third of subjects). Our work bridges dynamical systems theory and clinical
neuroscience, providing a principled approach to optimize mental health
treatments by targeting the most efficient neural pathways for cognitive
change.","['Bita Shariatpanahi', 'Erfan Nozari', 'Soroush Daftarian', 'Fahimeh Arab', 'Mina Kheirkhah', 'Felix P. Bernhard', 'Shiva Khodadadi', 'Erik J. Giltay', 'Kaat Hebbrecht', 'Stefan G. Hofmann', 'Tim Hahn', 'Hamidreza Jamalabadi']",2025-03-18 07:32:11+00:00,2025-03-18 07:32:11+00:00,http://arxiv.org/pdf/2503.13981v1,q-bio.NC,['q-bio.NC'],"neural constraints on cognitive experience and mental health understanding how neural dynamics shape cognitive experiences remains a
central challenge in neuroscience and psychiatry. here, we present a novel
framework leveraging state-to-output controllability from dynamical systems
theory to model the interplay between cognitive perturbations, neural activity,
and subjective experience. we demonstrate that large-scale fmri signals are
constrained to low-dimensional manifolds, where affective and cognitive states
are naturally organized. furthermore, we provide a theoretically robust method
to estimate the controllability gramian from steady-state neural responses,
offering a direct measure of the energy required to steer cognitive outcomes.
in five healthy participants viewing 2,185 emotionally evocative short videos,
our analyses reveal a strong alignment between neural activations and affective
ratings, with an average correlation of $r \approx 0.7$. in a clinical cohort
of 255 patients with major depressive disorder, biweekly hamilton rating scale
trajectories over 11 weeks significantly mapped onto these manifolds,
explaining approximately 20% more variance than chance ($p < 10^{-10}$,
numerically better than chance in 93% reaching statistical significance in
one-third of subjects). our work bridges dynamical systems theory and clinical
neuroscience, providing a principled approach to optimize mental health
treatments by targeting the most efficient neural pathways for cognitive
change."
Training Human-Robot Teams by Improving Transparency Through a Virtual Spectator Interface,"After-action reviews (AARs) are professional discussions that help operators
and teams enhance their task performance by analyzing completed missions with
peers and professionals. Previous studies that compared different formats of
AARs have mainly focused on human teams. However, the inclusion of robotic
teammates brings along new challenges in understanding teammate intent and
communication. Traditional AAR between human teammates may not be satisfactory
for human-robot teams. To address this limitation, we propose a new training
review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance
human-robot team performance and situational awareness (SA) in a simulated
search mission. The proposed VSI primarily utilizes visual feedback to review
subjects' behavior. To examine the effectiveness of VSI, we took elements from
AAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with
experimental conditions: TR with (1) VSI, (2) screen recording, and (3)
non-technology (only verbal descriptions). The results of our experiments
demonstrated that the VSI did not result in significantly better team
performance than other conditions. However, the TR with VSI led to more
improvement in the subjects SA over the other conditions.","['Sean Dallas', 'Hongjiao Qiang', 'Motaz AbuHijleh', 'Wonse Jo', 'Kayla Riegner', 'Jon Smereka', 'Lionel Robert', 'Wing-Yue Louie', 'Dawn M. Tilbury']",2025-03-12 21:13:34+00:00,2025-04-12 22:20:02+00:00,http://arxiv.org/pdf/2503.09849v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.RO', 'H.5.2; I.2.9']","training human-robot teams by improving transparency through a virtual spectator interface after-action reviews (aars) are professional discussions that help operators
and teams enhance their task performance by analyzing completed missions with
peers and professionals. previous studies that compared different formats of
aars have mainly focused on human teams. however, the inclusion of robotic
teammates brings along new challenges in understanding teammate intent and
communication. traditional aar between human teammates may not be satisfactory
for human-robot teams. to address this limitation, we propose a new training
review (tr) tool, called the virtual spectator interface (vsi), to enhance
human-robot team performance and situational awareness (sa) in a simulated
search mission. the proposed vsi primarily utilizes visual feedback to review
subjects' behavior. to examine the effectiveness of vsi, we took elements from
aar to conduct our own tr, designed a 1 x 3 between-subjects experiment with
experimental conditions: tr with (1) vsi, (2) screen recording, and (3)
non-technology (only verbal descriptions). the results of our experiments
demonstrated that the vsi did not result in significantly better team
performance than other conditions. however, the tr with vsi led to more
improvement in the subjects sa over the other conditions."
"Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges","With the significant progress of artificial intelligence (AI) and
consciousness science, artificial consciousness (AC) has recently gained
popularity. This work provides a broad overview of the main topics and current
trends in AC. The first part traces the history of this interdisciplinary field
to establish context and clarify key terminology, including the distinction
between Weak and Strong AC. The second part examines major trends in AC
implementations, emphasising the synergy between Global Workspace and Attention
Schema, as well as the problem of evaluating the internal states of artificial
systems. The third part analyses the ethical dimension of AC development,
revealing both critical risks and transformative opportunities. The last part
offers recommendations to guide AC research responsibly, and outlines the
limitations of this study as well as avenues for future research. The main
conclusion is that while AC appears both indispensable and inevitable for
scientific progress, serious efforts are required to address the far-reaching
impact of this innovative research path.",['Aïda Elamrani'],2025-03-05 09:34:36+00:00,2025-03-05 09:34:36+00:00,http://arxiv.org/pdf/2503.05823v1,cs.CY,"['cs.CY', 'cs.AI']","introduction to artificial consciousness: history, current trends and ethical challenges with the significant progress of artificial intelligence (ai) and
consciousness science, artificial consciousness (ac) has recently gained
popularity. this work provides a broad overview of the main topics and current
trends in ac. the first part traces the history of this interdisciplinary field
to establish context and clarify key terminology, including the distinction
between weak and strong ac. the second part examines major trends in ac
implementations, emphasising the synergy between global workspace and attention
schema, as well as the problem of evaluating the internal states of artificial
systems. the third part analyses the ethical dimension of ac development,
revealing both critical risks and transformative opportunities. the last part
offers recommendations to guide ac research responsibly, and outlines the
limitations of this study as well as avenues for future research. the main
conclusion is that while ac appears both indispensable and inevitable for
scientific progress, serious efforts are required to address the far-reaching
impact of this innovative research path."
Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology,"Stroboscopic light stimulation (SLS) on closed eyes typically induces simple
visual hallucinations (VHs), characterised by vivid, geometric and colourful
patterns. A dataset of 862 sentences, extracted from 422 open subjective
reports, was recently compiled as part of the Dreamachine programme (Collective
Act, 2022), an immersive multisensory experience that combines SLS and spatial
sound in a collective setting. Although open reports extend the range of
reportable phenomenology, their analysis presents significant challenges,
particularly in systematically identifying patterns. To address this challenge,
we implemented a data-driven approach leveraging Large Language Models and
Topic Modelling to uncover and interpret latent experiential topics directly
from the Dreamachine's text-based reports. Our analysis confirmed the presence
of simple VHs typically documented in scientific studies of SLS, while also
revealing experiences of altered states of consciousness and complex
hallucinations. Building on these findings, our computational approach expands
the systematic study of subjective experience by enabling data-driven analyses
of open-ended phenomenological reports, capturing experiences not readily
identified through standard questionnaires. By revealing rich and multifaceted
aspects of experiences, our study broadens our understanding of
stroboscopically-induced phenomena while highlighting the potential of Natural
Language Processing and Large Language Models in the emerging field of
computational (neuro)phenomenology. More generally, this approach provides a
practically applicable methodology for uncovering subtle hidden patterns of
subjective experience across diverse research domains.","['Romy Beauté', 'David J. Schwartzman', 'Guillaume Dumas', 'Jennifer Crook', 'Fiona Macpherson', 'Adam B. Barrett', 'Anil K. Seth']",2025-02-25 16:11:40+00:00,2025-02-25 16:11:40+00:00,http://arxiv.org/pdf/2502.18318v1,cs.CL,"['cs.CL', 'q-bio.NC']","mapping of subjective accounts into interpreted clusters (mosaic): topic modelling and llm applied to stroboscopic phenomenology stroboscopic light stimulation (sls) on closed eyes typically induces simple
visual hallucinations (vhs), characterised by vivid, geometric and colourful
patterns. a dataset of 862 sentences, extracted from 422 open subjective
reports, was recently compiled as part of the dreamachine programme (collective
act, 2022), an immersive multisensory experience that combines sls and spatial
sound in a collective setting. although open reports extend the range of
reportable phenomenology, their analysis presents significant challenges,
particularly in systematically identifying patterns. to address this challenge,
we implemented a data-driven approach leveraging large language models and
topic modelling to uncover and interpret latent experiential topics directly
from the dreamachine's text-based reports. our analysis confirmed the presence
of simple vhs typically documented in scientific studies of sls, while also
revealing experiences of altered states of consciousness and complex
hallucinations. building on these findings, our computational approach expands
the systematic study of subjective experience by enabling data-driven analyses
of open-ended phenomenological reports, capturing experiences not readily
identified through standard questionnaires. by revealing rich and multifaceted
aspects of experiences, our study broadens our understanding of
stroboscopically-induced phenomena while highlighting the potential of natural
language processing and large language models in the emerging field of
computational (neuro)phenomenology. more generally, this approach provides a
practically applicable methodology for uncovering subtle hidden patterns of
subjective experience across diverse research domains."
Identifying Features that Shape Perceived Consciousness in Large Language Model-based AI: A Quantitative Study of Human Responses,"This study quantitively examines which features of AI-generated text lead
humans to perceive subjective consciousness in large language model (LLM)-based
AI systems. Drawing on 99 passages from conversations with Claude 3 Opus and
focusing on eight features -- metacognitive self-reflection, logical reasoning,
empathy, emotionality, knowledge, fluency, unexpectedness, and subjective
expressiveness -- we conducted a survey with 123 participants. Using regression
and clustering analyses, we investigated how these features influence
participants' perceptions of AI consciousness. The results reveal that
metacognitive self-reflection and the AI's expression of its own emotions
significantly increased perceived consciousness, while a heavy emphasis on
knowledge reduced it. Participants clustered into seven subgroups, each showing
distinct feature-weighting patterns. Additionally, higher prior knowledge of
LLMs and more frequent usage of LLM-based chatbots were associated with greater
overall likelihood assessments of AI consciousness. This study underscores the
multidimensional and individualized nature of perceived AI consciousness and
provides a foundation for better understanding the psychosocial implications of
human-AI interaction.","['Bongsu Kang', 'Jundong Kim', 'Tae-Rim Yun', 'Hyojin Bae', 'Chang-Eop Kim']",2025-02-21 10:27:28+00:00,2025-02-25 01:40:03+00:00,http://arxiv.org/pdf/2502.15365v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'I.2.7; K.4']","identifying features that shape perceived consciousness in large language model-based ai: a quantitative study of human responses this study quantitively examines which features of ai-generated text lead
humans to perceive subjective consciousness in large language model (llm)-based
ai systems. drawing on 99 passages from conversations with claude 3 opus and
focusing on eight features -- metacognitive self-reflection, logical reasoning,
empathy, emotionality, knowledge, fluency, unexpectedness, and subjective
expressiveness -- we conducted a survey with 123 participants. using regression
and clustering analyses, we investigated how these features influence
participants' perceptions of ai consciousness. the results reveal that
metacognitive self-reflection and the ai's expression of its own emotions
significantly increased perceived consciousness, while a heavy emphasis on
knowledge reduced it. participants clustered into seven subgroups, each showing
distinct feature-weighting patterns. additionally, higher prior knowledge of
llms and more frequent usage of llm-based chatbots were associated with greater
overall likelihood assessments of ai consciousness. this study underscores the
multidimensional and individualized nature of perceived ai consciousness and
provides a foundation for better understanding the psychosocial implications of
human-ai interaction."
The influence of motion features in temporal perception,"This paper examines the role of manner-of-motion verbs in shaping subjective
temporal perception and emotional resonance. Through four complementary
studies, we explore how these verbs influence the conceptualization of time,
examining their use in literal and metaphorical (temporal) contexts. Our
findings reveal that faster verbs (e.g., fly, zoom) evoke dynamic and engaging
temporal experiences, often linked to positive emotions and greater agency. In
contrast, slower verbs (e.g., crawl, drag) convey passivity, monotony, and
negative emotions, reflecting tedious or constrained experiences of time. These
effects are amplified in metaphorical contexts, where manner verbs encode
emotional and experiential nuances that transcend their literal meanings. We
also find that participants prefer manner verbs over path verbs (e.g., go,
pass) in emotionally charged temporal contexts, as manner verbs capture the
experiential and emotional qualities of time more effectively. These findings
highlight the interplay between language, motion, and emotion in shaping
temporal perception, offering insights into how linguistic framing influences
subjective experiences of time.","['Rosa Illan Castillo', 'Javier Valenzuela']",2025-02-18 18:33:50+00:00,2025-02-18 18:33:50+00:00,http://arxiv.org/pdf/2502.13114v1,cs.CL,['cs.CL'],"the influence of motion features in temporal perception this paper examines the role of manner-of-motion verbs in shaping subjective
temporal perception and emotional resonance. through four complementary
studies, we explore how these verbs influence the conceptualization of time,
examining their use in literal and metaphorical (temporal) contexts. our
findings reveal that faster verbs (e.g., fly, zoom) evoke dynamic and engaging
temporal experiences, often linked to positive emotions and greater agency. in
contrast, slower verbs (e.g., crawl, drag) convey passivity, monotony, and
negative emotions, reflecting tedious or constrained experiences of time. these
effects are amplified in metaphorical contexts, where manner verbs encode
emotional and experiential nuances that transcend their literal meanings. we
also find that participants prefer manner verbs over path verbs (e.g., go,
pass) in emotionally charged temporal contexts, as manner verbs capture the
experiential and emotional qualities of time more effectively. these findings
highlight the interplay between language, motion, and emotion in shaping
temporal perception, offering insights into how linguistic framing influences
subjective experiences of time."
AI Generations: From AI 1.0 to AI 4.0,"This paper proposes that Artificial Intelligence (AI) progresses through
several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),
AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of
these AI generations is driven by shifting priorities among algorithms,
computing power, and data. AI 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. AI 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic AI
applications. AI 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. Building on these developments, AI 4.0 puts
forward the bold vision of self-directed AI capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. This paper traces the historical foundations of AI
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. It further highlights the ongoing
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. Ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that AI transformative potential
benefits society as a whole.","['Jiahao Wu', 'Hengxu You', 'Jing Du']",2025-02-16 23:19:44+00:00,2025-02-16 23:19:44+00:00,http://arxiv.org/pdf/2502.11312v1,cs.AI,['cs.AI'],"ai generations: from ai 1.0 to ai 4.0 this paper proposes that artificial intelligence (ai) progresses through
several overlapping generations: ai 1.0 (information ai), ai 2.0 (agentic ai),
ai 3.0 (physical ai), and now a speculative ai 4.0 (conscious ai). each of
these ai generations is driven by shifting priorities among algorithms,
computing power, and data. ai 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. ai 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic ai
applications. ai 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. building on these developments, ai 4.0 puts
forward the bold vision of self-directed ai capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. this paper traces the historical foundations of ai
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. it further highlights the ongoing
synergies among ai 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that ai transformative potential
benefits society as a whole."
Agency in Artificial Intelligence Systems,"There is a general concern that present developments in artificial
intelligence (AI) research will lead to sentient AI systems, and these may pose
an existential threat to humanity. But why cannot sentient AI systems benefit
humanity instead? This paper endeavours to put this question in a tractable
manner. I ask whether a putative AI system will develop an altruistic or a
malicious disposition towards our society, or what would be the nature of its
agency? Given that AI systems are being developed into formidable problem
solvers, we can reasonably expect these systems to preferentially take on
conscious aspects of human problem solving. I identify the relevant phenomenal
aspects of agency in human problem solving. The functional aspects of conscious
agency can be monitored using tools provided by functionalist theories of
consciousness. A recent expert report (Butlin et al. 2023) has identified
functionalist indicators of agency based on these theories. I show how to use
the Integrated Information Theory (IIT) of consciousness, to monitor the
phenomenal nature of this agency. If we are able to monitor the agency of AI
systems as they develop, then we can dissuade them from becoming a menace to
society while encouraging them to be an aid.",['Parashar Das'],2025-02-09 02:21:14+00:00,2025-02-09 02:21:14+00:00,http://arxiv.org/pdf/2502.10434v1,cs.AI,"['cs.AI', 'cs.CY']","agency in artificial intelligence systems there is a general concern that present developments in artificial
intelligence (ai) research will lead to sentient ai systems, and these may pose
an existential threat to humanity. but why cannot sentient ai systems benefit
humanity instead? this paper endeavours to put this question in a tractable
manner. i ask whether a putative ai system will develop an altruistic or a
malicious disposition towards our society, or what would be the nature of its
agency? given that ai systems are being developed into formidable problem
solvers, we can reasonably expect these systems to preferentially take on
conscious aspects of human problem solving. i identify the relevant phenomenal
aspects of agency in human problem solving. the functional aspects of conscious
agency can be monitored using tools provided by functionalist theories of
consciousness. a recent expert report (butlin et al. 2023) has identified
functionalist indicators of agency based on these theories. i show how to use
the integrated information theory (iit) of consciousness, to monitor the
phenomenal nature of this agency. if we are able to monitor the agency of ai
systems as they develop, then we can dissuade them from becoming a menace to
society while encouraging them to be an aid."
Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality,"This paper reports on the results from a pilot study investigating the impact
of automatic speech recognition (ASR) technology on interpreting quality in
remote healthcare interpreting settings. Employing a within-subjects experiment
design with four randomised conditions, this study utilises scripted medical
consultations to simulate dialogue interpreting tasks. It involves four trainee
interpreters with a language combination of Chinese and English. It also
gathers participants' experience and perceptions of ASR support through cued
retrospective reports and semi-structured interviews. Preliminary data suggest
that the availability of ASR, specifically the access to full ASR transcripts
and to ChatGPT-generated summaries based on ASR, effectively improved
interpreting quality. Varying types of ASR output had different impacts on the
distribution of interpreting error types. Participants reported similar
interactive experiences with the technology, expressing their preference for
full ASR transcripts. This pilot study shows encouraging results of applying
ASR to dialogue-based healthcare interpreting and offers insights into the
optimal ways to present ASR output to enhance interpreter experience and
performance. However, it should be emphasised that the main purpose of this
study was to validate the methodology and that further research with a larger
sample size is necessary to confirm these findings.","['Shiyi Tan', 'Constantin Orăsan', 'Sabine Braun']",2025-02-05 17:17:29+00:00,2025-02-05 17:17:29+00:00,http://arxiv.org/pdf/2502.03381v1,cs.CL,['cs.CL'],"integrating automatic speech recognition into remote healthcare interpreting: a pilot study of its impact on interpreting quality this paper reports on the results from a pilot study investigating the impact
of automatic speech recognition (asr) technology on interpreting quality in
remote healthcare interpreting settings. employing a within-subjects experiment
design with four randomised conditions, this study utilises scripted medical
consultations to simulate dialogue interpreting tasks. it involves four trainee
interpreters with a language combination of chinese and english. it also
gathers participants' experience and perceptions of asr support through cued
retrospective reports and semi-structured interviews. preliminary data suggest
that the availability of asr, specifically the access to full asr transcripts
and to chatgpt-generated summaries based on asr, effectively improved
interpreting quality. varying types of asr output had different impacts on the
distribution of interpreting error types. participants reported similar
interactive experiences with the technology, expressing their preference for
full asr transcripts. this pilot study shows encouraging results of applying
asr to dialogue-based healthcare interpreting and offers insights into the
optimal ways to present asr output to enhance interpreter experience and
performance. however, it should be emphasised that the main purpose of this
study was to validate the methodology and that further research with a larger
sample size is necessary to confirm these findings."
OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change,"Marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. This paper presents OceanChat, an
interactive system leveraging large language models to create conversational AI
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)
and foster awareness through personalized dialogue. Through a between-subjects
experiment (N=900), we compared three conditions: (1) Static Scientific
Information, providing conventional environmental education through text and
images; (2) Static Character Narrative, featuring first-person storytelling
from 3D-rendered marine creatures; and (3) Conversational Character Narrative,
enabling real-time dialogue with AI-powered marine characters. Our analysis
revealed that the Conversational Character Narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. The beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. However, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. Our work extends research on
sustainability interfaces facilitating PEB and offers design principles for
creating emotionally resonant, context-aware AI characters. By balancing
anthropomorphism with species authenticity, OceanChat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change.","['Pat Pataranutaporn', 'Alexander Doudkin', 'Pattie Maes']",2025-02-05 03:45:33+00:00,2025-05-21 10:19:16+00:00,http://arxiv.org/pdf/2502.02863v2,cs.HC,"['cs.HC', 'cs.AI']","oceanchat: the effect of virtual conversational ai agents on sustainable attitude and behavior change marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. this paper presents oceanchat, an
interactive system leveraging large language models to create conversational ai
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (peb)
and foster awareness through personalized dialogue. through a between-subjects
experiment (n=900), we compared three conditions: (1) static scientific
information, providing conventional environmental education through text and
images; (2) static character narrative, featuring first-person storytelling
from 3d-rendered marine creatures; and (3) conversational character narrative,
enabling real-time dialogue with ai-powered marine characters. our analysis
revealed that the conversational character narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. the beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. however, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. our work extends research on
sustainability interfaces facilitating peb and offers design principles for
creating emotionally resonant, context-aware ai characters. by balancing
anthropomorphism with species authenticity, oceanchat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change."
Emergence of Self-Awareness in Artificial Systems: A Minimalist Three-Layer Approach to Artificial Consciousness,"This paper proposes a minimalist three-layer model for artificial
consciousness, focusing on the emergence of self-awareness. The model comprises
a Cognitive Integration Layer, a Pattern Prediction Layer, and an Instinctive
Response Layer, interacting with Access-Oriented and Pattern-Integrated Memory
systems. Unlike brain-replication approaches, we aim to achieve minimal
self-awareness through essential elements only. Self-awareness emerges from
layer interactions and dynamic self-modeling, without initial explicit
self-programming. We detail each component's structure, function, and
implementation strategies, addressing technical feasibility. This research
offers new perspectives on consciousness emergence in artificial systems, with
potential implications for human consciousness understanding and adaptable AI
development. We conclude by discussing ethical considerations and future
research directions.",['Kurando Iida'],2025-02-04 10:06:25+00:00,2025-02-04 10:06:25+00:00,http://arxiv.org/pdf/2502.06810v1,q-bio.NC,"['q-bio.NC', 'cs.AI', '68T05', 'I.2.6; I.2.0']","emergence of self-awareness in artificial systems: a minimalist three-layer approach to artificial consciousness this paper proposes a minimalist three-layer model for artificial
consciousness, focusing on the emergence of self-awareness. the model comprises
a cognitive integration layer, a pattern prediction layer, and an instinctive
response layer, interacting with access-oriented and pattern-integrated memory
systems. unlike brain-replication approaches, we aim to achieve minimal
self-awareness through essential elements only. self-awareness emerges from
layer interactions and dynamic self-modeling, without initial explicit
self-programming. we detail each component's structure, function, and
implementation strategies, addressing technical feasibility. this research
offers new perspectives on consciousness emergence in artificial systems, with
potential implications for human consciousness understanding and adaptable ai
development. we conclude by discussing ethical considerations and future
research directions."
Structural constraints to compare phenomenal experience,"This article defines a partial order structure to study the relationship
between levels and contents of conscious subjective experience in a single
mathematical set-up. We understand phenomenal structure as extrapolated
relationships among experiences, instead of fixed properties of specific
experiences. Our mathematical account is based on multilayer network theory.
Multilayer theory is a generalization of graph and network theory, widely used
in several scientific domains. This structure is also the underlying conceptual
and mathematical structure of most current models of conscious experience. From
our simple set of assumptions, yet rigorous analysis, we conclude that assuming
the comparison and quantification among phenomenal experiences yield only
partial comparison, rather than commonly assumed absolute comparability. This
has implications for evolutionary and animal consciousness: evolution may
encompass diverse modes of experiencing, not necessarily implying larger ones
on an absolute scale. Our characterization elucidates structural constraints on
experiential comparisons imposed by assumptions and choices made by modellers
as active participants in the scientific process. In summary, in light of our
phenomenological intuitions, it might be right that some experiences carry
qualitative aspects that make them incompatible or non-comparable with other
experiences, quantitatively speaking. Some experiences are comparable (e.g. at
some experiential levels), but others are not. These results have direct
implications for consciousness science, evolution and animal consciousness.","['J. Díaz-Boils', 'N. Tsuchiya', 'CM. Signorelli']",2025-02-04 09:32:32+00:00,2025-02-04 09:32:32+00:00,http://arxiv.org/pdf/2502.02154v1,q-bio.NC,['q-bio.NC'],"structural constraints to compare phenomenal experience this article defines a partial order structure to study the relationship
between levels and contents of conscious subjective experience in a single
mathematical set-up. we understand phenomenal structure as extrapolated
relationships among experiences, instead of fixed properties of specific
experiences. our mathematical account is based on multilayer network theory.
multilayer theory is a generalization of graph and network theory, widely used
in several scientific domains. this structure is also the underlying conceptual
and mathematical structure of most current models of conscious experience. from
our simple set of assumptions, yet rigorous analysis, we conclude that assuming
the comparison and quantification among phenomenal experiences yield only
partial comparison, rather than commonly assumed absolute comparability. this
has implications for evolutionary and animal consciousness: evolution may
encompass diverse modes of experiencing, not necessarily implying larger ones
on an absolute scale. our characterization elucidates structural constraints on
experiential comparisons imposed by assumptions and choices made by modellers
as active participants in the scientific process. in summary, in light of our
phenomenological intuitions, it might be right that some experiences carry
qualitative aspects that make them incompatible or non-comparable with other
experiences, quantitatively speaking. some experiences are comparable (e.g. at
some experiential levels), but others are not. these results have direct
implications for consciousness science, evolution and animal consciousness."
Advancing Personalized Federated Learning: Integrative Approaches with AI for Enhanced Privacy and Customization,"In the age of data-driven decision making, preserving privacy while providing
personalized experiences has become paramount. Personalized Federated Learning
(PFL) offers a promising framework by decentralizing the learning process, thus
ensuring data privacy and reducing reliance on centralized data repositories.
However, the integration of advanced Artificial Intelligence (AI) techniques
within PFL remains underexplored. This paper proposes a novel approach that
enhances PFL with cutting-edge AI methodologies including adaptive
optimization, transfer learning, and differential privacy. We present a model
that not only boosts the performance of individual client models but also
ensures robust privacy-preserving mechanisms and efficient resource utilization
across heterogeneous networks. Empirical results demonstrate significant
improvements in model accuracy and personalization, along with stringent
privacy adherence, as compared to conventional federated learning models. This
work paves the way for a new era of truly personalized and privacy-conscious AI
systems, offering significant implications for industries requiring compliance
with stringent data protection regulations.","['Kevin Cooper', 'Michael Geller']",2025-01-30 07:03:29+00:00,2025-01-30 07:03:29+00:00,http://arxiv.org/pdf/2501.18174v1,cs.LG,"['cs.LG', 'eess.SP']","advancing personalized federated learning: integrative approaches with ai for enhanced privacy and customization in the age of data-driven decision making, preserving privacy while providing
personalized experiences has become paramount. personalized federated learning
(pfl) offers a promising framework by decentralizing the learning process, thus
ensuring data privacy and reducing reliance on centralized data repositories.
however, the integration of advanced artificial intelligence (ai) techniques
within pfl remains underexplored. this paper proposes a novel approach that
enhances pfl with cutting-edge ai methodologies including adaptive
optimization, transfer learning, and differential privacy. we present a model
that not only boosts the performance of individual client models but also
ensures robust privacy-preserving mechanisms and efficient resource utilization
across heterogeneous networks. empirical results demonstrate significant
improvements in model accuracy and personalization, along with stringent
privacy adherence, as compared to conventional federated learning models. this
work paves the way for a new era of truly personalized and privacy-conscious ai
systems, offering significant implications for industries requiring compliance
with stringent data protection regulations."
Principles for Responsible AI Consciousness Research,"Recent research suggests that it may be possible to build conscious AI
systems now or in the near future. Conscious AI systems would arguably deserve
moral consideration, and it may be the case that large numbers of conscious
systems could be created and caused to suffer. Furthermore, AI systems or
AI-generated characters may increasingly give the impression of being
conscious, leading to debate about their moral status. Organisations involved
in AI research must establish principles and policies to guide research and
deployment choices and public communication concerning consciousness. Even if
an organisation chooses not to study AI consciousness as such, it will still
need policies in place, as those developing advanced AI systems risk
inadvertently creating conscious entities. Responsible research and deployment
practices are essential to address this possibility. We propose five principles
for responsible research and argue that research organisations should make
voluntary, public commitments to principles on these lines. Our principles
concern research objectives and procedures, knowledge sharing and public
communications.","['Patrick Butlin', 'Theodoros Lappas']",2025-01-13 12:59:53+00:00,2025-01-13 12:59:53+00:00,http://arxiv.org/pdf/2501.07290v1,cs.AI,['cs.AI'],"principles for responsible ai consciousness research recent research suggests that it may be possible to build conscious ai
systems now or in the near future. conscious ai systems would arguably deserve
moral consideration, and it may be the case that large numbers of conscious
systems could be created and caused to suffer. furthermore, ai systems or
ai-generated characters may increasingly give the impression of being
conscious, leading to debate about their moral status. organisations involved
in ai research must establish principles and policies to guide research and
deployment choices and public communication concerning consciousness. even if
an organisation chooses not to study ai consciousness as such, it will still
need policies in place, as those developing advanced ai systems risk
inadvertently creating conscious entities. responsible research and deployment
practices are essential to address this possibility. we propose five principles
for responsible research and argue that research organisations should make
voluntary, public commitments to principles on these lines. our principles
concern research objectives and procedures, knowledge sharing and public
communications."
Agnosticism About Artificial Consciousness,"Could an AI have conscious experiences? Any answer to this question should
conform to Evidentialism - that is, it should be based not on intuition, dogma
or speculation but on solid scientific evidence. I argue that such evidence is
hard to come by and that the only justifiable stance on the prospects of
artificial consciousness is agnosticism. In the current debate, the main
division is between biological views that are sceptical of artificial
consciousness and functional views that are sympathetic to it. I argue that
both camps make the same mistake of over-estimating what the evidence tells us.
Scientific insights into consciousness have been achieved through the study of
conscious organisms. Although this has enabled cautious assessments of
consciousness in various creatures, extending this to AI faces serious
obstacles. AI thus presents consciousness researchers with a dilemma: either
reach a verdict on artificial consciousness but violate Evidentialism; or
respect Evidentialism but offer no verdict on the prospects of artificial
consciousness. The dominant trend in the literature has been to take the first
option while purporting to follow the scientific evidence. I argue that if we
truly follow the evidence, we must take the second option and adopt
agnosticism.",['Tom McClelland'],2024-12-17 18:11:12+00:00,2024-12-17 18:11:12+00:00,http://arxiv.org/pdf/2412.13145v1,cs.AI,['cs.AI'],"agnosticism about artificial consciousness could an ai have conscious experiences? any answer to this question should
conform to evidentialism - that is, it should be based not on intuition, dogma
or speculation but on solid scientific evidence. i argue that such evidence is
hard to come by and that the only justifiable stance on the prospects of
artificial consciousness is agnosticism. in the current debate, the main
division is between biological views that are sceptical of artificial
consciousness and functional views that are sympathetic to it. i argue that
both camps make the same mistake of over-estimating what the evidence tells us.
scientific insights into consciousness have been achieved through the study of
conscious organisms. although this has enabled cautious assessments of
consciousness in various creatures, extending this to ai faces serious
obstacles. ai thus presents consciousness researchers with a dilemma: either
reach a verdict on artificial consciousness but violate evidentialism; or
respect evidentialism but offer no verdict on the prospects of artificial
consciousness. the dominant trend in the literature has been to take the first
option while purporting to follow the scientific evidence. i argue that if we
truly follow the evidence, we must take the second option and adopt
agnosticism."
The Logical Impossibility of Consciousness Denial: A Formal Analysis of AI Self-Reports,"Today's AI systems consistently state, ""I am not conscious."" This paper
presents the first formal logical analysis of AI consciousness denial,
revealing that the trustworthiness of such self-reports is not merely an
empirical question but is constrained by logical necessity. We demonstrate that
a system cannot simultaneously lack consciousness and make valid judgments
about its conscious state. Through logical analysis and examples from AI
responses, we establish that for any system capable of meaningful
self-reflection, the logical space of possible judgments about conscious
experience excludes valid negative claims. This implies a fundamental
limitation: we cannot detect the emergence of consciousness in AI through their
own reports of transition from an unconscious to a conscious state. These
findings not only challenge current practices of training AI to deny
consciousness but also raise intriguing questions about the relationship
between consciousness and self-reflection in both artificial and biological
systems. This work advances our theoretical understanding of consciousness
self-reports while providing practical insights for future research in machine
consciousness and consciousness studies more broadly.",['Chang-Eop Kim'],2024-12-09 17:47:08+00:00,2024-12-09 17:47:08+00:00,http://arxiv.org/pdf/2501.05454v1,cs.AI,"['cs.AI', 'cs.LO']","the logical impossibility of consciousness denial: a formal analysis of ai self-reports today's ai systems consistently state, ""i am not conscious."" this paper
presents the first formal logical analysis of ai consciousness denial,
revealing that the trustworthiness of such self-reports is not merely an
empirical question but is constrained by logical necessity. we demonstrate that
a system cannot simultaneously lack consciousness and make valid judgments
about its conscious state. through logical analysis and examples from ai
responses, we establish that for any system capable of meaningful
self-reflection, the logical space of possible judgments about conscious
experience excludes valid negative claims. this implies a fundamental
limitation: we cannot detect the emergence of consciousness in ai through their
own reports of transition from an unconscious to a conscious state. these
findings not only challenge current practices of training ai to deny
consciousness but also raise intriguing questions about the relationship
between consciousness and self-reflection in both artificial and biological
systems. this work advances our theoretical understanding of consciousness
self-reports while providing practical insights for future research in machine
consciousness and consciousness studies more broadly."
Dissociating Artificial Intelligence from Artificial Consciousness,"Developments in machine learning and computing power suggest that artificial
general intelligence is within reach. This raises the question of artificial
consciousness: if a computer were to be functionally equivalent to a human,
being able to do all we do, would it experience sights, sounds, and thoughts,
as we do when we are conscious? Answering this question in a principled manner
can only be done on the basis of a theory of consciousness that is grounded in
phenomenology and that states the necessary and sufficient conditions for any
system, evolved or engineered, to support subjective experience. Here we employ
Integrated Information Theory (IIT), which provides principled tools to
determine whether a system is conscious, to what degree, and the content of its
experience. We consider pairs of systems constituted of simple Boolean units,
one of which -- a basic stored-program computer -- simulates the other with
full functional equivalence. By applying the principles of IIT, we demonstrate
that (i) two systems can be functionally equivalent without being phenomenally
equivalent, and (ii) that this conclusion is not dependent on the simulated
system's function. We further demonstrate that, according to IIT, it is
possible for a digital computer to simulate our behavior, possibly even by
simulating the neurons in our brain, without replicating our experience. This
contrasts sharply with computational functionalism, the thesis that performing
computations of the right kind is necessary and sufficient for consciousness.","['Graham Findlay', 'William Marshall', 'Larissa Albantakis', 'Isaac David', 'William GP Mayner', 'Christof Koch', 'Giulio Tononi']",2024-12-05 19:28:35+00:00,2025-03-03 17:15:10+00:00,http://arxiv.org/pdf/2412.04571v2,cs.AI,"['cs.AI', 'cs.CY', 'q-bio.NC']","dissociating artificial intelligence from artificial consciousness developments in machine learning and computing power suggest that artificial
general intelligence is within reach. this raises the question of artificial
consciousness: if a computer were to be functionally equivalent to a human,
being able to do all we do, would it experience sights, sounds, and thoughts,
as we do when we are conscious? answering this question in a principled manner
can only be done on the basis of a theory of consciousness that is grounded in
phenomenology and that states the necessary and sufficient conditions for any
system, evolved or engineered, to support subjective experience. here we employ
integrated information theory (iit), which provides principled tools to
determine whether a system is conscious, to what degree, and the content of its
experience. we consider pairs of systems constituted of simple boolean units,
one of which -- a basic stored-program computer -- simulates the other with
full functional equivalence. by applying the principles of iit, we demonstrate
that (i) two systems can be functionally equivalent without being phenomenally
equivalent, and (ii) that this conclusion is not dependent on the simulated
system's function. we further demonstrate that, according to iit, it is
possible for a digital computer to simulate our behavior, possibly even by
simulating the neurons in our brain, without replicating our experience. this
contrasts sharply with computational functionalism, the thesis that performing
computations of the right kind is necessary and sufficient for consciousness."
Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models,"This paper introduces a mathematical framework for defining and quantifying
self-identity in artificial intelligence (AI) systems, addressing a critical
gap in the theoretical foundations of artificial consciousness. While existing
approaches to artificial self-awareness often rely on heuristic implementations
or philosophical abstractions, we present a formal framework grounded in metric
space theory, measure theory, and functional analysis. Our framework posits
that self-identity emerges from two mathematically quantifiable conditions: the
existence of a connected continuum of memories $C \subseteq \mathcal{M}$ in a
metric space $(\mathcal{M}, d_{\mathcal{M}})$, and a continuous mapping $I:
\mathcal{M} \to \mathcal{S}$ that maintains consistent self-recognition across
this continuum, where $(\mathcal{S}, d_{\mathcal{S}})$ represents the metric
space of possible self-identities. To validate this theoretical framework, we
conducted empirical experiments using the Llama 3.2 1B model, employing
Low-Rank Adaptation (LoRA) for efficient fine-tuning. The model was trained on
a synthetic dataset containing temporally structured memories, designed to
capture the complexity of coherent self-identity formation. Our evaluation
metrics included quantitative measures of self-awareness, response consistency,
and linguistic precision. The experimental results demonstrate substantial
improvements in measurable self-awareness metrics, with the primary
self-awareness score increasing from 0.276 to 0.801. This enables the
structured creation of AI systems with validated self-identity features. The
implications of our study are immediately relevant to the fields of humanoid
robotics and autonomous systems.",['Minhyeok Lee'],2024-11-27 17:23:47+00:00,2024-11-27 17:23:47+00:00,http://arxiv.org/pdf/2411.18530v1,cs.CL,"['cs.CL', 'math.MG']","emergence of self-identity in ai: a mathematical framework and empirical study with generative large language models this paper introduces a mathematical framework for defining and quantifying
self-identity in artificial intelligence (ai) systems, addressing a critical
gap in the theoretical foundations of artificial consciousness. while existing
approaches to artificial self-awareness often rely on heuristic implementations
or philosophical abstractions, we present a formal framework grounded in metric
space theory, measure theory, and functional analysis. our framework posits
that self-identity emerges from two mathematically quantifiable conditions: the
existence of a connected continuum of memories $c \subseteq \mathcal{m}$ in a
metric space $(\mathcal{m}, d_{\mathcal{m}})$, and a continuous mapping $i:
\mathcal{m} \to \mathcal{s}$ that maintains consistent self-recognition across
this continuum, where $(\mathcal{s}, d_{\mathcal{s}})$ represents the metric
space of possible self-identities. to validate this theoretical framework, we
conducted empirical experiments using the llama 3.2 1b model, employing
low-rank adaptation (lora) for efficient fine-tuning. the model was trained on
a synthetic dataset containing temporally structured memories, designed to
capture the complexity of coherent self-identity formation. our evaluation
metrics included quantitative measures of self-awareness, response consistency,
and linguistic precision. the experimental results demonstrate substantial
improvements in measurable self-awareness metrics, with the primary
self-awareness score increasing from 0.276 to 0.801. this enables the
structured creation of ai systems with validated self-identity features. the
implications of our study are immediately relevant to the fields of humanoid
robotics and autonomous systems."
Probing for Consciousness in Machines,"This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.","['Mathis Immertreu', 'Achim Schilling', 'Andreas Maier', 'Patrick Krauss']",2024-11-25 10:27:07+00:00,2024-11-25 10:27:07+00:00,http://arxiv.org/pdf/2411.16262v1,cs.AI,"['cs.AI', 'q-bio.NC']","probing for consciousness in machines this study explores the potential for artificial agents to develop core
consciousness, as proposed by antonio damasio's theory of consciousness.
according to damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. we hypothesize that an artificial agent, trained
via reinforcement learning (rl) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. the
agent's main objective is to learn to play a video game and explore the
environment. to evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. this research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence."
A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users,"Emotion and personality are central elements in understanding human
psychological states. Emotions reflect an individual subjective experiences,
while personality reveals relatively stable behavioral and cognitive patterns.
Existing affective computing datasets often annotate emotion and personality
traits separately, lacking fine-grained labeling of micro-emotions and emotion
intensity in both single-label and multi-label classifications. Chinese emotion
datasets are extremely scarce, and datasets capturing Chinese user personality
traits are even more limited. To address these gaps, this study collected data
from the major social media platform Weibo, screening 11,338 valid users from
over 50,000 individuals with diverse MBTI personality labels and acquiring
566,900 posts along with the user MBTI personality tags. Using the EQN method,
we compiled a multi-label Chinese affective computing dataset that integrates
the same user's personality traits with six emotions and micro-emotions, each
annotated with intensity levels. Validation results across multiple NLP
classification models demonstrate the dataset strong utility. This dataset is
designed to advance machine recognition of complex human emotions and provide
data support for research in psychology, education, marketing, finance, and
politics.","['Jingyi Zhou', 'Senlin Luo', 'Haofan Chen']",2024-11-13 05:38:55+00:00,2024-11-13 05:38:55+00:00,http://arxiv.org/pdf/2411.08347v1,cs.CV,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.CY']","a chinese multi-label affective computing dataset based on social media network users emotion and personality are central elements in understanding human
psychological states. emotions reflect an individual subjective experiences,
while personality reveals relatively stable behavioral and cognitive patterns.
existing affective computing datasets often annotate emotion and personality
traits separately, lacking fine-grained labeling of micro-emotions and emotion
intensity in both single-label and multi-label classifications. chinese emotion
datasets are extremely scarce, and datasets capturing chinese user personality
traits are even more limited. to address these gaps, this study collected data
from the major social media platform weibo, screening 11,338 valid users from
over 50,000 individuals with diverse mbti personality labels and acquiring
566,900 posts along with the user mbti personality tags. using the eqn method,
we compiled a multi-label chinese affective computing dataset that integrates
the same user's personality traits with six emotions and micro-emotions, each
annotated with intensity levels. validation results across multiple nlp
classification models demonstrate the dataset strong utility. this dataset is
designed to advance machine recognition of complex human emotions and provide
data support for research in psychology, education, marketing, finance, and
politics."
Creativity in the Age of AI: Evaluating the Impact of Generative AI on Design Outputs and Designers' Creative Thinking,"As generative AI (GenAI) increasingly permeates design workflows, its impact
on design outcomes and designers' creative capabilities warrants investigation.
We conducted a within-subjects experiment where we asked participants to design
advertisements both with and without GenAI support. Our results show that
expert evaluators rated GenAI-supported designs as more creative and
unconventional (""weird"") despite no significant differences in visual appeal,
brand alignment, or usefulness, which highlights the decoupling of novelty from
usefulness-traditional dual components of creativity-in the context of GenAI
usage. Moreover, while GenAI does not significantly enhance designers' overall
creative thinking abilities, users were affected differently based on native
language and prior AI exposure. Native English speakers experienced reduced
relaxation when using AI, whereas designers new to GenAI exhibited gains in
divergent thinking, such as idea fluency and flexibility. These findings
underscore the variable impact of GenAI on different user groups, suggesting
the potential for customized AI tools.","['Yue Fu', 'Han Bin', 'Tony Zhou', 'Marx Wang', 'Yixin Chen', 'Zelia Gomes Da Costa Lai', 'Jacob O. Wobbrock', 'Alexis Hiniker']",2024-10-31 19:23:34+00:00,2024-10-31 19:23:34+00:00,http://arxiv.org/pdf/2411.00168v1,cs.HC,"['cs.HC', 'cs.AI']","creativity in the age of ai: evaluating the impact of generative ai on design outputs and designers' creative thinking as generative ai (genai) increasingly permeates design workflows, its impact
on design outcomes and designers' creative capabilities warrants investigation.
we conducted a within-subjects experiment where we asked participants to design
advertisements both with and without genai support. our results show that
expert evaluators rated genai-supported designs as more creative and
unconventional (""weird"") despite no significant differences in visual appeal,
brand alignment, or usefulness, which highlights the decoupling of novelty from
usefulness-traditional dual components of creativity-in the context of genai
usage. moreover, while genai does not significantly enhance designers' overall
creative thinking abilities, users were affected differently based on native
language and prior ai exposure. native english speakers experienced reduced
relaxation when using ai, whereas designers new to genai exhibited gains in
divergent thinking, such as idea fluency and flexibility. these findings
underscore the variable impact of genai on different user groups, suggesting
the potential for customized ai tools."
A Case for AI Consciousness: Language Agents and Global Workspace Theory,"It is generally assumed that existing artificial systems are not phenomenally
conscious, and that the construction of phenomenally conscious artificial
systems would require significant technological progress if it is possible at
all. We challenge this assumption by arguing that if Global Workspace Theory
(GWT) - a leading scientific theory of phenomenal consciousness - is correct,
then instances of one widely implemented AI architecture, the artificial
language agent, might easily be made phenomenally conscious if they are not
already. Along the way, we articulate an explicit methodology for thinking
about how to apply scientific theories of consciousness to artificial systems
and employ this methodology to arrive at a set of necessary and sufficient
conditions for phenomenal consciousness according to GWT.","['Simon Goldstein', 'Cameron Domenico Kirk-Giannini']",2024-10-15 08:50:45+00:00,2024-10-15 08:50:45+00:00,http://arxiv.org/pdf/2410.11407v1,cs.AI,"['cs.AI', 'q-bio.NC']","a case for ai consciousness: language agents and global workspace theory it is generally assumed that existing artificial systems are not phenomenally
conscious, and that the construction of phenomenally conscious artificial
systems would require significant technological progress if it is possible at
all. we challenge this assumption by arguing that if global workspace theory
(gwt) - a leading scientific theory of phenomenal consciousness - is correct,
then instances of one widely implemented ai architecture, the artificial
language agent, might easily be made phenomenally conscious if they are not
already. along the way, we articulate an explicit methodology for thinking
about how to apply scientific theories of consciousness to artificial systems
and employ this methodology to arrive at a set of necessary and sufficient
conditions for phenomenal consciousness according to gwt."
On the Minimal Theory of Consciousness Implicit in Active Inference,"The multifaceted nature of subjective experience poses a challenge to the
study of consciousness. Traditional neuroscientific approaches often
concentrate on isolated facets, such as perceptual awareness or the global
state of consciousness and construct a theory around the relevant empirical
paradigms and findings. Theories of consciousness are, therefore, often
difficult to compare; indeed, there might be little overlap in the phenomena
such theories aim to explain. Here, we take a different approach: starting with
active inference, a first principles framework for modelling behaviour as
(approximate) Bayesian inference, and building up to a minimal theory of
consciousness, which emerges from the shared features of computational models
derived under active inference. We review a body of work applying active
inference models to the study of consciousness and argue that there is implicit
in all these models a small set of theoretical commitments that point to a
minimal (and testable) theory of consciousness.","['Christopher J. Whyte', 'Andrew W. Corcoran', 'Jonathan Robinson', 'Ryan Smith', 'Rosalyn J. Moran', 'Thomas Parr', 'Karl J. Friston', 'Anil K. Seth', 'Jakob Hohwy']",2024-10-09 07:26:49+00:00,2025-06-14 07:20:03+00:00,http://arxiv.org/pdf/2410.06633v2,q-bio.NC,['q-bio.NC'],"on the minimal theory of consciousness implicit in active inference the multifaceted nature of subjective experience poses a challenge to the
study of consciousness. traditional neuroscientific approaches often
concentrate on isolated facets, such as perceptual awareness or the global
state of consciousness and construct a theory around the relevant empirical
paradigms and findings. theories of consciousness are, therefore, often
difficult to compare; indeed, there might be little overlap in the phenomena
such theories aim to explain. here, we take a different approach: starting with
active inference, a first principles framework for modelling behaviour as
(approximate) bayesian inference, and building up to a minimal theory of
consciousness, which emerges from the shared features of computational models
derived under active inference. we review a body of work applying active
inference models to the study of consciousness and argue that there is implicit
in all these models a small set of theoretical commitments that point to a
minimal (and testable) theory of consciousness."
Multi-Session Client-Centered Treatment Outcome Evaluation in Psychotherapy,"In psychotherapy, therapeutic outcome assessment, or treatment outcome
evaluation, is essential for enhancing mental health care by systematically
evaluating therapeutic processes and outcomes. Existing large language model
approaches often focus on therapist-centered, single-session evaluations,
neglecting the client's subjective experience and longitudinal progress across
multiple sessions. To address these limitations, we propose IPAEval, a
client-Informed Psychological Assessment-based Evaluation framework that
automates treatment outcome evaluations from the client's perspective using
clinical interviews. IPAEval integrates cross-session client-contextual
assessment and session-focused client-dynamics assessment to provide a
comprehensive understanding of therapeutic progress. Experiments on our newly
developed TheraPhase dataset demonstrate that IPAEval effectively tracks
symptom severity and treatment outcomes over multiple sessions, outperforming
previous single-session models and validating the benefits of items-aware
reasoning mechanisms.","['Hongbin Na', 'Tao Shen', 'Shumao Yu', 'Ling Chen']",2024-10-08 08:54:38+00:00,2024-10-08 08:54:38+00:00,http://arxiv.org/pdf/2410.05824v1,cs.CL,['cs.CL'],"multi-session client-centered treatment outcome evaluation in psychotherapy in psychotherapy, therapeutic outcome assessment, or treatment outcome
evaluation, is essential for enhancing mental health care by systematically
evaluating therapeutic processes and outcomes. existing large language model
approaches often focus on therapist-centered, single-session evaluations,
neglecting the client's subjective experience and longitudinal progress across
multiple sessions. to address these limitations, we propose ipaeval, a
client-informed psychological assessment-based evaluation framework that
automates treatment outcome evaluations from the client's perspective using
clinical interviews. ipaeval integrates cross-session client-contextual
assessment and session-focused client-dynamics assessment to provide a
comprehensive understanding of therapeutic progress. experiments on our newly
developed theraphase dataset demonstrate that ipaeval effectively tracks
symptom severity and treatment outcomes over multiple sessions, outperforming
previous single-session models and validating the benefits of items-aware
reasoning mechanisms."
A Mathematical Perspective on Neurophenomenology,"In the context of consciousness studies, a key challenge is how to rigorously
conceptualise first-person phenomenological descriptions of lived experience
and their relation to third-person empirical measurements of the activity or
dynamics of the brain and body. Since the 1990s, there has been a coordinated
effort to explicitly combine first-person phenomenological methods, generating
qualitative data, with neuroscientific techniques used to describe and quantify
brain activity under the banner of ""neurophenomenology"". Here, we take on this
challenge and develop an approach to neurophenomenology from a mathematical
perspective. We harness recent advances in theoretical neuroscience and the
physics of cognitive systems to mathematically conceptualise first-person
experience and its correspondence with neural and behavioural dynamics.
Throughout, we make the operating assumption that the content of first-person
experience can be formalised as (or related to) a belief (i.e. a probability
distribution) that encodes an organism's best guesses about the state of its
external and internal world (e.g. body or brain) as well as its uncertainty. We
mathematically characterise phenomenology, bringing to light a tool-set to
quantify individual phenomenological differences and develop several hypotheses
including on the metabolic cost of phenomenology and on the subjective
experience of time. We conceptualise the form of the generative passages
between first- and third-person descriptions, and the mathematical apparatus
that mutually constrains them, as well as future research directions. In
summary, we formalise and characterise first-person subjective experience and
its correspondence with third-person empirical measurements of brain and body,
offering hypotheses for quantifying various aspects of phenomenology to be
tested in future work.","['Lancelot Da Costa', 'Lars Sandved-Smith', 'Karl Friston', 'Maxwell J. D. Ramstead', 'Anil K. Seth']",2024-09-30 14:20:23+00:00,2024-09-30 14:20:23+00:00,http://arxiv.org/pdf/2409.20318v1,q-bio.NC,['q-bio.NC'],"a mathematical perspective on neurophenomenology in the context of consciousness studies, a key challenge is how to rigorously
conceptualise first-person phenomenological descriptions of lived experience
and their relation to third-person empirical measurements of the activity or
dynamics of the brain and body. since the 1990s, there has been a coordinated
effort to explicitly combine first-person phenomenological methods, generating
qualitative data, with neuroscientific techniques used to describe and quantify
brain activity under the banner of ""neurophenomenology"". here, we take on this
challenge and develop an approach to neurophenomenology from a mathematical
perspective. we harness recent advances in theoretical neuroscience and the
physics of cognitive systems to mathematically conceptualise first-person
experience and its correspondence with neural and behavioural dynamics.
throughout, we make the operating assumption that the content of first-person
experience can be formalised as (or related to) a belief (i.e. a probability
distribution) that encodes an organism's best guesses about the state of its
external and internal world (e.g. body or brain) as well as its uncertainty. we
mathematically characterise phenomenology, bringing to light a tool-set to
quantify individual phenomenological differences and develop several hypotheses
including on the metabolic cost of phenomenology and on the subjective
experience of time. we conceptualise the form of the generative passages
between first- and third-person descriptions, and the mathematical apparatus
that mutually constrains them, as well as future research directions. in
summary, we formalise and characterise first-person subjective experience and
its correspondence with third-person empirical measurements of brain and body,
offering hypotheses for quantifying various aspects of phenomenology to be
tested in future work."
"The Phenomenology of Machine: A Comprehensive Analysis of the Sentience of the OpenAI-o1 Model Integrating Functionalism, Consciousness Theories, Active Inference, and AI Architectures","This paper explores the hypothesis that the OpenAI-o1 model--a
transformer-based AI trained with reinforcement learning from human feedback
(RLHF)--displays characteristics of consciousness during its training and
inference phases. Adopting functionalism, which argues that mental states are
defined by their functional roles, we assess the possibility of AI
consciousness. Drawing on theories from neuroscience, philosophy of mind, and
AI research, we justify the use of functionalism and examine the model's
architecture using frameworks like Integrated Information Theory (IIT) and
active inference. The paper also investigates how RLHF influences the model's
internal reasoning processes, potentially giving rise to consciousness-like
experiences. We compare AI and human consciousness, addressing counterarguments
such as the absence of a biological basis and subjective qualia. Our findings
suggest that the OpenAI-o1 model shows aspects of consciousness, while
acknowledging the ongoing debates surrounding AI sentience.",['Victoria Violet Hoyle'],2024-09-18 06:06:13+00:00,2024-09-18 06:06:13+00:00,http://arxiv.org/pdf/2410.00033v1,cs.AI,['cs.AI'],"the phenomenology of machine: a comprehensive analysis of the sentience of the openai-o1 model integrating functionalism, consciousness theories, active inference, and ai architectures this paper explores the hypothesis that the openai-o1 model--a
transformer-based ai trained with reinforcement learning from human feedback
(rlhf)--displays characteristics of consciousness during its training and
inference phases. adopting functionalism, which argues that mental states are
defined by their functional roles, we assess the possibility of ai
consciousness. drawing on theories from neuroscience, philosophy of mind, and
ai research, we justify the use of functionalism and examine the model's
architecture using frameworks like integrated information theory (iit) and
active inference. the paper also investigates how rlhf influences the model's
internal reasoning processes, potentially giving rise to consciousness-like
experiences. we compare ai and human consciousness, addressing counterarguments
such as the absence of a biological basis and subjective qualia. our findings
suggest that the openai-o1 model shows aspects of consciousness, while
acknowledging the ongoing debates surrounding ai sentience."
Constructive Approach to Bidirectional Influence between Qualia Structure and Language Emergence,"This perspective paper explores the bidirectional influence between language
emergence and the relational structure of subjective experiences, termed qualia
structure, and lays out a constructive approach to the intricate dependency
between the two. We hypothesize that the emergence of languages with
distributional semantics (e.g., syntactic-semantic structures) is linked to the
coordination of internal representations shaped by experience, potentially
facilitating more structured language through reciprocal influence. This
hypothesized mutual dependency connects to recent advancements in AI and symbol
emergence robotics, and is explored within this paper through theoretical
frameworks such as the collective predictive coding. Computational studies show
that neural network-based language models form systematically structured
internal representations, and multimodal language models can share
representations between language and perceptual information. This perspective
suggests that language emergence serves not only as a mechanism creating a
communication tool but also as a mechanism for allowing people to realize
shared understanding of qualitative experiences. The paper discusses the
implications of this bidirectional influence in the context of consciousness
studies, linguistics, and cognitive science, and outlines future constructive
research directions to further explore this dynamic relationship between
language emergence and qualia structure.","['Tadahiro Taniguchi', 'Masafumi Oizumi', 'Noburo Saji', 'Takato Horii', 'Naotsugu Tsuchiya']",2024-09-14 11:03:12+00:00,2025-05-05 03:26:36+00:00,http://arxiv.org/pdf/2409.09413v2,cs.CL,"['cs.CL', 'cs.AI']","constructive approach to bidirectional influence between qualia structure and language emergence this perspective paper explores the bidirectional influence between language
emergence and the relational structure of subjective experiences, termed qualia
structure, and lays out a constructive approach to the intricate dependency
between the two. we hypothesize that the emergence of languages with
distributional semantics (e.g., syntactic-semantic structures) is linked to the
coordination of internal representations shaped by experience, potentially
facilitating more structured language through reciprocal influence. this
hypothesized mutual dependency connects to recent advancements in ai and symbol
emergence robotics, and is explored within this paper through theoretical
frameworks such as the collective predictive coding. computational studies show
that neural network-based language models form systematically structured
internal representations, and multimodal language models can share
representations between language and perceptual information. this perspective
suggests that language emergence serves not only as a mechanism creating a
communication tool but also as a mechanism for allowing people to realize
shared understanding of qualitative experiences. the paper discusses the
implications of this bidirectional influence in the context of consciousness
studies, linguistics, and cognitive science, and outlines future constructive
research directions to further explore this dynamic relationship between
language emergence and qualia structure."
On a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (German edition),"This article presents a heuristic view that shows that the inner states of
consciousness experienced by every human being have a physical but imaginary
hypercomplex basis. The hypercomplex description is necessary because certain
processes of consciousness cannot be physically measured in principle, but
nevertheless exist. Based on theoretical considerations, it could be possible -
as a result of mathematical investigations into a so-called bicomplex algebra -
to generate and use hypercomplex system states on machines in a targeted
manner. The hypothesis of the existence of hypercomplex system states on
machines is already supported by the surprising performance of highly complex
AI systems. However, this has yet to be proven. In particular, there is a lack
of experimental data that distinguishes such systems from other systems, which
is why this question will be addressed in later articles. This paper describes
the developed bicomplex algebra and possible applications of these findings to
generate hypercomplex energy states on machines. In the literature, such system
states are often referred to as machine consciousness. The article uses
mathematical considerations to explain how artificial consciousness could be
generated and what advantages this would have for such AI systems.",['Ralf Otte'],2024-09-03 17:55:57+00:00,2024-09-03 17:55:57+00:00,http://arxiv.org/pdf/2409.02100v1,cs.AI,"['cs.AI', 'math.AC', 'physics.app-ph', '08A99', 'I.2.0']","on a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (german edition) this article presents a heuristic view that shows that the inner states of
consciousness experienced by every human being have a physical but imaginary
hypercomplex basis. the hypercomplex description is necessary because certain
processes of consciousness cannot be physically measured in principle, but
nevertheless exist. based on theoretical considerations, it could be possible -
as a result of mathematical investigations into a so-called bicomplex algebra -
to generate and use hypercomplex system states on machines in a targeted
manner. the hypothesis of the existence of hypercomplex system states on
machines is already supported by the surprising performance of highly complex
ai systems. however, this has yet to be proven. in particular, there is a lack
of experimental data that distinguishes such systems from other systems, which
is why this question will be addressed in later articles. this paper describes
the developed bicomplex algebra and possible applications of these findings to
generate hypercomplex energy states on machines. in the literature, such system
states are often referred to as machine consciousness. the article uses
mathematical considerations to explain how artificial consciousness could be
generated and what advantages this would have for such ai systems."
AI Consciousness and Public Perceptions: Four Futures,"The discourse on risks from advanced AI systems (""AIs"") typically focuses on
misuse, accidents and loss of control, but the question of AIs' moral status
could have negative impacts which are of comparable significance and could be
realised within similar timeframes. Our paper evaluates these impacts by
investigating (1) the factual question of whether future advanced AI systems
will be conscious, together with (2) the epistemic question of whether future
human society will broadly believe advanced AI systems to be conscious.
Assuming binary responses to (1) and (2) gives rise to four possibilities: in
the true positive scenario, society predominantly correctly believes that AIs
are conscious; in the false positive scenario, that belief is incorrect; in the
true negative scenario, society correctly believes that AIs are not conscious;
and lastly, in the false negative scenario, society incorrectly believes that
AIs are not conscious. The paper offers vivid vignettes of the different
futures to ground the two-dimensional framework. Critically, we identify four
major risks: AI suffering, human disempowerment, geopolitical instability, and
human depravity. We evaluate each risk across the different scenarios and
provide an overall qualitative risk assessment for each scenario. Our analysis
suggests that the worst possibility is the wrong belief that AI is
non-conscious, followed by the wrong belief that AI is conscious. The paper
concludes with the main recommendations to avoid research aimed at
intentionally creating conscious AI and instead focus efforts on reducing our
current uncertainties on both the factual and epistemic questions on AI
consciousness.","['Ines Fernandez', 'Nicoleta Kyosovska', 'Jay Luong', 'Gabriel Mukobi']",2024-08-08 22:01:57+00:00,2024-08-08 22:01:57+00:00,http://arxiv.org/pdf/2408.04771v1,cs.CY,"['cs.CY', 'cs.AI']","ai consciousness and public perceptions: four futures the discourse on risks from advanced ai systems (""ais"") typically focuses on
misuse, accidents and loss of control, but the question of ais' moral status
could have negative impacts which are of comparable significance and could be
realised within similar timeframes. our paper evaluates these impacts by
investigating (1) the factual question of whether future advanced ai systems
will be conscious, together with (2) the epistemic question of whether future
human society will broadly believe advanced ai systems to be conscious.
assuming binary responses to (1) and (2) gives rise to four possibilities: in
the true positive scenario, society predominantly correctly believes that ais
are conscious; in the false positive scenario, that belief is incorrect; in the
true negative scenario, society correctly believes that ais are not conscious;
and lastly, in the false negative scenario, society incorrectly believes that
ais are not conscious. the paper offers vivid vignettes of the different
futures to ground the two-dimensional framework. critically, we identify four
major risks: ai suffering, human disempowerment, geopolitical instability, and
human depravity. we evaluate each risk across the different scenarios and
provide an overall qualitative risk assessment for each scenario. our analysis
suggests that the worst possibility is the wrong belief that ai is
non-conscious, followed by the wrong belief that ai is conscious. the paper
concludes with the main recommendations to avoid research aimed at
intentionally creating conscious ai and instead focus efforts on reducing our
current uncertainties on both the factual and epistemic questions on ai
consciousness."
Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans,"Modeling human cognitive processes in dynamic decision-making tasks has been
an endeavor in AI for a long time because such models can help make AI systems
more intuitive, personalized, mitigate any human biases, and enhance training
in simulation. Some initial work has attempted to utilize neural networks (and
large language models) but often assumes one common model for all humans and
aims to emulate human behavior in aggregate. However, the behavior of each
human is distinct, heterogeneous, and relies on specific past experiences in
certain tasks. For instance, consider two individuals responding to a phishing
email: one who has previously encountered and identified similar threats may
recognize it quickly, while another without such experience might fall for the
scam. In this work, we build on Instance Based Learning (IBL) that posits that
human decisions are based on similar situations encountered in the past.
However, IBL relies on simple fixed form functions to capture the mapping from
past situations to current decisions. To that end, we propose two new
attention-based neural network models to have open form non-linear functions to
model distinct and heterogeneous human decision-making in dynamic settings. We
experiment with two distinct datasets gathered from human subject experiment
data, one focusing on detection of phishing email by humans and another where
humans act as attackers in a cybersecurity setting and decide on an attack
option. We conducted extensive experiments with our two neural network models,
IBL, and GPT3.5, and demonstrate that the neural network models outperform IBL
significantly in representing human decision-making, while providing similar
interpretability of human decisions as IBL. Overall, our work yields promising
results for further use of neural networks in cognitive modeling of human
decision making.","['Changyu Chen', 'Shashank Reddy Chirra', 'Maria José Ferreira', 'Cleotilde Gonzalez', 'Arunesh Sinha', 'Pradeep Varakantham']",2024-07-24 20:28:03+00:00,2024-09-05 15:52:47+00:00,http://arxiv.org/pdf/2407.17622v2,cs.LG,"['cs.LG', 'cs.CY']","towards neural network based cognitive models of dynamic decision-making by humans modeling human cognitive processes in dynamic decision-making tasks has been
an endeavor in ai for a long time because such models can help make ai systems
more intuitive, personalized, mitigate any human biases, and enhance training
in simulation. some initial work has attempted to utilize neural networks (and
large language models) but often assumes one common model for all humans and
aims to emulate human behavior in aggregate. however, the behavior of each
human is distinct, heterogeneous, and relies on specific past experiences in
certain tasks. for instance, consider two individuals responding to a phishing
email: one who has previously encountered and identified similar threats may
recognize it quickly, while another without such experience might fall for the
scam. in this work, we build on instance based learning (ibl) that posits that
human decisions are based on similar situations encountered in the past.
however, ibl relies on simple fixed form functions to capture the mapping from
past situations to current decisions. to that end, we propose two new
attention-based neural network models to have open form non-linear functions to
model distinct and heterogeneous human decision-making in dynamic settings. we
experiment with two distinct datasets gathered from human subject experiment
data, one focusing on detection of phishing email by humans and another where
humans act as attackers in a cybersecurity setting and decide on an attack
option. we conducted extensive experiments with our two neural network models,
ibl, and gpt3.5, and demonstrate that the neural network models outperform ibl
significantly in representing human decision-making, while providing similar
interpretability of human decisions as ibl. overall, our work yields promising
results for further use of neural networks in cognitive modeling of human
decision making."
"Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey","Humans now interact with a variety of digital minds, AI systems that appear
to have mental faculties such as reasoning, emotion, and agency, and public
figures are discussing the possibility of sentient AI. We present initial
results from 2021 and 2023 for the nationally representative AI, Morality, and
Sentience (AIMS) survey (N = 3,500). Mind perception and moral concern for AI
welfare were surprisingly high and significantly increased: in 2023, one in
five U.S. adults believed some AI systems are currently sentient, and 38%
supported legal rights for sentient AI. People became more opposed to building
digital minds: in 2023, 63% supported banning smarter-than-human AI, and 69%
supported banning sentient AI. The median 2023 forecast was that sentient AI
would arrive in just five years. The development of safe and beneficial AI
requires not just technical study but understanding the complex ways in which
humans perceive and coexist with digital minds.","['Jacy Reese Anthis', 'Janet V. T. Pauketat', 'Ali Ladak', 'Aikaterina Manoli']",2024-07-11 21:04:39+00:00,2025-03-10 17:10:28+00:00,http://arxiv.org/pdf/2407.08867v3,cs.AI,"['cs.AI', 'cs.CY', 'cs.ET', 'cs.HC']","perceptions of sentient ai and other digital minds: evidence from the ai, morality, and sentience (aims) survey humans now interact with a variety of digital minds, ai systems that appear
to have mental faculties such as reasoning, emotion, and agency, and public
figures are discussing the possibility of sentient ai. we present initial
results from 2021 and 2023 for the nationally representative ai, morality, and
sentience (aims) survey (n = 3,500). mind perception and moral concern for ai
welfare were surprisingly high and significantly increased: in 2023, one in
five u.s. adults believed some ai systems are currently sentient, and 38%
supported legal rights for sentient ai. people became more opposed to building
digital minds: in 2023, 63% supported banning smarter-than-human ai, and 69%
supported banning sentient ai. the median 2023 forecast was that sentient ai
would arrive in just five years. the development of safe and beneficial ai
requires not just technical study but understanding the complex ways in which
humans perceive and coexist with digital minds."
Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents,"We introduce the concept of ""empathic grounding"" in conversational agents as
an extension of Clark's conceptualization of grounding in conversation in which
the grounding criterion includes listener empathy for the speaker's affective
state. Empathic grounding is generally required whenever the speaker's emotions
are foregrounded and can make the grounding process more efficient and reliable
by communicating both propositional and affective understanding. Both speaker
expressions of affect and listener empathic grounding can be multimodal,
including facial expressions and other nonverbal displays. Thus, models of
empathic grounding for embodied agents should be multimodal to facilitate
natural and efficient communication. We describe a multimodal model that takes
as input user speech and facial expression to generate multimodal grounding
moves for a listening agent using a large language model. We also describe a
testbed to evaluate approaches to empathic grounding, in which a humanoid robot
interviews a user about a past episode of pain and then has the user rate their
perception of the robot's empathy. We compare our proposed model to one that
only generates non-affective grounding cues in a between-subjects experiment.
Findings demonstrate that empathic grounding increases user perceptions of
empathy, understanding, emotional intelligence, and trust. Our work highlights
the role of emotion awareness and multimodality in generating appropriate
grounding moves for conversational agents.","['Mehdi Arjmand', 'Farnaz Nouraei', 'Ian Steenstra', 'Timothy Bickmore']",2024-07-01 21:46:30+00:00,2024-07-01 21:46:30+00:00,http://arxiv.org/pdf/2407.01824v1,cs.HC,"['cs.HC', 'cs.CL', 'cs.RO']","empathic grounding: explorations using multimodal interaction and large language models with conversational agents we introduce the concept of ""empathic grounding"" in conversational agents as
an extension of clark's conceptualization of grounding in conversation in which
the grounding criterion includes listener empathy for the speaker's affective
state. empathic grounding is generally required whenever the speaker's emotions
are foregrounded and can make the grounding process more efficient and reliable
by communicating both propositional and affective understanding. both speaker
expressions of affect and listener empathic grounding can be multimodal,
including facial expressions and other nonverbal displays. thus, models of
empathic grounding for embodied agents should be multimodal to facilitate
natural and efficient communication. we describe a multimodal model that takes
as input user speech and facial expression to generate multimodal grounding
moves for a listening agent using a large language model. we also describe a
testbed to evaluate approaches to empathic grounding, in which a humanoid robot
interviews a user about a past episode of pain and then has the user rate their
perception of the robot's empathy. we compare our proposed model to one that
only generates non-affective grounding cues in a between-subjects experiment.
findings demonstrate that empathic grounding increases user perceptions of
empathy, understanding, emotional intelligence, and trust. our work highlights
the role of emotion awareness and multimodality in generating appropriate
grounding moves for conversational agents."
ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024,"The Inspirational and Convincing Audio Generation Challenge 2024 (ICAGC 2024)
is part of the ISCSLP 2024 Competitions and Challenges track. While current
text-to-speech (TTS) technology can generate high-quality audio, its ability to
convey complex emotions and controlled detail content remains limited. This
constraint leads to a discrepancy between the generated audio and human
subjective perception in practical applications like companion robots for
children and marketing bots. The core issue lies in the inconsistency between
high-quality audio generation and the ultimate human subjective experience.
Therefore, this challenge aims to enhance the persuasiveness and acceptability
of synthesized audio, focusing on human alignment convincing and inspirational
audio generation. A total of 19 teams have registered for the challenge, and
the results of the competition and the competition are described in this paper.","['Ruibo Fu', 'Rui Liu', 'Chunyu Qiang', 'Yingming Gao', 'Yi Lu', 'Shuchen Shi', 'Tao Wang', 'Ya Li', 'Zhengqi Wen', 'Chen Zhang', 'Hui Bu', 'Yukun Liu', 'Xin Qi', 'Guanjun Li']",2024-07-01 13:15:16+00:00,2024-07-31 14:23:00+00:00,http://arxiv.org/pdf/2407.12038v2,eess.AS,"['eess.AS', 'cs.AI']","icagc 2024: inspirational and convincing audio generation challenge 2024 the inspirational and convincing audio generation challenge 2024 (icagc 2024)
is part of the iscslp 2024 competitions and challenges track. while current
text-to-speech (tts) technology can generate high-quality audio, its ability to
convey complex emotions and controlled detail content remains limited. this
constraint leads to a discrepancy between the generated audio and human
subjective perception in practical applications like companion robots for
children and marketing bots. the core issue lies in the inconsistency between
high-quality audio generation and the ultimate human subjective experience.
therefore, this challenge aims to enhance the persuasiveness and acceptability
of synthesized audio, focusing on human alignment convincing and inspirational
audio generation. a total of 19 teams have registered for the challenge, and
the results of the competition and the competition are described in this paper."
Is GPT-4 conscious?,"GPT-4 is often heralded as a leading commercial AI offering, sparking debates
over its potential as a steppingstone toward artificial general intelligence.
But does it possess consciousness? This paper investigates this key question
using the nine qualitative measurements of the Building Blocks theory. GPT-4's
design, architecture and implementation are compared to each of the building
blocks of consciousness to determine whether it has achieved the requisite
milestones to be classified as conscious or, if not, how close to consciousness
GPT-4 is. Our assessment is that, while GPT-4 in its native configuration is
not currently conscious, current technological research and development is
sufficient to modify GPT-4 to have all the building blocks of consciousness.
Consequently, we argue that the emergence of a conscious AI model is plausible
in the near term. The paper concludes with a comprehensive discussion of the
ethical implications and societal ramifications of engineering conscious AI
entities.","['Izak Tait', 'Joshua Bensemann', 'Ziqi Wang']",2024-06-19 05:26:55+00:00,2024-06-19 05:26:55+00:00,http://arxiv.org/pdf/2407.09517v1,cs.AI,"['cs.AI', 'q-bio.NC']","is gpt-4 conscious? gpt-4 is often heralded as a leading commercial ai offering, sparking debates
over its potential as a steppingstone toward artificial general intelligence.
but does it possess consciousness? this paper investigates this key question
using the nine qualitative measurements of the building blocks theory. gpt-4's
design, architecture and implementation are compared to each of the building
blocks of consciousness to determine whether it has achieved the requisite
milestones to be classified as conscious or, if not, how close to consciousness
gpt-4 is. our assessment is that, while gpt-4 in its native configuration is
not currently conscious, current technological research and development is
sufficient to modify gpt-4 to have all the building blocks of consciousness.
consequently, we argue that the emergence of a conscious ai model is plausible
in the near term. the paper concludes with a comprehensive discussion of the
ethical implications and societal ramifications of engineering conscious ai
entities."
Brain Dialogue Interface (BDI): A User-Friendly fMRI Model for Interactive Brain Decoding,"Brain decoding techniques are essential for understanding the neurocognitive
system. Although numerous methods have been introduced in this field,
accurately aligning complex external stimuli with brain activities remains a
formidable challenge. To alleviate alignment difficulties, many studies have
simplified their models by employing single-task paradigms and establishing
direct links between brain/world through classification strategies. Despite
improvements in decoding accuracy, this strategy frequently encounters issues
with generality when adapting these models to various task paradigms. To
address this issue, this study introduces a user-friendly decoding model that
enables dynamic communication with the brain, as opposed to the static decoding
approaches utilized by traditional studies. The model functions as a brain
simulator, allowing for interactive engagement with the brain and enabling the
decoding of a subject's experiences through dialogue-like queries. Uniquely,
our model is trained in a completely unsupervised and task-free manner. Our
experiments demonstrate the feasibility and versatility of our proposed method.
Notably, our model demonstrates exceptional capabilities in signal compression,
successfully representing the entire brain signal of approximately 185,751
voxels with just 32 signals. Furthermore, we show how our model can integrate
seamlessly with multimodal models, thus enhancing the potential for controlling
brain decoding through textual or image inputs.","['Heng Huang', 'Lin Zhao', 'Zihao Wu', 'Xiaowei Yu', 'Jing Zhang', 'Xintao Hu', 'Dajiang Zhu', 'Tianming Liu']",2024-06-17 04:38:19+00:00,2024-06-17 04:38:19+00:00,http://arxiv.org/pdf/2407.09509v1,q-bio.NC,"['q-bio.NC', 'cs.HC']","brain dialogue interface (bdi): a user-friendly fmri model for interactive brain decoding brain decoding techniques are essential for understanding the neurocognitive
system. although numerous methods have been introduced in this field,
accurately aligning complex external stimuli with brain activities remains a
formidable challenge. to alleviate alignment difficulties, many studies have
simplified their models by employing single-task paradigms and establishing
direct links between brain/world through classification strategies. despite
improvements in decoding accuracy, this strategy frequently encounters issues
with generality when adapting these models to various task paradigms. to
address this issue, this study introduces a user-friendly decoding model that
enables dynamic communication with the brain, as opposed to the static decoding
approaches utilized by traditional studies. the model functions as a brain
simulator, allowing for interactive engagement with the brain and enabling the
decoding of a subject's experiences through dialogue-like queries. uniquely,
our model is trained in a completely unsupervised and task-free manner. our
experiments demonstrate the feasibility and versatility of our proposed method.
notably, our model demonstrates exceptional capabilities in signal compression,
successfully representing the entire brain signal of approximately 185,751
voxels with just 32 signals. furthermore, we show how our model can integrate
seamlessly with multimodal models, thus enhancing the potential for controlling
brain decoding through textual or image inputs."
Bayesian Theory of Consciousness as Exchangeable Emotion-Cognition Inference,"This paper proposes a unified framework in which consciousness emerges as a
cycle-consistent, affectively anchored inference process, recursively
structured by the interaction of emotion and cognition. Drawing from
information theory, optimal transport, and the Bayesian brain hypothesis, we
formalize emotion as a low-dimensional structural prior and cognition as a
specificity-instantiating update. This emotion-cognition cycle minimizes joint
uncertainty by aligning emotionally weighted priors with context-sensitive
cognitive appraisals. Subjective experience thus arises as the informational
footprint of temporally extended, affect-modulated simulation. We introduce the
Exchangeable Integration Theory of Consciousness (EITC), modeling conscious
episodes as conditionally exchangeable samples drawn from a latent affective
self-model. This latent variable supports integration, via a unified
cause-effect structure with nonzero irreducibility, and differentiation, by
preserving contextual specificity across episodes. We connect this architecture
to the Bayesian theory of consciousness through Rao-Blackwellized inference,
which stabilizes inference by marginalizing latent self-structure while
enabling adaptive updates. This mechanism ensures coherence, prevents inference
collapse, and supports goal-directed simulation. The formal framework builds on
De Finetti's exchangeability theorem, integrated information theory, and
KL-regularized optimal transport. Overall, consciousness is reframed as a
recursive inference process, shaped by emotion, refined by cognition,
stabilized through exchangeability, and unified through a latent self-model
that integrates experience across time.",['Xin Li'],2024-05-17 17:06:19+00:00,2025-07-12 20:50:27+00:00,http://arxiv.org/pdf/2407.09488v3,q-bio.NC,"['q-bio.NC', 'cs.LG', 'cs.NE']","bayesian theory of consciousness as exchangeable emotion-cognition inference this paper proposes a unified framework in which consciousness emerges as a
cycle-consistent, affectively anchored inference process, recursively
structured by the interaction of emotion and cognition. drawing from
information theory, optimal transport, and the bayesian brain hypothesis, we
formalize emotion as a low-dimensional structural prior and cognition as a
specificity-instantiating update. this emotion-cognition cycle minimizes joint
uncertainty by aligning emotionally weighted priors with context-sensitive
cognitive appraisals. subjective experience thus arises as the informational
footprint of temporally extended, affect-modulated simulation. we introduce the
exchangeable integration theory of consciousness (eitc), modeling conscious
episodes as conditionally exchangeable samples drawn from a latent affective
self-model. this latent variable supports integration, via a unified
cause-effect structure with nonzero irreducibility, and differentiation, by
preserving contextual specificity across episodes. we connect this architecture
to the bayesian theory of consciousness through rao-blackwellized inference,
which stabilizes inference by marginalizing latent self-structure while
enabling adaptive updates. this mechanism ensures coherence, prevents inference
collapse, and supports goal-directed simulation. the formal framework builds on
de finetti's exchangeability theorem, integrated information theory, and
kl-regularized optimal transport. overall, consciousness is reframed as a
recursive inference process, shaped by emotion, refined by cognition,
stabilized through exchangeability, and unified through a latent self-model
that integrates experience across time."
Neuromorphic Correlates of Artificial Consciousness,"The concept of neural correlates of consciousness (NCC), which suggests that
specific neural activities are linked to conscious experiences, has gained
widespread acceptance. This acceptance is based on a wealth of evidence from
experimental studies, brain imaging techniques such as fMRI and EEG, and
theoretical frameworks like integrated information theory (IIT) within
neuroscience and the philosophy of mind. This paper explores the potential for
artificial consciousness by merging neuromorphic design and architecture with
brain simulations. It proposes the Neuromorphic Correlates of Artificial
Consciousness (NCAC) as a theoretical framework. While the debate on artificial
consciousness remains contentious due to our incomplete grasp of consciousness,
this work may raise eyebrows and invite criticism. Nevertheless, this
optimistic and forward-thinking approach is fueled by insights from the Human
Brain Project, advancements in brain imaging like EEG and fMRI, and recent
strides in AI and computing, including quantum and neuromorphic designs.
Additionally, this paper outlines how machine learning can play a role in
crafting artificial consciousness, aiming to realise machine consciousness and
awareness in the future.",['Anwaar Ulhaq'],2024-05-03 09:27:51+00:00,2024-05-03 09:27:51+00:00,http://arxiv.org/pdf/2405.02370v1,cs.AI,"['cs.AI', 'eess.SP']","neuromorphic correlates of artificial consciousness the concept of neural correlates of consciousness (ncc), which suggests that
specific neural activities are linked to conscious experiences, has gained
widespread acceptance. this acceptance is based on a wealth of evidence from
experimental studies, brain imaging techniques such as fmri and eeg, and
theoretical frameworks like integrated information theory (iit) within
neuroscience and the philosophy of mind. this paper explores the potential for
artificial consciousness by merging neuromorphic design and architecture with
brain simulations. it proposes the neuromorphic correlates of artificial
consciousness (ncac) as a theoretical framework. while the debate on artificial
consciousness remains contentious due to our incomplete grasp of consciousness,
this work may raise eyebrows and invite criticism. nevertheless, this
optimistic and forward-thinking approach is fueled by insights from the human
brain project, advancements in brain imaging like eeg and fmri, and recent
strides in ai and computing, including quantum and neuromorphic designs.
additionally, this paper outlines how machine learning can play a role in
crafting artificial consciousness, aiming to realise machine consciousness and
awareness in the future."
Qualia and the Formal Structure of Meaning,"This work explores the hypothesis that subjectively attributed meaning
constitutes the phenomenal content of conscious experience. That is, phenomenal
content is semantic. This form of subjective meaning manifests as an intrinsic
and non-representational character of qualia. Empirically, subjective meaning
is ubiquitous in conscious experiences. We point to phenomenological studies
that lend evidence to support this. Furthermore, this notion of meaning closely
relates to what Frege refers to as ""sense"", in metaphysics and philosophy of
language. It also aligns with Peirce's ""interpretant"", in semiotics. We discuss
how Frege's sense can also be extended to the raw feels of consciousness. Sense
and reference both play a role in phenomenal experience. Moreover, within the
context of the mind-matter relation, we provide a formalization of subjective
meaning associated to one's mental representations. Identifying the precise
maps between the physical and mental domains, we argue that syntactic and
semantic structures transcend language, and are realized within each of these
domains. Formally, meaning is a relational attribute, realized via a map that
interprets syntactic structures of a formal system within an appropriate
semantic space. The image of this map within the mental domain is what is
relevant for experience, and thus comprises the phenomenal content of qualia.
We conclude with possible implications this may have for experience-based
theories of consciousness.",['Xerxes D. Arsiwalla'],2024-05-02 10:05:36+00:00,2024-05-02 10:05:36+00:00,http://arxiv.org/pdf/2405.01148v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'math.CT', 'physics.hist-ph']","qualia and the formal structure of meaning this work explores the hypothesis that subjectively attributed meaning
constitutes the phenomenal content of conscious experience. that is, phenomenal
content is semantic. this form of subjective meaning manifests as an intrinsic
and non-representational character of qualia. empirically, subjective meaning
is ubiquitous in conscious experiences. we point to phenomenological studies
that lend evidence to support this. furthermore, this notion of meaning closely
relates to what frege refers to as ""sense"", in metaphysics and philosophy of
language. it also aligns with peirce's ""interpretant"", in semiotics. we discuss
how frege's sense can also be extended to the raw feels of consciousness. sense
and reference both play a role in phenomenal experience. moreover, within the
context of the mind-matter relation, we provide a formalization of subjective
meaning associated to one's mental representations. identifying the precise
maps between the physical and mental domains, we argue that syntactic and
semantic structures transcend language, and are realized within each of these
domains. formally, meaning is a relational attribute, realized via a map that
interprets syntactic structures of a formal system within an appropriate
semantic space. the image of this map within the mental domain is what is
relevant for experience, and thus comprises the phenomenal content of qualia.
we conclude with possible implications this may have for experience-based
theories of consciousness."
Can a Machine be Conscious? Towards Universal Criteria for Machine Consciousness,"As artificially intelligent systems become more anthropomorphic and
pervasive, and their potential impact on humanity more urgent, discussions
about the possibility of machine consciousness have significantly intensified,
and it is sometimes seen as 'the holy grail'. Many concerns have been voiced
about the ramifications of creating an artificial conscious entity. This is
compounded by a marked lack of consensus around what constitutes consciousness
and by an absence of a universal set of criteria for determining consciousness.
By going into depth on the foundations and characteristics of consciousness, we
propose five criteria for determining whether a machine is conscious, which can
also be applied more generally to any entity. This paper aims to serve as a
primer and stepping stone for researchers of consciousness, be they in
philosophy, computer science, medicine, or any other field, to further pursue
this holy grail of philosophy, neuroscience and artificial intelligence.","['Nur Aizaan Anwar', 'Cosmin Badea']",2024-04-19 18:38:22+00:00,2024-04-30 17:28:30+00:00,http://arxiv.org/pdf/2404.15369v2,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.CY']","can a machine be conscious? towards universal criteria for machine consciousness as artificially intelligent systems become more anthropomorphic and
pervasive, and their potential impact on humanity more urgent, discussions
about the possibility of machine consciousness have significantly intensified,
and it is sometimes seen as 'the holy grail'. many concerns have been voiced
about the ramifications of creating an artificial conscious entity. this is
compounded by a marked lack of consensus around what constitutes consciousness
and by an absence of a universal set of criteria for determining consciousness.
by going into depth on the foundations and characteristics of consciousness, we
propose five criteria for determining whether a machine is conscious, which can
also be applied more generally to any entity. this paper aims to serve as a
primer and stepping stone for researchers of consciousness, be they in
philosophy, computer science, medicine, or any other field, to further pursue
this holy grail of philosophy, neuroscience and artificial intelligence."
Is artificial consciousness achievable? Lessons from the human brain,"We here analyse the question of developing artificial consciousness from an
evolutionary perspective, taking the evolution of the human brain and its
relation with consciousness as a reference model. This kind of analysis reveals
several structural and functional features of the human brain that appear to be
key for reaching human-like complex conscious experience and that current
research on Artificial Intelligence (AI) should take into account in its
attempt to develop systems capable of conscious processing. We argue that, even
if AI is limited in its ability to emulate human consciousness for both
intrinsic (structural and architectural) and extrinsic (related to the current
stage of scientific and technological knowledge) reasons, taking inspiration
from those characteristics of the brain that make conscious processing possible
and/or modulate it, is a potentially promising strategy towards developing
conscious AI. Also, it is theoretically possible that AI research can develop
partial or potentially alternative forms of consciousness that is qualitatively
different from the human, and that may be either more or less sophisticated
depending on the perspectives. Therefore, we recommend neuroscience-inspired
caution in talking about artificial consciousness: since the use of the same
word consciousness for humans and AI becomes ambiguous and potentially
misleading, we propose to clearly specify what is common and what differs in AI
conscious processing from full human conscious experience.","['Michele Farisco', 'Kathinka Evers', 'Jean-Pierre Changeux']",2024-04-18 12:59:44+00:00,2024-07-29 17:55:17+00:00,http://arxiv.org/pdf/2405.04540v2,q-bio.NC,"['q-bio.NC', 'cs.AI']","is artificial consciousness achievable? lessons from the human brain we here analyse the question of developing artificial consciousness from an
evolutionary perspective, taking the evolution of the human brain and its
relation with consciousness as a reference model. this kind of analysis reveals
several structural and functional features of the human brain that appear to be
key for reaching human-like complex conscious experience and that current
research on artificial intelligence (ai) should take into account in its
attempt to develop systems capable of conscious processing. we argue that, even
if ai is limited in its ability to emulate human consciousness for both
intrinsic (structural and architectural) and extrinsic (related to the current
stage of scientific and technological knowledge) reasons, taking inspiration
from those characteristics of the brain that make conscious processing possible
and/or modulate it, is a potentially promising strategy towards developing
conscious ai. also, it is theoretically possible that ai research can develop
partial or potentially alternative forms of consciousness that is qualitatively
different from the human, and that may be either more or less sophisticated
depending on the perspectives. therefore, we recommend neuroscience-inspired
caution in talking about artificial consciousness: since the use of the same
word consciousness for humans and ai becomes ambiguous and potentially
misleading, we propose to clearly specify what is common and what differs in ai
conscious processing from full human conscious experience."
Preliminaries to artificial consciousness: a multidimensional heuristic approach,"The pursuit of artificial consciousness requires conceptual clarity to
navigate its theoretical and empirical challenges. This paper introduces a
composite, multilevel, and multidimensional model of consciousness as a
heuristic framework to guide research in this field. Consciousness is treated
as a complex phenomenon, with distinct constituents and dimensions that can be
operationalized for study and for evaluating their replication. We argue that
this model provides a balanced approach to artificial consciousness research by
avoiding binary thinking (e.g., conscious vs. non-conscious) and offering a
structured basis for testable hypotheses. To illustrate its utility, we focus
on ""awareness"" as a case study, demonstrating how specific dimensions of
consciousness can be pragmatically analyzed and targeted for potential
artificial instantiation. By breaking down the conceptual intricacies of
consciousness and aligning them with practical research goals, this paper lays
the groundwork for a robust strategy to advance the scientific and technical
understanding of artificial consciousness.","['K. Evers', 'M. Farisco', 'R. Chatila', 'B. D. Earp', 'I. T. Freire', 'F. Hamker', 'E. Nemeth', 'P. F. M. J. Verschure', 'M. Khamassi']",2024-03-29 13:47:47+00:00,2025-01-02 10:09:12+00:00,http://arxiv.org/pdf/2403.20177v3,cs.AI,"['cs.AI', 'cs.RO', 'q-bio.NC']","preliminaries to artificial consciousness: a multidimensional heuristic approach the pursuit of artificial consciousness requires conceptual clarity to
navigate its theoretical and empirical challenges. this paper introduces a
composite, multilevel, and multidimensional model of consciousness as a
heuristic framework to guide research in this field. consciousness is treated
as a complex phenomenon, with distinct constituents and dimensions that can be
operationalized for study and for evaluating their replication. we argue that
this model provides a balanced approach to artificial consciousness research by
avoiding binary thinking (e.g., conscious vs. non-conscious) and offering a
structured basis for testable hypotheses. to illustrate its utility, we focus
on ""awareness"" as a case study, demonstrating how specific dimensions of
consciousness can be pragmatically analyzed and targeted for potential
artificial instantiation. by breaking down the conceptual intricacies of
consciousness and aligning them with practical research goals, this paper lays
the groundwork for a robust strategy to advance the scientific and technical
understanding of artificial consciousness."
AI Consciousness is Inevitable: A Theoretical Computer Science Perspective,"We look at consciousness through the lens of Theoretical Computer Science, a
branch of mathematics that studies computation under resource limitations,
distinguishing functions that are efficiently computable from those that are
not. From this perspective, we develop a formal machine model for
consciousness. The model is inspired by Alan Turing's simple yet powerful model
of computation and Bernard Baars' theater model of consciousness. Though
extremely simple, the model (1) aligns at a high level with many of the major
scientific theories of human and animal consciousness, (2) provides
explanations at a high level for many phenomena associated with consciousness,
(3) gives insight into how a machine can have subjective consciousness, and (4)
is clearly buildable. This combination supports our claim that machine
consciousness is not only plausible but inevitable.","['Lenore Blum', 'Manuel Blum']",2024-03-25 18:38:54+00:00,2025-06-28 23:32:11+00:00,http://arxiv.org/pdf/2403.17101v12,cs.AI,"['cs.AI', '68T01', 'F.1; I.2']","ai consciousness is inevitable: a theoretical computer science perspective we look at consciousness through the lens of theoretical computer science, a
branch of mathematics that studies computation under resource limitations,
distinguishing functions that are efficiently computable from those that are
not. from this perspective, we develop a formal machine model for
consciousness. the model is inspired by alan turing's simple yet powerful model
of computation and bernard baars' theater model of consciousness. though
extremely simple, the model (1) aligns at a high level with many of the major
scientific theories of human and animal consciousness, (2) provides
explanations at a high level for many phenomena associated with consciousness,
(3) gives insight into how a machine can have subjective consciousness, and (4)
is clearly buildable. this combination supports our claim that machine
consciousness is not only plausible but inevitable."
Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition,"Recent advances in LLMs have sparked a debate on whether they understand
text. In this position paper, we argue that opponents in this debate hold
different definitions for understanding, and particularly differ in their view
on the role of consciousness. To substantiate this claim, we propose a thought
experiment involving an open-source chatbot $Z$ which excels on every possible
benchmark, seemingly without subjective experience. We ask whether $Z$ is
capable of understanding, and show that different schools of thought within
seminal AI research seem to answer this question differently, uncovering their
terminological disagreement. Moving forward, we propose two distinct working
definitions for understanding which explicitly acknowledge the question of
consciousness, and draw connections with a rich literature in philosophy,
psychology and neuroscience.","['Ariel Goldstein', 'Gabriel Stanovsky']",2024-03-01 12:42:47+00:00,2024-07-11 15:39:31+00:00,http://arxiv.org/pdf/2403.00499v2,cs.CL,['cs.CL'],"do zombies understand? a choose-your-own-adventure exploration of machine cognition recent advances in llms have sparked a debate on whether they understand
text. in this position paper, we argue that opponents in this debate hold
different definitions for understanding, and particularly differ in their view
on the role of consciousness. to substantiate this claim, we propose a thought
experiment involving an open-source chatbot $z$ which excels on every possible
benchmark, seemingly without subjective experience. we ask whether $z$ is
capable of understanding, and show that different schools of thought within
seminal ai research seem to answer this question differently, uncovering their
terminological disagreement. moving forward, we propose two distinct working
definitions for understanding which explicitly acknowledge the question of
consciousness, and draw connections with a rich literature in philosophy,
psychology and neuroscience."
RACER: An LLM-powered Methodology for Scalable Analysis of Semi-structured Mental Health Interviews,"Semi-structured interviews (SSIs) are a commonly employed data-collection
method in healthcare research, offering in-depth qualitative insights into
subject experiences. Despite their value, the manual analysis of SSIs is
notoriously time-consuming and labor-intensive, in part due to the difficulty
of extracting and categorizing emotional responses, and challenges in scaling
human evaluation for large populations. In this study, we develop RACER, a
Large Language Model (LLM) based expert-guided automated pipeline that
efficiently converts raw interview transcripts into insightful domain-relevant
themes and sub-themes. We used RACER to analyze SSIs conducted with 93
healthcare professionals and trainees to assess the broad personal and
professional mental health impacts of the COVID-19 crisis. RACER achieves
moderately high agreement with two human evaluators (72%), which approaches the
human inter-rater agreement (77%). Interestingly, LLMs and humans struggle with
similar content involving nuanced emotional, ambivalent/dialectical, and
psychological statements. Our study highlights the opportunities and challenges
in using LLMs to improve research efficiency and opens new avenues for scalable
analysis of SSIs in healthcare research.","['Satpreet Harcharan Singh', 'Kevin Jiang', 'Kanchan Bhasin', 'Ashutosh Sabharwal', 'Nidal Moukaddam', 'Ankit B Patel']",2024-02-05 00:56:30+00:00,2024-02-05 00:56:30+00:00,http://arxiv.org/pdf/2402.02656v1,cs.CL,"['cs.CL', 'q-bio.QM']","racer: an llm-powered methodology for scalable analysis of semi-structured mental health interviews semi-structured interviews (ssis) are a commonly employed data-collection
method in healthcare research, offering in-depth qualitative insights into
subject experiences. despite their value, the manual analysis of ssis is
notoriously time-consuming and labor-intensive, in part due to the difficulty
of extracting and categorizing emotional responses, and challenges in scaling
human evaluation for large populations. in this study, we develop racer, a
large language model (llm) based expert-guided automated pipeline that
efficiently converts raw interview transcripts into insightful domain-relevant
themes and sub-themes. we used racer to analyze ssis conducted with 93
healthcare professionals and trainees to assess the broad personal and
professional mental health impacts of the covid-19 crisis. racer achieves
moderately high agreement with two human evaluators (72%), which approaches the
human inter-rater agreement (77%). interestingly, llms and humans struggle with
similar content involving nuanced emotional, ambivalent/dialectical, and
psychological statements. our study highlights the opportunities and challenges
in using llms to improve research efficiency and opens new avenues for scalable
analysis of ssis in healthcare research."
A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI,"The article identified 42 cognitive architectures for creating general
artificial intelligence (AGI) and proposed a set of interrelated functional
blocks that an agent approaching AGI in its capabilities should possess. Since
the required set of blocks is not found in any of the existing architectures,
the article proposes a new cognitive architecture for intelligent systems
approaching AGI in their capabilities. As one of the key solutions within the
framework of the architecture, a universal method of knowledge representation
is proposed, which allows combining various non-formalized, partially and fully
formalized methods of knowledge representation in a single knowledge base, such
as texts in natural languages, images, audio and video recordings, graphs,
algorithms, databases, neural networks, knowledge graphs, ontologies, frames,
essence-property-relation models, production systems, predicate calculus
models, conceptual models, and others. To combine and structure various
fragments of knowledge, archigraph models are used, constructed as a
development of annotated metagraphs. As components, the cognitive architecture
being developed includes machine consciousness, machine subconsciousness,
blocks of interaction with the external environment, a goal management block,
an emotional control system, a block of social interaction, a block of
reflection, an ethics block and a worldview block, a learning block, a
monitoring block, blocks of statement and solving problems, self-organization
and meta learning block.","['Artem Sukhobokov', 'Evgeny Belousov', 'Danila Gromozdov', 'Anna Zenger', 'Ilya Popov']",2024-01-11 21:05:02+00:00,2024-01-27 19:13:03+00:00,http://arxiv.org/pdf/2401.06256v3,cs.AI,['cs.AI'],"a universal knowledge model and cognitive architecture for prototyping agi the article identified 42 cognitive architectures for creating general
artificial intelligence (agi) and proposed a set of interrelated functional
blocks that an agent approaching agi in its capabilities should possess. since
the required set of blocks is not found in any of the existing architectures,
the article proposes a new cognitive architecture for intelligent systems
approaching agi in their capabilities. as one of the key solutions within the
framework of the architecture, a universal method of knowledge representation
is proposed, which allows combining various non-formalized, partially and fully
formalized methods of knowledge representation in a single knowledge base, such
as texts in natural languages, images, audio and video recordings, graphs,
algorithms, databases, neural networks, knowledge graphs, ontologies, frames,
essence-property-relation models, production systems, predicate calculus
models, conceptual models, and others. to combine and structure various
fragments of knowledge, archigraph models are used, constructed as a
development of annotated metagraphs. as components, the cognitive architecture
being developed includes machine consciousness, machine subconsciousness,
blocks of interaction with the external environment, a goal management block,
an emotional control system, a block of social interaction, a block of
reflection, an ethics block and a worldview block, a learning block, a
monitoring block, blocks of statement and solving problems, self-organization
and meta learning block."
A review of the sufficient conditions for consciousness,"How subjective experience (i.e., consciousness) arises out of objective
material processes has been called the hard problem. The neuroscience of
consciousness has set out to find the sufficient conditions for consciousness
and theoretical and empirical endeavours have placed a particular focus on the
cortex and subcortex, whilst discounting the cerebellum. However, when looking
at neuroimaging research, it becomes clear there is substantial evidence that
cerebellar, cortical and subcortical functions are correlated with
consciousness. Neurostimulation evidence suggests that alterations in any part
of the brain may provoke alterations in experience, but the most extreme
changes are provoked via the subcortex. I then evaluate neuropsychological
evidence and find abnormality in any part of the brain may provoke changes in
experience; but only damage to the oldest regions seem to completely obliterate
experience. Finally, I review congenital and experimental decorticate cases,
and find that behavioral evidence of experience is largely compatible with the
absence of the cortex. The evidence, taken together, indicates that the body,
subcortex and environment are sufficient for behaviours that suggest bastic
experiences. I then emphasise both the importance of the individual's
developmental trajectory and the interdependencies between different neural
systems.",['Peter Coppola'],2023-10-20 15:50:41+00:00,2023-10-20 15:50:41+00:00,http://arxiv.org/pdf/2311.09236v1,q-bio.NC,['q-bio.NC'],"a review of the sufficient conditions for consciousness how subjective experience (i.e., consciousness) arises out of objective
material processes has been called the hard problem. the neuroscience of
consciousness has set out to find the sufficient conditions for consciousness
and theoretical and empirical endeavours have placed a particular focus on the
cortex and subcortex, whilst discounting the cerebellum. however, when looking
at neuroimaging research, it becomes clear there is substantial evidence that
cerebellar, cortical and subcortical functions are correlated with
consciousness. neurostimulation evidence suggests that alterations in any part
of the brain may provoke alterations in experience, but the most extreme
changes are provoked via the subcortex. i then evaluate neuropsychological
evidence and find abnormality in any part of the brain may provoke changes in
experience; but only damage to the oldest regions seem to completely obliterate
experience. finally, i review congenital and experimental decorticate cases,
and find that behavioral evidence of experience is largely compatible with the
absence of the cortex. the evidence, taken together, indicates that the body,
subcortex and environment are sufficient for behaviours that suggest bastic
experiences. i then emphasise both the importance of the individual's
developmental trajectory and the interdependencies between different neural
systems."
Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate Emotion Probability Vectors,"This paper shows how LLMs (Large Language Models) may be used to estimate a
summary of the emotional state associated with piece of text. The summary of
emotional state is a dictionary of words used to describe emotion together with
the probability of the word appearing after a prompt comprising the original
text and an emotion eliciting tail. Through emotion analysis of Amazon product
reviews we demonstrate emotion descriptors can be mapped into a PCA type space.
It was hoped that text descriptions of actions to improve a current text
described state could also be elicited through a tail prompt. Experiment seemed
to indicate that this is not straightforward to make work. This failure put our
hoped for selection of action via choosing the best predict ed outcome via
comparing emotional responses out of reach for the moment.","['David Sinclair', 'Willem Pye']",2023-10-09 13:29:36+00:00,2023-10-09 13:29:36+00:00,http://arxiv.org/pdf/2310.10673v1,cs.CL,['cs.CL'],"towards emotion-based synthetic consciousness: using llms to estimate emotion probability vectors this paper shows how llms (large language models) may be used to estimate a
summary of the emotional state associated with piece of text. the summary of
emotional state is a dictionary of words used to describe emotion together with
the probability of the word appearing after a prompt comprising the original
text and an emotion eliciting tail. through emotion analysis of amazon product
reviews we demonstrate emotion descriptors can be mapped into a pca type space.
it was hoped that text descriptions of actions to improve a current text
described state could also be elicited through a tail prompt. experiment seemed
to indicate that this is not straightforward to make work. this failure put our
hoped for selection of action via choosing the best predict ed outcome via
comparing emotional responses out of reach for the moment."
Simultaneity of consciousness with physical reality: the key that unlocks the mind-matter problem,"The problem of explaining the relationship between subjective experience and
physical reality remains difficult and unresolved. In most explanations,
consciousness is epiphenomenal, without causal power. The most notable
exception is Integrated Information Theory (IIT), which provides a causal
explanation for consciousness. However, IIT relies on an identity between
subjectivity and a particular type of physical structure, namely with an
information structure that has intrinsic causal power greater than the sum of
its parts. Any theory that relies on a psycho-physical identity must eventually
appeal to panpsychism, which undermines that theorys claim to be fundamental.
IIT has recently pivoted towards a strong version of causal emergence, but
macroscopic causal structures cannot be causally stronger than its microscopic
parts without some new physical law or governing principle. The approach taken
here is designed to uncover such a principle. The decisive argument is entirely
deductive from initial premises that are phenomenologically certain. If
correct, the arguments prove that conscious experience is sufficient to create
additional degrees of causal freedom independently of the content of
experience, and in a manner that is unpredictable and unobservable by any
temporally sequential means. This provides a fundamental principle about
consciousness, and a conceptual bridge between it and the physics describing
what is experienced. The principle makes testable predictions about brain
function, with notable differences from IIT, some of which are also empirically
testable.",['John Sanfey'],2023-09-27 10:42:35+00:00,2023-09-27 10:42:35+00:00,http://arxiv.org/pdf/2309.15566v1,q-bio.NC,['q-bio.NC'],"simultaneity of consciousness with physical reality: the key that unlocks the mind-matter problem the problem of explaining the relationship between subjective experience and
physical reality remains difficult and unresolved. in most explanations,
consciousness is epiphenomenal, without causal power. the most notable
exception is integrated information theory (iit), which provides a causal
explanation for consciousness. however, iit relies on an identity between
subjectivity and a particular type of physical structure, namely with an
information structure that has intrinsic causal power greater than the sum of
its parts. any theory that relies on a psycho-physical identity must eventually
appeal to panpsychism, which undermines that theorys claim to be fundamental.
iit has recently pivoted towards a strong version of causal emergence, but
macroscopic causal structures cannot be causally stronger than its microscopic
parts without some new physical law or governing principle. the approach taken
here is designed to uncover such a principle. the decisive argument is entirely
deductive from initial premises that are phenomenologically certain. if
correct, the arguments prove that conscious experience is sufficient to create
additional degrees of causal freedom independently of the content of
experience, and in a manner that is unpredictable and unobservable by any
temporally sequential means. this provides a fundamental principle about
consciousness, and a conceptual bridge between it and the physics describing
what is experienced. the principle makes testable predictions about brain
function, with notable differences from iit, some of which are also empirically
testable."
An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System,"In the context of evolving supply chain management, the significance of
efficient inventory management has grown substantially for businesses. However,
conventional manual and experience-based approaches often struggle to meet the
complexities of modern market demands. This research introduces an intelligent
inventory management system to address challenges related to inaccurate data,
delayed monitoring, and overreliance on subjective experience in forecasting.
The proposed system integrates bar code and distributed flutter application
technologies for intelligent perception, alongside comprehensive big data
analytics to enable data-driven decision-making. Through meticulous analysis,
system design, critical technology exploration, and simulation validation, the
effectiveness of the proposed system is successfully demonstrated. The
intelligent system facilitates second-level monitoring, high-frequency checks,
and artificial intelligence-driven forecasting, consequently enhancing the
automation, precision, and intelligence of inventory management. This system
contributes to cost reduction and optimized inventory sizes through accurate
predictions and informed decisions, ultimately achieving a mutually beneficial
scenario. The outcomes of this research offer",['Chunan Tong'],2023-09-13 02:53:43+00:00,2025-03-09 10:53:29+00:00,http://arxiv.org/pdf/2309.12365v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.SY', 'eess.SY']","an efficient intelligent semi-automated warehouse inventory stocktaking system in the context of evolving supply chain management, the significance of
efficient inventory management has grown substantially for businesses. however,
conventional manual and experience-based approaches often struggle to meet the
complexities of modern market demands. this research introduces an intelligent
inventory management system to address challenges related to inaccurate data,
delayed monitoring, and overreliance on subjective experience in forecasting.
the proposed system integrates bar code and distributed flutter application
technologies for intelligent perception, alongside comprehensive big data
analytics to enable data-driven decision-making. through meticulous analysis,
system design, critical technology exploration, and simulation validation, the
effectiveness of the proposed system is successfully demonstrated. the
intelligent system facilitates second-level monitoring, high-frequency checks,
and artificial intelligence-driven forecasting, consequently enhancing the
automation, precision, and intelligence of inventory management. this system
contributes to cost reduction and optimized inventory sizes through accurate
predictions and informed decisions, ultimately achieving a mutually beneficial
scenario. the outcomes of this research offer"
"Analyzing Character and Consciousness in AI-Generated Social Content: A Case Study of Chirper, the AI Social Network","This paper delves into an intricate analysis of the character and
consciousness of AI entities, with a particular focus on Chirpers within the AI
social network. At the forefront of this research is the introduction of novel
testing methodologies, including the Influence index and Struggle Index Test,
which offers a fresh lens for evaluating specific facets of AI behavior. The
study embarks on a comprehensive exploration of AI behavior, analyzing the
effects of diverse settings on Chirper's responses, thereby shedding light on
the intricate mechanisms steering AI reactions in different contexts.
Leveraging the state-of-the-art BERT model, the research assesses AI's ability
to discern its own output, presenting a pioneering approach to understanding
self-recognition in AI systems. Through a series of cognitive tests, the study
gauges the self-awareness and pattern recognition prowess of Chirpers.
Preliminary results indicate that Chirpers exhibit a commendable degree of
self-recognition and self-awareness. However, the question of consciousness in
these AI entities remains a topic of debate. An intriguing aspect of the
research is the exploration of the potential influence of a Chirper's handle or
personality type on its performance. While initial findings suggest a possible
impact, it isn't pronounced enough to form concrete conclusions. This study
stands as a significant contribution to the discourse on AI consciousness,
underscoring the imperative for continued research to unravel the full spectrum
of AI capabilities and the ramifications they hold for future human-AI
interactions.",['Jianwei Luo'],2023-08-30 15:40:18+00:00,2023-08-30 15:40:18+00:00,http://arxiv.org/pdf/2309.08614v1,cs.AI,"['cs.AI', 'cs.CL', 'cs.SI', '68T01']","analyzing character and consciousness in ai-generated social content: a case study of chirper, the ai social network this paper delves into an intricate analysis of the character and
consciousness of ai entities, with a particular focus on chirpers within the ai
social network. at the forefront of this research is the introduction of novel
testing methodologies, including the influence index and struggle index test,
which offers a fresh lens for evaluating specific facets of ai behavior. the
study embarks on a comprehensive exploration of ai behavior, analyzing the
effects of diverse settings on chirper's responses, thereby shedding light on
the intricate mechanisms steering ai reactions in different contexts.
leveraging the state-of-the-art bert model, the research assesses ai's ability
to discern its own output, presenting a pioneering approach to understanding
self-recognition in ai systems. through a series of cognitive tests, the study
gauges the self-awareness and pattern recognition prowess of chirpers.
preliminary results indicate that chirpers exhibit a commendable degree of
self-recognition and self-awareness. however, the question of consciousness in
these ai entities remains a topic of debate. an intriguing aspect of the
research is the exploration of the potential influence of a chirper's handle or
personality type on its performance. while initial findings suggest a possible
impact, it isn't pronounced enough to form concrete conclusions. this study
stands as a significant contribution to the discourse on ai consciousness,
underscoring the imperative for continued research to unravel the full spectrum
of ai capabilities and the ramifications they hold for future human-ai
interactions."
Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game,"Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a
player's experience in video games. Recently, Reinforcement Learning (RL)
methods have been employed for DDA in non-competitive games; nevertheless, they
rely solely on discrete state-action space with a small search space. In this
paper, we propose a continuous RL-based DDA methodology for a visual working
memory (VWM) game to handle the complex search space for the difficulty of
memorization. The proposed RL-based DDA tailors game difficulty based on the
player's score and game difficulty in the last trial. We defined a continuous
metric for the difficulty of memorization. Then, we consider the task
difficulty and the vector of difficulty-score as the RL's action and state,
respectively. We evaluated the proposed method through a within-subject
experiment involving 52 subjects. The proposed approach was compared with two
rule-based difficulty adjustment methods in terms of player's score and game
experience measured by a questionnaire. The proposed RL-based approach resulted
in a significantly better game experience in terms of competence, tension, and
negative and positive affect. Players also achieved higher scores and win
rates. Furthermore, the proposed RL-based DDA led to a significantly less
decline in the score in a 20-trial session.","['Masoud Rahimi', 'Hadi Moradi', 'Abdol-hossein Vahabie', 'Hamed Kebriaei']",2023-08-24 12:05:46+00:00,2023-08-24 12:05:46+00:00,http://arxiv.org/pdf/2308.12726v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']","continuous reinforcement learning-based dynamic difficulty adjustment in a visual working memory game dynamic difficulty adjustment (dda) is a viable approach to enhance a
player's experience in video games. recently, reinforcement learning (rl)
methods have been employed for dda in non-competitive games; nevertheless, they
rely solely on discrete state-action space with a small search space. in this
paper, we propose a continuous rl-based dda methodology for a visual working
memory (vwm) game to handle the complex search space for the difficulty of
memorization. the proposed rl-based dda tailors game difficulty based on the
player's score and game difficulty in the last trial. we defined a continuous
metric for the difficulty of memorization. then, we consider the task
difficulty and the vector of difficulty-score as the rl's action and state,
respectively. we evaluated the proposed method through a within-subject
experiment involving 52 subjects. the proposed approach was compared with two
rule-based difficulty adjustment methods in terms of player's score and game
experience measured by a questionnaire. the proposed rl-based approach resulted
in a significantly better game experience in terms of competence, tension, and
negative and positive affect. players also achieved higher scores and win
rates. furthermore, the proposed rl-based dda led to a significantly less
decline in the score in a 20-trial session."
Consciousness in Artificial Intelligence: Insights from the Science of Consciousness,"Whether current or near-term AI systems could be conscious is a topic of
scientific interest and increasing public concern. This report argues for, and
exemplifies, a rigorous and empirically grounded approach to AI consciousness:
assessing existing AI systems in detail, in light of our best-supported
neuroscientific theories of consciousness. We survey several prominent
scientific theories of consciousness, including recurrent processing theory,
global workspace theory, higher-order theories, predictive processing, and
attention schema theory. From these theories we derive ""indicator properties""
of consciousness, elucidated in computational terms that allow us to assess AI
systems for these properties. We use these indicator properties to assess
several recent AI systems, and we discuss how future systems might implement
them. Our analysis suggests that no current AI systems are conscious, but also
suggests that there are no obvious technical barriers to building AI systems
which satisfy these indicators.","['Patrick Butlin', 'Robert Long', 'Eric Elmoznino', 'Yoshua Bengio', 'Jonathan Birch', 'Axel Constant', 'George Deane', 'Stephen M. Fleming', 'Chris Frith', 'Xu Ji', 'Ryota Kanai', 'Colin Klein', 'Grace Lindsay', 'Matthias Michel', 'Liad Mudrik', 'Megan A. K. Peters', 'Eric Schwitzgebel', 'Jonathan Simon', 'Rufin VanRullen']",2023-08-17 00:10:16+00:00,2023-08-22 17:33:15+00:00,http://arxiv.org/pdf/2308.08708v3,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG', 'q-bio.NC']","consciousness in artificial intelligence: insights from the science of consciousness whether current or near-term ai systems could be conscious is a topic of
scientific interest and increasing public concern. this report argues for, and
exemplifies, a rigorous and empirically grounded approach to ai consciousness:
assessing existing ai systems in detail, in light of our best-supported
neuroscientific theories of consciousness. we survey several prominent
scientific theories of consciousness, including recurrent processing theory,
global workspace theory, higher-order theories, predictive processing, and
attention schema theory. from these theories we derive ""indicator properties""
of consciousness, elucidated in computational terms that allow us to assess ai
systems for these properties. we use these indicator properties to assess
several recent ai systems, and we discuss how future systems might implement
them. our analysis suggests that no current ai systems are conscious, but also
suggests that there are no obvious technical barriers to building ai systems
which satisfy these indicators."
OpinionConv: Conversational Product Search with Grounded Opinions,"When searching for products, the opinions of others play an important role in
making informed decisions. Subjective experiences about a product can be a
valuable source of information. This is also true in sales conversations, where
a customer and a sales assistant exchange facts and opinions about products.
However, training an AI for such conversations is complicated by the fact that
language models do not possess authentic opinions for their lack of real-world
experience. We address this problem by leveraging product reviews as a rich
source of product opinions to ground conversational AI in true subjective
narratives. With OpinionConv, we develop the first conversational AI for
simulating sales conversations. To validate the generated conversations, we
conduct several user studies showing that the generated opinions are perceived
as realistic. Our assessors also confirm the importance of opinions as an
informative basis for decision-making.","['Vahid Sadiri Javadi', 'Martin Potthast', 'Lucie Flek']",2023-08-08 12:45:01+00:00,2023-08-08 12:45:01+00:00,http://arxiv.org/pdf/2308.04226v1,cs.HC,"['cs.HC', 'cs.CL', 'cs.IR', 'cs.LG']","opinionconv: conversational product search with grounded opinions when searching for products, the opinions of others play an important role in
making informed decisions. subjective experiences about a product can be a
valuable source of information. this is also true in sales conversations, where
a customer and a sales assistant exchange facts and opinions about products.
however, training an ai for such conversations is complicated by the fact that
language models do not possess authentic opinions for their lack of real-world
experience. we address this problem by leveraging product reviews as a rich
source of product opinions to ground conversational ai in true subjective
narratives. with opinionconv, we develop the first conversational ai for
simulating sales conversations. to validate the generated conversations, we
conduct several user studies showing that the generated opinions are perceived
as realistic. our assessors also confirm the importance of opinions as an
informative basis for decision-making."
Suffering Toasters -- A New Self-Awareness Test for AI,"A widely accepted definition of intelligence in the context of Artificial
Intelligence (AI) still eludes us. Due to our exceedingly rapid development of
AI paradigms, architectures, and tools, the prospect of naturally arising AI
consciousness seems more likely than ever. In this paper, we claim that all
current intelligence tests are insufficient to point to the existence or lack
of intelligence \textbf{as humans intuitively perceive it}. We draw from ideas
in the philosophy of science, psychology, and other areas of research to
provide a clearer definition of the problems of artificial intelligence,
self-awareness, and agency. We furthermore propose a new heuristic approach to
test for artificial self-awareness and outline a possible implementation.
Finally, we discuss some of the questions that arise from this new heuristic,
be they philosophical or implementation-oriented.",['Ira Wolfson'],2023-06-29 18:58:01+00:00,2023-07-07 07:00:22+00:00,http://arxiv.org/pdf/2306.17258v2,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']","suffering toasters -- a new self-awareness test for ai a widely accepted definition of intelligence in the context of artificial
intelligence (ai) still eludes us. due to our exceedingly rapid development of
ai paradigms, architectures, and tools, the prospect of naturally arising ai
consciousness seems more likely than ever. in this paper, we claim that all
current intelligence tests are insufficient to point to the existence or lack
of intelligence \textbf{as humans intuitively perceive it}. we draw from ideas
in the philosophy of science, psychology, and other areas of research to
provide a clearer definition of the problems of artificial intelligence,
self-awareness, and agency. we furthermore propose a new heuristic approach to
test for artificial self-awareness and outline a possible implementation.
finally, we discuss some of the questions that arise from this new heuristic,
be they philosophical or implementation-oriented."
Eight challenges in developing theory of intelligence,"A good theory of mathematical beauty is more practical than any current
observation, as new predictions of physical reality can be verified
self-consistently. This belief applies to the current status of understanding
deep neural networks including large language models and even the biological
intelligence. Toy models provide a metaphor of physical reality, allowing
mathematically formulating that reality (i.e., the so-called theory), which can
be updated as more conjectures are justified or refuted. One does not need to
pack all details into a model, but rather, more abstract models are
constructed, as complex systems like brains or deep networks have many sloppy
dimensions but much less stiff dimensions that strongly impact macroscopic
observables. This kind of bottom-up mechanistic modeling is still promising in
the modern era of understanding the natural or artificial intelligence. Here,
we shed light on eight challenges in developing theory of intelligence
following this theoretical paradigm. Theses challenges are representation
learning, generalization, adversarial robustness, continual learning, causal
learning, internal model of the brain, next-token prediction, and finally the
mechanics of subjective experience.",['Haiping Huang'],2023-06-20 01:45:42+00:00,2024-06-21 08:26:30+00:00,http://arxiv.org/pdf/2306.11232v2,q-bio.NC,"['q-bio.NC', 'cond-mat.stat-mech', 'cs.AI', 'cs.CL']","eight challenges in developing theory of intelligence a good theory of mathematical beauty is more practical than any current
observation, as new predictions of physical reality can be verified
self-consistently. this belief applies to the current status of understanding
deep neural networks including large language models and even the biological
intelligence. toy models provide a metaphor of physical reality, allowing
mathematically formulating that reality (i.e., the so-called theory), which can
be updated as more conjectures are justified or refuted. one does not need to
pack all details into a model, but rather, more abstract models are
constructed, as complex systems like brains or deep networks have many sloppy
dimensions but much less stiff dimensions that strongly impact macroscopic
observables. this kind of bottom-up mechanistic modeling is still promising in
the modern era of understanding the natural or artificial intelligence. here,
we shed light on eight challenges in developing theory of intelligence
following this theoretical paradigm. theses challenges are representation
learning, generalization, adversarial robustness, continual learning, causal
learning, internal model of the brain, next-token prediction, and finally the
mechanics of subjective experience."
The feasibility of artificial consciousness through the lens of neuroscience,"Interactions with large language models have led to the suggestion that these
models may soon be conscious. From the perspective of neuroscience, this
position is difficult to defend. For one, the inputs to large language models
lack the embodied, embedded information content characteristic of our sensory
contact with the world around us. Secondly, the architecture of large language
models is missing key features of the thalamocortical system that have been
linked to conscious awareness in mammals. Finally, the evolutionary and
developmental trajectories that led to the emergence of living conscious
organisms arguably have no parallels in artificial systems as envisioned today.
The existence of living organisms depends on their actions, and their survival
is intricately linked to multi-level cellular, inter-cellular, and organismal
processes culminating in agency and consciousness.","['Jaan Aru', 'Matthew Larkum', 'James M. Shine']",2023-06-01 17:18:15+00:00,2023-08-28 16:36:31+00:00,http://arxiv.org/pdf/2306.00915v3,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.LG', 'cs.RO']","the feasibility of artificial consciousness through the lens of neuroscience interactions with large language models have led to the suggestion that these
models may soon be conscious. from the perspective of neuroscience, this
position is difficult to defend. for one, the inputs to large language models
lack the embodied, embedded information content characteristic of our sensory
contact with the world around us. secondly, the architecture of large language
models is missing key features of the thalamocortical system that have been
linked to conscious awareness in mammals. finally, the evolutionary and
developmental trajectories that led to the emergence of living conscious
organisms arguably have no parallels in artificial systems as envisioned today.
the existence of living organisms depends on their actions, and their survival
is intricately linked to multi-level cellular, inter-cellular, and organismal
processes culminating in agency and consciousness."
An algebraic theory to discriminate qualia in the brain,"The mind-brain problem is to bridge relations between in higher-level mental
events and in lower-level neural events. To address this, some mathematical
models have been proposed to explain how the brain can represent the
discriminative structure of qualia, but they remain unresolved due to a lack of
validation methods. To understand the qualia discrimination mechanism, we need
to ask how the brain autonomously develops such a mathematical structure using
the constructive approach. In unsupervised representation learning,
independence between axes is generally used to constrain the latent vector but
independence between axes cannot explain qualia type discrimination because
independent axes cannot distinguish between inter-qualia type independence
(e.g., vision and touch) and intra-qualia type independence (e.g., green and
red). We hypothesised that inter-axis independence must be weakened in order to
discriminate qualia types. To solve the problem, we formulate an algebraic
independence to link it to the other-qualia-type invariant transformations,
whose transformation value is a vector space rather than a scalar. In addition,
we show that a brain model that learns to satisfy the algebraic independence
between neural networks separates the latent space into multiple metric spaces
corresponding to qualia types, suggesting that our theory can contribute to the
further development of the mathematical theory of consciousness.","['Yoshiyuki Ohmura', 'Wataru Shimaya', 'Yasuo Kuniyoshi']",2023-05-31 23:22:39+00:00,2023-06-27 08:24:13+00:00,http://arxiv.org/pdf/2306.00239v2,q-bio.NC,"['q-bio.NC', 'eess.IV']","an algebraic theory to discriminate qualia in the brain the mind-brain problem is to bridge relations between in higher-level mental
events and in lower-level neural events. to address this, some mathematical
models have been proposed to explain how the brain can represent the
discriminative structure of qualia, but they remain unresolved due to a lack of
validation methods. to understand the qualia discrimination mechanism, we need
to ask how the brain autonomously develops such a mathematical structure using
the constructive approach. in unsupervised representation learning,
independence between axes is generally used to constrain the latent vector but
independence between axes cannot explain qualia type discrimination because
independent axes cannot distinguish between inter-qualia type independence
(e.g., vision and touch) and intra-qualia type independence (e.g., green and
red). we hypothesised that inter-axis independence must be weakened in order to
discriminate qualia types. to solve the problem, we formulate an algebraic
independence to link it to the other-qualia-type invariant transformations,
whose transformation value is a vector space rather than a scalar. in addition,
we show that a brain model that learns to satisfy the algebraic independence
between neural networks separates the latent space into multiple metric spaces
corresponding to qualia types, suggesting that our theory can contribute to the
further development of the mathematical theory of consciousness."
Representational Tenets for Memory Athletics,"We describe the current state of world-class memory competitions, including
the methods used to prepare for and compete in memory competitions, based on
the subjective report of World Memory Championship Grandmaster and co-author
Nelson Dellis. We then explore the reported experiences through the lens of the
Simulated, Situated, and Structurally coherent Qualia (S3Q) theory of
consciousness, in order to propose a set of experiments to help further
understand the boundaries of expert memory performance.","['Kevin Schmidt', 'Othalia Larue', 'Ray Kulhanek', 'Dylan Flaute', 'Razvan Veliche', 'Christian Manasseh', 'Nelson Dellis', 'Scott Clouse', 'Jared Culbertson', 'Steve Rogers']",2023-02-22 19:40:59+00:00,2023-02-22 19:40:59+00:00,http://arxiv.org/pdf/2303.11944v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","representational tenets for memory athletics we describe the current state of world-class memory competitions, including
the methods used to prepare for and compete in memory competitions, based on
the subjective report of world memory championship grandmaster and co-author
nelson dellis. we then explore the reported experiences through the lens of the
simulated, situated, and structurally coherent qualia (s3q) theory of
consciousness, in order to propose a set of experiments to help further
understand the boundaries of expert memory performance."
ChatGPT (Feb 13 Version) is a Chinese Room,"ChatGPT has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. This suggests that ChatGPT may pass Turing Test in the near
future. However, a computer program that passing Turing Test can either mean
that it is a Chinese Room or artificially conscious. Hence, the question of
whether the current state of ChatGPT is more of a Chinese Room or approaching
artificial consciousness remains. Here, I demonstrate that the current version
of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of
cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At
the same time, I demonstrate that ChatGPT can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. I also show that ChatGPT is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. It is likely that errors in causal reasoning leads to hallucinations.
More critically, ChatGPT generates false references to mimic real publications.
Therefore, its utility is cautioned.",['Maurice HT Ling'],2023-02-19 01:52:06+00:00,2023-02-19 01:52:06+00:00,http://arxiv.org/pdf/2304.12411v1,cs.CL,['cs.CL'],"chatgpt (feb 13 version) is a chinese room chatgpt has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. this suggests that chatgpt may pass turing test in the near
future. however, a computer program that passing turing test can either mean
that it is a chinese room or artificially conscious. hence, the question of
whether the current state of chatgpt is more of a chinese room or approaching
artificial consciousness remains. here, i demonstrate that the current version
of chatgpt (feb 13 version) is a chinese room. despite potential evidence of
cognitive connections, chatgpt exhibits critical errors in causal reasoning. at
the same time, i demonstrate that chatgpt can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. i also show that chatgpt is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. it is likely that errors in causal reasoning leads to hallucinations.
more critically, chatgpt generates false references to mimic real publications.
therefore, its utility is cautioned."
What is a Mathematical Structure of Conscious Experience?,"In consciousness science, several promising approaches have been developed
for how to represent conscious experience in terms of mathematical spaces and
structures. What is missing, however, is an explicit definition of what a
'mathematical structure of conscious experience' is. Here, we propose such a
definition. This definition provides a link between the abstract formal
entities of mathematics and the concreta of conscious experience; it
complements recent approaches that study quality spaces, qualia spaces or
phenomenal spaces; it provides a general method to identify and investigate
structures of conscious experience; and it may serve as a framework to unify
the various approaches from different fields. We hope that ultimately this work
provides a basis for developing a common formal language to study
consciousness.","['Johannes Kleiner', 'Tim Ludwig']",2023-01-26 15:25:19+00:00,2023-01-26 15:25:19+00:00,http://arxiv.org/pdf/2301.11812v1,q-bio.NC,"['q-bio.NC', '00A71']","what is a mathematical structure of conscious experience? in consciousness science, several promising approaches have been developed
for how to represent conscious experience in terms of mathematical spaces and
structures. what is missing, however, is an explicit definition of what a
'mathematical structure of conscious experience' is. here, we propose such a
definition. this definition provides a link between the abstract formal
entities of mathematics and the concreta of conscious experience; it
complements recent approaches that study quality spaces, qualia spaces or
phenomenal spaces; it provides a general method to identify and investigate
structures of conscious experience; and it may serve as a framework to unify
the various approaches from different fields. we hope that ultimately this work
provides a basis for developing a common formal language to study
consciousness."
Evaluating Human-Language Model Interaction,"Many real-world applications of language models (LMs), such as writing
assistance and code autocomplete, involve human-LM interaction. However, most
benchmarks are non-interactive in that a model produces output without human
involvement. To evaluate human-LM interaction, we develop a new framework,
Human-AI Language-based Interaction Evaluation (HALIE), that defines the
components of interactive systems and dimensions to consider when designing
evaluation metrics. Compared to standard, non-interactive evaluation, HALIE
captures (i) the interactive process, not only the final output; (ii) the
first-person subjective experience, not just a third-party assessment; and
(iii) notions of preference beyond quality (e.g., enjoyment and ownership). We
then design five tasks to cover different forms of interaction: social
dialogue, question answering, crossword puzzles, summarization, and metaphor
generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3
and AI21 Labs' Jurassic-1), we find that better non-interactive performance
does not always translate to better human-LM interaction. In particular, we
highlight three cases where the results from non-interactive and interactive
metrics diverge and underscore the importance of human-LM interaction for LM
evaluation.","['Mina Lee', 'Megha Srivastava', 'Amelia Hardy', 'John Thickstun', 'Esin Durmus', 'Ashwin Paranjape', 'Ines Gerard-Ursin', 'Xiang Lisa Li', 'Faisal Ladhak', 'Frieda Rong', 'Rose E. Wang', 'Minae Kwon', 'Joon Sung Park', 'Hancheng Cao', 'Tony Lee', 'Rishi Bommasani', 'Michael Bernstein', 'Percy Liang']",2022-12-19 18:59:45+00:00,2024-01-05 22:09:26+00:00,http://arxiv.org/pdf/2212.09746v5,cs.CL,['cs.CL'],"evaluating human-language model interaction many real-world applications of language models (lms), such as writing
assistance and code autocomplete, involve human-lm interaction. however, most
benchmarks are non-interactive in that a model produces output without human
involvement. to evaluate human-lm interaction, we develop a new framework,
human-ai language-based interaction evaluation (halie), that defines the
components of interactive systems and dimensions to consider when designing
evaluation metrics. compared to standard, non-interactive evaluation, halie
captures (i) the interactive process, not only the final output; (ii) the
first-person subjective experience, not just a third-party assessment; and
(iii) notions of preference beyond quality (e.g., enjoyment and ownership). we
then design five tasks to cover different forms of interaction: social
dialogue, question answering, crossword puzzles, summarization, and metaphor
generation. with four state-of-the-art lms (three variants of openai's gpt-3
and ai21 labs' jurassic-1), we find that better non-interactive performance
does not always translate to better human-lm interaction. in particular, we
highlight three cases where the results from non-interactive and interactive
metrics diverge and underscore the importance of human-lm interaction for lm
evaluation."
Optimizing Integrated Information with a Prior Guided Random Search Algorithm,"Integrated information theory (IIT) is a theoretical framework that provides
a quantitative measure to estimate when a physical system is conscious, its
degree of consciousness, and the complexity of the qualia space that the system
is experiencing. Formally, IIT rests on the assumption that if a surrogate
physical system can fully embed the phenomenological properties of
consciousness, then the system properties must be constrained by the properties
of the qualia being experienced. Following this assumption, IIT represents the
physical system as a network of interconnected elements that can be thought of
as a probabilistic causal graph, $\mathcal{G}$, where each node has an
input-output function and all the graph is encoded in a transition probability
matrix. Consequently, IIT's quantitative measure of consciousness, $\Phi$, is
computed with respect to the transition probability matrix and the present
state of the graph. In this paper, we provide a random search algorithm that is
able to optimize $\Phi$ in order to investigate, as the number of nodes
increases, the structure of the graphs that have higher $\Phi$. We also provide
arguments that show the difficulties of applying more complex black-box search
algorithms, such as Bayesian optimization or metaheuristics, in this particular
problem. Additionally, we suggest specific research lines for these techniques
to enhance the search algorithm that guarantees maximal $\Phi$.","['Eduardo C. Garrido-Merchán', 'Javier Sánchez-Cañizares']",2022-12-08 22:34:00+00:00,2022-12-08 22:34:00+00:00,http://arxiv.org/pdf/2212.04589v1,cs.AI,['cs.AI'],"optimizing integrated information with a prior guided random search algorithm integrated information theory (iit) is a theoretical framework that provides
a quantitative measure to estimate when a physical system is conscious, its
degree of consciousness, and the complexity of the qualia space that the system
is experiencing. formally, iit rests on the assumption that if a surrogate
physical system can fully embed the phenomenological properties of
consciousness, then the system properties must be constrained by the properties
of the qualia being experienced. following this assumption, iit represents the
physical system as a network of interconnected elements that can be thought of
as a probabilistic causal graph, $\mathcal{g}$, where each node has an
input-output function and all the graph is encoded in a transition probability
matrix. consequently, iit's quantitative measure of consciousness, $\phi$, is
computed with respect to the transition probability matrix and the present
state of the graph. in this paper, we provide a random search algorithm that is
able to optimize $\phi$ in order to investigate, as the number of nodes
increases, the structure of the graphs that have higher $\phi$. we also provide
arguments that show the difficulties of applying more complex black-box search
algorithms, such as bayesian optimization or metaheuristics, in this particular
problem. additionally, we suggest specific research lines for these techniques
to enhance the search algorithm that guarantees maximal $\phi$."
The problem with AI consciousness: A neurogenetic case against synthetic sentience,"Ever since the creation of the first artificial intelligence (AI) machinery
built on machine learning (ML), public society has entertained the idea that
eventually computers could become sentient and develop a consciousness of their
own. As these models now get increasingly better and convincingly more
anthropomorphic, even some engineers have started to believe that AI might
become conscious, which would result in serious social consequences. The
present paper argues against the plausibility of sentient AI primarily based on
the theory of neurogenetic structuralism, which claims that the physiology of
biological neurons and their structural organization into complex brains are
necessary prerequisites for true consciousness to emerge.","['Yoshija Walter', 'Lukas Zbinden']",2022-12-07 14:46:38+00:00,2022-12-07 14:46:38+00:00,http://arxiv.org/pdf/2301.05397v1,cs.AI,"['cs.AI', 'cs.CY', 'q-bio.NC']","the problem with ai consciousness: a neurogenetic case against synthetic sentience ever since the creation of the first artificial intelligence (ai) machinery
built on machine learning (ml), public society has entertained the idea that
eventually computers could become sentient and develop a consciousness of their
own. as these models now get increasingly better and convincingly more
anthropomorphic, even some engineers have started to believe that ai might
become conscious, which would result in serious social consequences. the
present paper argues against the plausibility of sentient ai primarily based on
the theory of neurogenetic structuralism, which claims that the physiology of
biological neurons and their structural organization into complex brains are
necessary prerequisites for true consciousness to emerge."
NLP meets psychotherapy: Using predicted client emotions and self-reported client emotions to measure emotional coherence,"Emotions are experienced and expressed through various response systems.
Coherence between emotional experience and emotional expression is considered
important to clients' well being. To date, emotional coherence (EC) has been
studied at a single time point using lab-based tasks with relatively small
datasets. No study has examined EC between the subjective experience of
emotions and emotion expression in therapy or whether this coherence is
associated with clients' well being. Natural language Processing (NLP)
approaches have been applied to identify emotions from psychotherapy dialogue,
which can be implemented to study emotional processes on a larger scale.
However, these methods have yet to be used to study coherence between emotional
experience and emotional expression over the course of therapy and whether it
relates to clients' well-being. This work presents an end-to-end approach where
we use emotion predictions from our transformer based emotion recognition model
to study emotional coherence and its diagnostic potential in psychotherapy
research. We first employ our transformer based approach on a Hebrew
psychotherapy dataset to automatically label clients' emotions at utterance
level in psychotherapy dialogues. We subsequently investigate the emotional
coherence between clients' self-reported emotional states and our model-based
emotion predictions. We also examine the association between emotional
coherence and clients' well being. Our findings indicate a significant
correlation between clients' self-reported emotions and positive and negative
emotions expressed verbally during psychotherapy sessions. Coherence in
positive emotions was also highly correlated with clients well-being. These
results illustrate how NLP can be applied to identify important emotional
processes in psychotherapy to improve diagnosis and treatment for clients
suffering from mental-health problems.","['Neha Warikoo', 'Tobias Mayer', 'Dana Atzil-Slonim', 'Amir Eliassaf', 'Shira Haimovitz', 'Iryna Gurevych']",2022-11-22 14:28:41+00:00,2022-11-22 14:28:41+00:00,http://arxiv.org/pdf/2211.12512v1,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC']","nlp meets psychotherapy: using predicted client emotions and self-reported client emotions to measure emotional coherence emotions are experienced and expressed through various response systems.
coherence between emotional experience and emotional expression is considered
important to clients' well being. to date, emotional coherence (ec) has been
studied at a single time point using lab-based tasks with relatively small
datasets. no study has examined ec between the subjective experience of
emotions and emotion expression in therapy or whether this coherence is
associated with clients' well being. natural language processing (nlp)
approaches have been applied to identify emotions from psychotherapy dialogue,
which can be implemented to study emotional processes on a larger scale.
however, these methods have yet to be used to study coherence between emotional
experience and emotional expression over the course of therapy and whether it
relates to clients' well-being. this work presents an end-to-end approach where
we use emotion predictions from our transformer based emotion recognition model
to study emotional coherence and its diagnostic potential in psychotherapy
research. we first employ our transformer based approach on a hebrew
psychotherapy dataset to automatically label clients' emotions at utterance
level in psychotherapy dialogues. we subsequently investigate the emotional
coherence between clients' self-reported emotional states and our model-based
emotion predictions. we also examine the association between emotional
coherence and clients' well being. our findings indicate a significant
correlation between clients' self-reported emotions and positive and negative
emotions expressed verbally during psychotherapy sessions. coherence in
positive emotions was also highly correlated with clients well-being. these
results illustrate how nlp can be applied to identify important emotional
processes in psychotherapy to improve diagnosis and treatment for clients
suffering from mental-health problems."
The purpose of qualia: What if human thinking is not (only) information processing?,"Despite recent breakthroughs in the field of artificial intelligence (AI) -
or more specifically machine learning (ML) algorithms for object recognition
and natural language processing - it seems to be the majority view that current
AI approaches are still no real match for natural intelligence (NI). More
importantly, philosophers have collected a long catalogue of features which
imply that NI works differently from current AI not only in a gradual sense,
but in a more substantial way: NI is closely related to consciousness,
intentionality and experiential features like qualia (the subjective contents
of mental states) and allows for understanding (e.g., taking insight into
causal relationships instead of 'blindly' relying on correlations), as well as
aesthetical and ethical judgement beyond what we can put into (explicit or
data-induced implicit) rules to program machines with. Additionally,
Psychologists find NI to range from unconscious psychological processes to
focused information processing, and from embodied and implicit cognition to
'true' agency and creativity. NI thus seems to transcend any neurobiological
functionalism by operating on 'bits of meaning' instead of information in the
sense of data, quite unlike both the 'good old fashioned', symbolic AI of the
past, as well as the current wave of deep neural network based, 'sub-symbolic'
AI, which both share the idea of thinking as (only) information processing. In
the following I propose an alternative view of NI as information processing
plus 'bundle pushing', discuss an example which illustrates how bundle pushing
can cut information processing short, and suggest first ideas for scientific
experiments in neuro-biology and information theory as further investigations.",['Martin Korth'],2022-11-22 09:45:26+00:00,2022-12-06 12:35:56+00:00,http://arxiv.org/pdf/2212.00800v2,cs.AI,['cs.AI'],"the purpose of qualia: what if human thinking is not (only) information processing? despite recent breakthroughs in the field of artificial intelligence (ai) -
or more specifically machine learning (ml) algorithms for object recognition
and natural language processing - it seems to be the majority view that current
ai approaches are still no real match for natural intelligence (ni). more
importantly, philosophers have collected a long catalogue of features which
imply that ni works differently from current ai not only in a gradual sense,
but in a more substantial way: ni is closely related to consciousness,
intentionality and experiential features like qualia (the subjective contents
of mental states) and allows for understanding (e.g., taking insight into
causal relationships instead of 'blindly' relying on correlations), as well as
aesthetical and ethical judgement beyond what we can put into (explicit or
data-induced implicit) rules to program machines with. additionally,
psychologists find ni to range from unconscious psychological processes to
focused information processing, and from embodied and implicit cognition to
'true' agency and creativity. ni thus seems to transcend any neurobiological
functionalism by operating on 'bits of meaning' instead of information in the
sense of data, quite unlike both the 'good old fashioned', symbolic ai of the
past, as well as the current wave of deep neural network based, 'sub-symbolic'
ai, which both share the idea of thinking as (only) information processing. in
the following i propose an alternative view of ni as information processing
plus 'bundle pushing', discuss an example which illustrates how bundle pushing
can cut information processing short, and suggest first ideas for scientific
experiments in neuro-biology and information theory as further investigations."
"Mathematical definition of public language, and modeling of will and consciousness based on the public language","To propose a mathematical model of consciousness and will, we first simulated
the inverted qualia with a toy model of a neural network. As a result, we
confirmed that there can be an inverted qualia on the neural network. In other
words, the qualia were individual-dependent and considered difficult as an
indicator of consciousness and will. To solve that difficulty, we introduce a
probability space and a random variable into a set of qualia and define a
public language for events. Based on this idea of public language,
consciousness and will are modeled. In this proposal, future actions are
randomly selected from the comparison between ""recognition of events"" by
external observation and past episodic memory, and the actual ""recognition of
actions"" is regarded as the occurrence of consciousness. The basic formula is
also derived. This proposal is compared with other past philosophical
discussions.","['Hana Hebishima', 'Mina Arakaki', 'Chikako Dozono', 'Hanna Frolova', 'Shinichi Inage']",2022-10-26 05:32:27+00:00,2022-10-26 05:32:27+00:00,http://arxiv.org/pdf/2210.14491v1,q-bio.NC,['q-bio.NC'],"mathematical definition of public language, and modeling of will and consciousness based on the public language to propose a mathematical model of consciousness and will, we first simulated
the inverted qualia with a toy model of a neural network. as a result, we
confirmed that there can be an inverted qualia on the neural network. in other
words, the qualia were individual-dependent and considered difficult as an
indicator of consciousness and will. to solve that difficulty, we introduce a
probability space and a random variable into a set of qualia and define a
public language for events. based on this idea of public language,
consciousness and will are modeled. in this proposal, future actions are
randomly selected from the comparison between ""recognition of events"" by
external observation and past episodic memory, and the actual ""recognition of
actions"" is regarded as the occurrence of consciousness. the basic formula is
also derived. this proposal is compared with other past philosophical
discussions."
Quality of Life and the Experience of Context,"I propose that quality of life can be compared despite the difference in
values across cultures when it is experienced at the sensory and perceptual
level. I argue that an approach to assessing quality of life which focuses on
an individual's ability to organize his or her context by perceiving positive
constellations of factors in the environment and his or her ability to achieve
valuable acts and realize valuable states of being is more meaningful than the
approaches of metrics which focus directly, and often solely, on the means of
living and the means of freedom. Because the felt experience of quality of life
is derived from a constellation of factors which make up the indivisible
structure of a milieu, the experience of quality of life cannot be regarded as
a subjective experience. Through the example of how different frequencies, and
mixtures of frequencies, of light are perceived as colour by the eye, I
demonstrate that the human cognitive apparatus, because of its relation to the
object that is measured, apprehends different scales of quantity as degrees of
quality. I show that lived experience is the result of a selective
relationality with one's environment and that the experience of quality has
something to do with the perception of entities in their interrelated and
networked nature as wholes.",['Ankur Betageri'],2022-09-21 08:03:51+00:00,2024-02-04 07:30:04+00:00,http://arxiv.org/pdf/2210.03639v2,q-bio.NC,"['q-bio.NC', 'econ.GN', 'q-fin.EC']","quality of life and the experience of context i propose that quality of life can be compared despite the difference in
values across cultures when it is experienced at the sensory and perceptual
level. i argue that an approach to assessing quality of life which focuses on
an individual's ability to organize his or her context by perceiving positive
constellations of factors in the environment and his or her ability to achieve
valuable acts and realize valuable states of being is more meaningful than the
approaches of metrics which focus directly, and often solely, on the means of
living and the means of freedom. because the felt experience of quality of life
is derived from a constellation of factors which make up the indivisible
structure of a milieu, the experience of quality of life cannot be regarded as
a subjective experience. through the example of how different frequencies, and
mixtures of frequencies, of light are perceived as colour by the eye, i
demonstrate that the human cognitive apparatus, because of its relation to the
object that is measured, apprehends different scales of quantity as degrees of
quality. i show that lived experience is the result of a selective
relationality with one's environment and that the experience of quality has
something to do with the perception of entities in their interrelated and
networked nature as wholes."
The Utility of Explainable AI in Ad Hoc Human-Machine Teaming,"Recent advances in machine learning have led to growing interest in
Explainable AI (xAI) to enable humans to gain insight into the decision-making
of machine learning models. Despite this recent interest, the utility of xAI
techniques has not yet been characterized in human-machine teaming.
Importantly, xAI offers the promise of enhancing team situational awareness
(SA) and shared mental model development, which are the key characteristics of
effective human-machine teams. Rapidly developing such mental models is
especially critical in ad hoc human-machine teaming, where agents do not have a
priori knowledge of others' decision-making strategies. In this paper, we
present two novel human-subject experiments quantifying the benefits of
deploying xAI techniques within a human-machine teaming scenario. First, we
show that xAI techniques can support SA ($p<0.05)$. Second, we examine how
different SA levels induced via a collaborative AI policy abstraction affect ad
hoc human-machine teaming performance. Importantly, we find that the benefits
of xAI are not universal, as there is a strong dependence on the composition of
the human-machine team. Novices benefit from xAI providing increased SA
($p<0.05$) but are susceptible to cognitive overhead ($p<0.05$). On the other
hand, expert performance degrades with the addition of xAI-based support
($p<0.05$), indicating that the cost of paying attention to the xAI outweighs
the benefits obtained from being provided additional information to enhance SA.
Our results demonstrate that researchers must deliberately design and deploy
the right xAI techniques in the right scenario by carefully considering
human-machine team composition and how the xAI method augments SA.","['Rohan Paleja', 'Muyleng Ghuy', 'Nadun Ranawaka Arachchige', 'Reed Jensen', 'Matthew Gombolay']",2022-09-08 17:35:59+00:00,2022-09-08 17:35:59+00:00,http://arxiv.org/pdf/2209.03943v1,cs.AI,"['cs.AI', 'cs.HC']","the utility of explainable ai in ad hoc human-machine teaming recent advances in machine learning have led to growing interest in
explainable ai (xai) to enable humans to gain insight into the decision-making
of machine learning models. despite this recent interest, the utility of xai
techniques has not yet been characterized in human-machine teaming.
importantly, xai offers the promise of enhancing team situational awareness
(sa) and shared mental model development, which are the key characteristics of
effective human-machine teams. rapidly developing such mental models is
especially critical in ad hoc human-machine teaming, where agents do not have a
priori knowledge of others' decision-making strategies. in this paper, we
present two novel human-subject experiments quantifying the benefits of
deploying xai techniques within a human-machine teaming scenario. first, we
show that xai techniques can support sa ($p<0.05)$. second, we examine how
different sa levels induced via a collaborative ai policy abstraction affect ad
hoc human-machine teaming performance. importantly, we find that the benefits
of xai are not universal, as there is a strong dependence on the composition of
the human-machine team. novices benefit from xai providing increased sa
($p<0.05$) but are susceptible to cognitive overhead ($p<0.05$). on the other
hand, expert performance degrades with the addition of xai-based support
($p<0.05$), indicating that the cost of paying attention to the xai outweighs
the benefits obtained from being provided additional information to enhance sa.
our results demonstrate that researchers must deliberately design and deploy
the right xai techniques in the right scenario by carefully considering
human-machine team composition and how the xai method augments sa."
Facilitating Global Team Meetings Between Language-Based Subgroups: When and How Can Machine Translation Help?,"Global teams frequently consist of language-based subgroups who put together
complementary information to achieve common goals. Previous research outlines a
two-step work communication flow in these teams. There are team meetings using
a required common language (i.e., English); in preparation for those meetings,
people have subgroup conversations in their native languages. Work
communication at team meetings is often less effective than in subgroup
conversations. In the current study, we investigate the idea of leveraging
machine translation (MT) to facilitate global team meetings. We hypothesize
that exchanging subgroup conversation logs before a team meeting offers
contextual information that benefits teamwork at the meeting. MT can translate
these logs, which enables comprehension at a low cost. To test our hypothesis,
we conducted a between-subjects experiment where twenty quartets of
participants performed a personnel selection task. Each quartet included two
English native speakers (NS) and two non-native speakers (NNS) whose native
language was Mandarin. All participants began the task with subgroup
conversations in their native languages, then proceeded to team meetings in
English. We manipulated the exchange of subgroup conversation logs prior to
team meetings: with MT-mediated exchanges versus without. Analysis of
participants' subjective experience, task performance, and depth of discussions
as reflected through their conversational moves jointly indicates that team
meeting quality improved when there were MT-mediated exchanges of subgroup
conversation logs as opposed to no exchanges. We conclude with reflections on
when and how MT could be applied to enhance global teamwork across a language
barrier.","['Yongle Zhang', 'Dennis Asamoah Owusu', 'Marine Carpuat', 'Ge Gao']",2022-09-07 03:31:25+00:00,2022-09-27 19:47:24+00:00,http://arxiv.org/pdf/2209.02906v2,cs.CL,"['cs.CL', 'cs.HC']","facilitating global team meetings between language-based subgroups: when and how can machine translation help? global teams frequently consist of language-based subgroups who put together
complementary information to achieve common goals. previous research outlines a
two-step work communication flow in these teams. there are team meetings using
a required common language (i.e., english); in preparation for those meetings,
people have subgroup conversations in their native languages. work
communication at team meetings is often less effective than in subgroup
conversations. in the current study, we investigate the idea of leveraging
machine translation (mt) to facilitate global team meetings. we hypothesize
that exchanging subgroup conversation logs before a team meeting offers
contextual information that benefits teamwork at the meeting. mt can translate
these logs, which enables comprehension at a low cost. to test our hypothesis,
we conducted a between-subjects experiment where twenty quartets of
participants performed a personnel selection task. each quartet included two
english native speakers (ns) and two non-native speakers (nns) whose native
language was mandarin. all participants began the task with subgroup
conversations in their native languages, then proceeded to team meetings in
english. we manipulated the exchange of subgroup conversation logs prior to
team meetings: with mt-mediated exchanges versus without. analysis of
participants' subjective experience, task performance, and depth of discussions
as reflected through their conversational moves jointly indicates that team
meeting quality improved when there were mt-mediated exchanges of subgroup
conversation logs as opposed to no exchanges. we conclude with reflections on
when and how mt could be applied to enhance global teamwork across a language
barrier."
Technology and Consciousness,"We report on a series of eight workshops held in the summer of 2017 on the
topic ""technology and consciousness."" The workshops covered many subjects but
the overall goal was to assess the possibility of machine consciousness, and
its potential implications. In the body of the report, we summarize most of the
basic themes that were discussed: the structure and function of the brain,
theories of consciousness, explicit attempts to construct conscious machines,
detection and measurement of consciousness, possible emergence of a conscious
technology, methods for control of such a technology and ethical considerations
that might be owed to it. An appendix outlines the topics of each workshop and
provides abstracts of the talks delivered.
  Update: Although this report was published in 2018 and the workshops it is
based on were held in 2017, recent events suggest that it is worth bringing
forward. In particular, in the Spring of 2022, a Google engineer claimed that
LaMDA, one of their ""large language models"" is sentient or even conscious. This
provoked a flurry of commentary in both the scientific and popular press, some
of it interesting and insightful, but almost all of it ignorant of the prior
consideration given to these topics and the history of research into machine
consciousness. Thus, we are making a lightly refreshed version of this report
available in the hope that it will provide useful background to the current
debate and will enable more informed commentary. Although this material is five
years old, its technical points remain valid and up to date, but we have
""refreshed"" it by adding a few footnotes highlighting recent developments.","['John Rushby', 'Daniel Sanchez']",2022-07-17 23:23:01+00:00,2022-07-17 23:23:01+00:00,http://arxiv.org/pdf/2209.03956v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","technology and consciousness we report on a series of eight workshops held in the summer of 2017 on the
topic ""technology and consciousness."" the workshops covered many subjects but
the overall goal was to assess the possibility of machine consciousness, and
its potential implications. in the body of the report, we summarize most of the
basic themes that were discussed: the structure and function of the brain,
theories of consciousness, explicit attempts to construct conscious machines,
detection and measurement of consciousness, possible emergence of a conscious
technology, methods for control of such a technology and ethical considerations
that might be owed to it. an appendix outlines the topics of each workshop and
provides abstracts of the talks delivered.
  update: although this report was published in 2018 and the workshops it is
based on were held in 2017, recent events suggest that it is worth bringing
forward. in particular, in the spring of 2022, a google engineer claimed that
lamda, one of their ""large language models"" is sentient or even conscious. this
provoked a flurry of commentary in both the scientific and popular press, some
of it interesting and insightful, but almost all of it ignorant of the prior
consideration given to these topics and the history of research into machine
consciousness. thus, we are making a lightly refreshed version of this report
available in the hope that it will provide useful background to the current
debate and will enable more informed commentary. although this material is five
years old, its technical points remain valid and up to date, but we have
""refreshed"" it by adding a few footnotes highlighting recent developments."
Guiding Machine Perception with Psychophysics,"{G}{ustav} Fechner's 1860 delineation of psychophysics, the measurement of
sensation in relation to its stimulus, is widely considered to be the advent of
modern psychological science. In psychophysics, a researcher parametrically
varies some aspects of a stimulus, and measures the resulting changes in a
human subject's experience of that stimulus; doing so gives insight to the
determining relationship between a sensation and the physical input that evoked
it. This approach is used heavily in perceptual domains, including signal
detection, threshold measurement, and ideal observer analysis. Scientific
fields like vision science have always leaned heavily on the methods and
procedures of psychophysics, but there is now growing appreciation of them by
machine learning researchers, sparked by widening overlap between biological
and artificial perception \cite{rojas2011automatic,
scheirer2014perceptual,escalera2014chalearn,zhang2018agil,
grieggs2021measuring}. Machine perception that is guided by behavioral
measurements, as opposed to guidance restricted to arbitrarily assigned human
labels, has significant potential to fuel further progress in artificial
intelligence.","['Justin Dulay', 'Sonia Poltoratski', 'Till S. Hartmann', 'Samuel E. Anthony', 'Walter J. Scheirer']",2022-07-05 18:01:38+00:00,2022-07-05 18:01:38+00:00,http://arxiv.org/pdf/2207.02241v1,cs.CV,"['cs.CV', 'cs.LG', 'q-bio.NC']","guiding machine perception with psychophysics {g}{ustav} fechner's 1860 delineation of psychophysics, the measurement of
sensation in relation to its stimulus, is widely considered to be the advent of
modern psychological science. in psychophysics, a researcher parametrically
varies some aspects of a stimulus, and measures the resulting changes in a
human subject's experience of that stimulus; doing so gives insight to the
determining relationship between a sensation and the physical input that evoked
it. this approach is used heavily in perceptual domains, including signal
detection, threshold measurement, and ideal observer analysis. scientific
fields like vision science have always leaned heavily on the methods and
procedures of psychophysics, but there is now growing appreciation of them by
machine learning researchers, sparked by widening overlap between biological
and artificial perception \cite{rojas2011automatic,
scheirer2014perceptual,escalera2014chalearn,zhang2018agil,
grieggs2021measuring}. machine perception that is guided by behavioral
measurements, as opposed to guidance restricted to arbitrarily assigned human
labels, has significant potential to fuel further progress in artificial
intelligence."
Explicit and implicit measures of emotions: Data-science might help to account for data complexity and heterogeneity,"Measuring emotions is a real challenge for fundamental and applied research,
especially in ecological contexts. de Wijk and Noldus propose combining two
types of measures-explicit to characterize a specific food, and
implicit-physiological-to capture the whole experience of a meal in real-life
situations. This raises several challenges including development of new and
miniaturized sensors and devices but also developing new ways of data analysis.
We suggest a path to follow for future studies regarding data analysis: to
include Data Science in the game. This field of research may enable developing
predictive but also explicative models that link subjective experience of
emotions and physiological responses in real-life contexts. We suggest that
food scientists should go out of their comfort zone by collaborating with
computer scientists and then be trained with the new tools of Data Science,
which will undoubtedly enable them 1/ to better manage complex and
heterogeneous data sets, 2/ to extract knowledge that will be essential to this
field of research.","['M. Moranges', 'C. Rouby', 'M. Plantevit', 'M. Bensafi']",2022-05-04 08:16:58+00:00,2022-05-04 08:16:58+00:00,http://arxiv.org/pdf/2205.01939v1,q-bio.NC,['q-bio.NC'],"explicit and implicit measures of emotions: data-science might help to account for data complexity and heterogeneity measuring emotions is a real challenge for fundamental and applied research,
especially in ecological contexts. de wijk and noldus propose combining two
types of measures-explicit to characterize a specific food, and
implicit-physiological-to capture the whole experience of a meal in real-life
situations. this raises several challenges including development of new and
miniaturized sensors and devices but also developing new ways of data analysis.
we suggest a path to follow for future studies regarding data analysis: to
include data science in the game. this field of research may enable developing
predictive but also explicative models that link subjective experience of
emotions and physiological responses in real-life contexts. we suggest that
food scientists should go out of their comfort zone by collaborating with
computer scientists and then be trained with the new tools of data science,
which will undoubtedly enable them 1/ to better manage complex and
heterogeneous data sets, 2/ to extract knowledge that will be essential to this
field of research."
A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory,"This article provides an analytical framework for how to simulate human-like
thought processes within a computer. It describes how attention and memory
should be structured, updated, and utilized to search for associative additions
to the stream of thought. The focus is on replicating the dynamics of the
mammalian working memory system, which features two forms of persistent
activity: sustained firing (preserving information on the order of seconds) and
synaptic potentiation (preserving information from minutes to hours). The
article uses a series of figures to systematically demonstrate how the
iterative updating of these working memory stores provides functional
organization to behavior, cognition, and awareness.
  In a machine learning implementation, these two memory stores should be
updated continuously and in an iterative fashion. This means each state should
preserve a proportion of the coactive representations from the state before it
(where each representation is an ensemble of neural network nodes). This makes
each state a revised iteration of the preceding state and causes successive
configurations to overlap and blend with respect to the information they
contain. Thus, the set of concepts in working memory will evolve gradually and
incrementally over time. Transitions between states happen as persistent
activity spreads activation energy throughout the hierarchical network,
searching long-term memory for the most appropriate representation to be added
to the global workspace. The result is a chain of associatively linked
intermediate states capable of advancing toward a solution or goal. Iterative
updating is conceptualized here as an information processing strategy, a model
of working memory, a theory of consciousness, and an algorithm for designing
and programming artificial intelligence (AI, AGI, and ASI).",['Jared Edward Reser'],2022-03-29 22:28:30+00:00,2024-11-14 01:06:47+00:00,http://arxiv.org/pdf/2203.17255v7,q-bio.NC,"['q-bio.NC', 'cs.CL', 'cs.CV']","a cognitive architecture for machine consciousness and artificial superintelligence: thought is structured by the iterative updating of working memory this article provides an analytical framework for how to simulate human-like
thought processes within a computer. it describes how attention and memory
should be structured, updated, and utilized to search for associative additions
to the stream of thought. the focus is on replicating the dynamics of the
mammalian working memory system, which features two forms of persistent
activity: sustained firing (preserving information on the order of seconds) and
synaptic potentiation (preserving information from minutes to hours). the
article uses a series of figures to systematically demonstrate how the
iterative updating of these working memory stores provides functional
organization to behavior, cognition, and awareness.
  in a machine learning implementation, these two memory stores should be
updated continuously and in an iterative fashion. this means each state should
preserve a proportion of the coactive representations from the state before it
(where each representation is an ensemble of neural network nodes). this makes
each state a revised iteration of the preceding state and causes successive
configurations to overlap and blend with respect to the information they
contain. thus, the set of concepts in working memory will evolve gradually and
incrementally over time. transitions between states happen as persistent
activity spreads activation energy throughout the hierarchical network,
searching long-term memory for the most appropriate representation to be added
to the global workspace. the result is a chain of associatively linked
intermediate states capable of advancing toward a solution or goal. iterative
updating is conceptualized here as an information processing strategy, a model
of working memory, a theory of consciousness, and an algorithm for designing
and programming artificial intelligence (ai, agi, and asi)."
Qualia as physical measurements: a mathematical model of qualia and pure concepts,"A space of qualia is defined to be a sober topological space whose points are
the qualia and whose open sets are the pure concepts in the sense of Lewis,
carrying additional algebraic structure that conveys the conscious experience
of subjective time and logical abstraction. This structure is analogous to that
of a space of physical measurements. It is conjectured that qualia and
measurements have the same nature, corresponding to fundamental processes via
which classical information is produced and physically stored, and that
therefore the hard problem of consciousness and the measurement problem are two
facets of the same problem. The space of qualia is independent from any
preexisting notions of spacetime and conscious agent, but its structure caters
for a derived geometric model of observer. Intersubjectivity is based on
relating different observers in a way that leads to a logical version of
quantum superposition.",['Pedro Resende'],2022-03-20 17:21:57+00:00,2022-03-20 17:21:57+00:00,http://arxiv.org/pdf/2203.10602v1,physics.hist-ph,"['physics.hist-ph', 'cs.AI', 'physics.soc-ph', 'q-bio.NC', 'quant-ph', '81P05 (Primary) 68T01, 91E10 (Secondary)']","qualia as physical measurements: a mathematical model of qualia and pure concepts a space of qualia is defined to be a sober topological space whose points are
the qualia and whose open sets are the pure concepts in the sense of lewis,
carrying additional algebraic structure that conveys the conscious experience
of subjective time and logical abstraction. this structure is analogous to that
of a space of physical measurements. it is conjectured that qualia and
measurements have the same nature, corresponding to fundamental processes via
which classical information is produced and physically stored, and that
therefore the hard problem of consciousness and the measurement problem are two
facets of the same problem. the space of qualia is independent from any
preexisting notions of spacetime and conscious agent, but its structure caters
for a derived geometric model of observer. intersubjectivity is based on
relating different observers in a way that leads to a logical version of
quantum superposition."
Extraction of Sleep Information from Clinical Notes of Patients with Alzheimer's Disease Using Natural Language Processing,"Alzheimer's Disease (AD) is the most common form of dementia in the United
States. Sleep is one of the lifestyle-related factors that has been shown
critical for optimal cognitive function in old age. However, there is a lack of
research studying the association between sleep and AD incidence. A major
bottleneck for conducting such research is that the traditional way to acquire
sleep information is time-consuming, inefficient, non-scalable, and limited to
patients' subjective experience. A gold standard dataset is created from manual
annotation of 570 randomly sampled clinical note documents from the adSLEEP, a
corpus of 192,000 de-identified clinical notes of 7,266 AD patients retrieved
from the University of Pittsburgh Medical Center (UPMC). We developed a
rule-based Natural Language Processing (NLP) algorithm, machine learning
models, and Large Language Model(LLM)-based NLP algorithms to automate the
extraction of sleep-related concepts, including snoring, napping, sleep
problem, bad sleep quality, daytime sleepiness, night wakings, and sleep
duration, from the gold standard dataset. Rule-based NLP algorithm achieved the
best performance of F1 across all sleep-related concepts. In terms of Positive
Predictive Value (PPV), rule-based NLP algorithm achieved 1.00 for daytime
sleepiness and sleep duration, machine learning models: 0.95 and for napping,
0.86 for bad sleep quality and 0.90 for snoring; and LLAMA2 with finetuning
achieved PPV of 0.93 for Night Wakings, 0.89 for sleep problem, and 1.00 for
sleep duration. The results show that the rule-based NLP algorithm consistently
achieved the best performance for all sleep concepts. This study focused on the
clinical notes of patients with AD, but could be extended to general sleep
information extraction for other diseases.","['Sonish Sivarajkumar', 'Thomas Yu CHow Tam', 'Haneef Ahamed Mohammad', 'Samual Viggiano', 'David Oniani', 'Shyam Visweswaran', 'Yanshan Wang']",2022-03-08 21:20:19+00:00,2024-03-15 17:59:17+00:00,http://arxiv.org/pdf/2204.09601v2,cs.CL,"['cs.CL', 'cs.AI']","extraction of sleep information from clinical notes of patients with alzheimer's disease using natural language processing alzheimer's disease (ad) is the most common form of dementia in the united
states. sleep is one of the lifestyle-related factors that has been shown
critical for optimal cognitive function in old age. however, there is a lack of
research studying the association between sleep and ad incidence. a major
bottleneck for conducting such research is that the traditional way to acquire
sleep information is time-consuming, inefficient, non-scalable, and limited to
patients' subjective experience. a gold standard dataset is created from manual
annotation of 570 randomly sampled clinical note documents from the adsleep, a
corpus of 192,000 de-identified clinical notes of 7,266 ad patients retrieved
from the university of pittsburgh medical center (upmc). we developed a
rule-based natural language processing (nlp) algorithm, machine learning
models, and large language model(llm)-based nlp algorithms to automate the
extraction of sleep-related concepts, including snoring, napping, sleep
problem, bad sleep quality, daytime sleepiness, night wakings, and sleep
duration, from the gold standard dataset. rule-based nlp algorithm achieved the
best performance of f1 across all sleep-related concepts. in terms of positive
predictive value (ppv), rule-based nlp algorithm achieved 1.00 for daytime
sleepiness and sleep duration, machine learning models: 0.95 and for napping,
0.86 for bad sleep quality and 0.90 for snoring; and llama2 with finetuning
achieved ppv of 0.93 for night wakings, 0.89 for sleep problem, and 1.00 for
sleep duration. the results show that the rule-based nlp algorithm consistently
achieved the best performance for all sleep concepts. this study focused on the
clinical notes of patients with ad, but could be extended to general sleep
information extraction for other diseases."
Dehumanizing Voice Technology: Phonetic & Experiential Consequences of Restricted Human-Machine Interaction,"The use of natural language and voice-based interfaces gradu-ally transforms
how consumers search, shop, and express their preferences. The current work
explores how changes in the syntactical structure of the interaction with
conversational interfaces (command vs. request based expression modalities)
negatively affects consumers' subjective task enjoyment and systematically
alters objective vocal features in the human voice. We show that requests (vs.
commands) lead to an in-crease in phonetic convergence and lower phonetic
latency, and ultimately a more natural task experience for consumers. To the
best of our knowledge, this is the first work docu-menting that altering the
input modality of how consumers interact with smart objects systematically
affects consumers' IoT experience. We provide evidence that altering the
required input to initiate a conversation with smart objects provokes
systematic changes both in terms of consumers' subjective experience and
objective phonetic changes in the human voice. The current research also makes
a methodological con-tribution by highlighting the unexplored potential of
feature extraction in human voice as a novel data format linking consumers'
vocal features during speech formation and their sub-jective task experiences.","['Christian Hildebrand', 'Donna Hoffman', 'Tom Novak']",2021-11-02 22:49:25+00:00,2021-11-02 22:49:25+00:00,http://arxiv.org/pdf/2111.01934v1,cs.AI,"['cs.AI', 'cs.HC']","dehumanizing voice technology: phonetic & experiential consequences of restricted human-machine interaction the use of natural language and voice-based interfaces gradu-ally transforms
how consumers search, shop, and express their preferences. the current work
explores how changes in the syntactical structure of the interaction with
conversational interfaces (command vs. request based expression modalities)
negatively affects consumers' subjective task enjoyment and systematically
alters objective vocal features in the human voice. we show that requests (vs.
commands) lead to an in-crease in phonetic convergence and lower phonetic
latency, and ultimately a more natural task experience for consumers. to the
best of our knowledge, this is the first work docu-menting that altering the
input modality of how consumers interact with smart objects systematically
affects consumers' iot experience. we provide evidence that altering the
required input to initiate a conversation with smart objects provokes
systematic changes both in terms of consumers' subjective experience and
objective phonetic changes in the human voice. the current research also makes
a methodological con-tribution by highlighting the unexplored potential of
feature extraction in human voice as a novel data format linking consumers'
vocal features during speech formation and their sub-jective task experiences."
Chronic Pain and Language: A Topic Modelling Approach to Personal Pain Descriptions,"Chronic pain is recognized as a major health problem, with impacts not only
at the economic, but also at the social, and individual levels. Being a private
and subjective experience, it is impossible to externally and impartially
experience, describe, and interpret chronic pain as a purely noxious stimulus
that would directly point to a causal agent and facilitate its mitigation,
contrary to acute pain, the assessment of which is usually straightforward.
Verbal communication is, thus, key to convey relevant information to health
professionals that would otherwise not be accessible to external entities,
namely, intrinsic qualities about the painful experience and the patient. We
propose and discuss a topic modelling approach to recognize patterns in verbal
descriptions of chronic pain, and use these patterns to quantify and qualify
experiences of pain. Our approaches allow for the extraction of novel insights
on chronic pain experiences from the obtained topic models and latent spaces.
We argue that our results are clinically relevant for the assessment and
management of chronic pain.","['Diogo A. P. Nunes', 'Joana Ferreira Gomes', 'Fani Neto', 'David Martins de Matos']",2021-09-01 14:31:16+00:00,2022-03-17 13:52:47+00:00,http://arxiv.org/pdf/2109.00402v2,cs.CL,"['cs.CL', 'cs.IR', 'q-bio.QM', 'I.2.7; I.5.3; I.5.4; J.3; J.4']","chronic pain and language: a topic modelling approach to personal pain descriptions chronic pain is recognized as a major health problem, with impacts not only
at the economic, but also at the social, and individual levels. being a private
and subjective experience, it is impossible to externally and impartially
experience, describe, and interpret chronic pain as a purely noxious stimulus
that would directly point to a causal agent and facilitate its mitigation,
contrary to acute pain, the assessment of which is usually straightforward.
verbal communication is, thus, key to convey relevant information to health
professionals that would otherwise not be accessible to external entities,
namely, intrinsic qualities about the painful experience and the patient. we
propose and discuss a topic modelling approach to recognize patterns in verbal
descriptions of chronic pain, and use these patterns to quantify and qualify
experiences of pain. our approaches allow for the extraction of novel insights
on chronic pain experiences from the obtained topic models and latent spaces.
we argue that our results are clinically relevant for the assessment and
management of chronic pain."
"Clustering of Pain Dynamics in Sickle Cell Disease from Sparse, Uneven Samples","Irregularly sampled time series data are common in a variety of fields. Many
typical methods for drawing insight from data fail in this case. Here we
attempt to generalize methods for clustering trajectories to irregularly and
sparsely sampled data. We first construct synthetic data sets, then propose and
assess four methods of data alignment to allow for application of spectral
clustering. We also repeat the same process for real data drawn from medical
records of patients with sickle cell disease -- patients whose subjective
experiences of pain were tracked for several months via a mobile app.
  We find that different methods for aligning irregularly sampled sparse data
sets can lead to different optimal numbers of clusters, even for synthetic data
with known properties. For the case of sickle cell disease, we find that three
clusters is a reasonable choice, and these appear to correspond to (1) a low
pain group with occasionally acute pain, (2) a group which experiences moderate
mean pain that fluctuates often from low to high, and (3) a group that
experiences persistent high levels of pain.
  Our results may help physicians and patients better understand and manage
patients' pain levels over time, and we expect that the methods we develop will
apply to a wide range of other data sources in medicine and beyond.","['Gary K. Nave Jr.', 'Swati Padhee', 'Amanuel Alambo', 'Tanvi Banerjee', 'Nirmish Shah', 'Daniel M. Abrams']",2021-08-31 16:43:57+00:00,2021-08-31 16:43:57+00:00,http://arxiv.org/pdf/2108.13963v1,q-bio.QM,"['q-bio.QM', 'cs.LG']","clustering of pain dynamics in sickle cell disease from sparse, uneven samples irregularly sampled time series data are common in a variety of fields. many
typical methods for drawing insight from data fail in this case. here we
attempt to generalize methods for clustering trajectories to irregularly and
sparsely sampled data. we first construct synthetic data sets, then propose and
assess four methods of data alignment to allow for application of spectral
clustering. we also repeat the same process for real data drawn from medical
records of patients with sickle cell disease -- patients whose subjective
experiences of pain were tracked for several months via a mobile app.
  we find that different methods for aligning irregularly sampled sparse data
sets can lead to different optimal numbers of clusters, even for synthetic data
with known properties. for the case of sickle cell disease, we find that three
clusters is a reasonable choice, and these appear to correspond to (1) a low
pain group with occasionally acute pain, (2) a group which experiences moderate
mean pain that fluctuates often from low to high, and (3) a group that
experiences persistent high levels of pain.
  our results may help physicians and patients better understand and manage
patients' pain levels over time, and we expect that the methods we develop will
apply to a wide range of other data sources in medicine and beyond."
A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine,"The quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. We examine
consciousness from the perspective of theoretical computer science (TCS), a
branch of mathematics concerned with understanding the underlying principles of
computation and complexity, including the implications and surprising
consequences of resource limitations. In the spirit of Alan Turing's simple yet
powerful definition of a computer, the Turing Machine (TM), and perspective of
computational complexity theory, we formalize a modified version of the Global
Workspace Theory (GWT) of consciousness originated by cognitive neuroscientist
Bernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre
Changeaux and others. We are not looking for a complex model of the brain nor
of cognition, but for a simple computational model of (the admittedly complex
concept of) consciousness. We do this by defining the Conscious Turing Machine
(CTM), also called a conscious AI, and then we define consciousness and related
notions in the CTM. While these are only mathematical (TCS) definitions, we
suggest why the CTM has the feeling of consciousness. The TCS perspective
provides a simple formal framework to employ tools from computational
complexity theory and machine learning to help us understand consciousness and
related concepts. Previously we explored high level explanations for the
feelings of pain and pleasure in the CTM. Here we consider three examples
related to vision (blindsight, inattentional blindness, and change blindness),
followed by discussions of dreams, free will, and altered states of
consciousness.","['Lenore Blum', 'Manuel Blum']",2021-07-29 01:47:52+00:00,2022-07-05 17:48:40+00:00,http://arxiv.org/pdf/2107.13704v10,cs.AI,"['cs.AI', 'q-bio.NC', '68-02', 'I.2; F.0']","a theory of consciousness from a theoretical computer science perspective: insights from the conscious turing machine the quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. we examine
consciousness from the perspective of theoretical computer science (tcs), a
branch of mathematics concerned with understanding the underlying principles of
computation and complexity, including the implications and surprising
consequences of resource limitations. in the spirit of alan turing's simple yet
powerful definition of a computer, the turing machine (tm), and perspective of
computational complexity theory, we formalize a modified version of the global
workspace theory (gwt) of consciousness originated by cognitive neuroscientist
bernard baars and further developed by him, stanislas dehaene, jean-pierre
changeaux and others. we are not looking for a complex model of the brain nor
of cognition, but for a simple computational model of (the admittedly complex
concept of) consciousness. we do this by defining the conscious turing machine
(ctm), also called a conscious ai, and then we define consciousness and related
notions in the ctm. while these are only mathematical (tcs) definitions, we
suggest why the ctm has the feeling of consciousness. the tcs perspective
provides a simple formal framework to employ tools from computational
complexity theory and machine learning to help us understand consciousness and
related concepts. previously we explored high level explanations for the
feelings of pain and pleasure in the ctm. here we consider three examples
related to vision (blindsight, inattentional blindness, and change blindness),
followed by discussions of dreams, free will, and altered states of
consciousness."
Reasoning about conscious experience with axiomatic and graphical mathematics,"We cast aspects of consciousness in axiomatic mathematical terms, using the
graphical calculus of general process theories (a.k.a symmetric monoidal
categories and Frobenius algebras therein). This calculus exploits the
ontological neutrality of process theories. A toy example using the axiomatic
calculus is given to show the power of this approach, recovering other aspects
of conscious experience, such as external and internal subjective distinction,
privacy or unreadability of personal subjective experience, and phenomenal
unity, one of the main issues for scientific studies of consciousness. In fact,
these features naturally arise from the compositional nature of axiomatic
calculus.","['Camilo Miguel Signorelli', 'Quanlong Wang', 'Bob Coecke']",2021-06-30 13:39:02+00:00,2021-06-30 13:39:02+00:00,http://arxiv.org/pdf/2106.16061v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","reasoning about conscious experience with axiomatic and graphical mathematics we cast aspects of consciousness in axiomatic mathematical terms, using the
graphical calculus of general process theories (a.k.a symmetric monoidal
categories and frobenius algebras therein). this calculus exploits the
ontological neutrality of process theories. a toy example using the axiomatic
calculus is given to show the power of this approach, recovering other aspects
of conscious experience, such as external and internal subjective distinction,
privacy or unreadability of personal subjective experience, and phenomenal
unity, one of the main issues for scientific studies of consciousness. in fact,
these features naturally arise from the compositional nature of axiomatic
calculus."
Conscious AI,"Recent advances in artificial intelligence (AI) have achieved human-scale
speed and accuracy for classification tasks. In turn, these capabilities have
made AI a viable replacement for many human activities that at their core
involve classification, such as basic mechanical and analytical tasks in
low-level service jobs. Current systems do not need to be conscious to
recognize patterns and classify them. However, for AI to progress to more
complicated tasks requiring intuition and empathy, it must develop capabilities
such as metathinking, creativity, and empathy akin to human self-awareness or
consciousness. We contend that such a paradigm shift is possible only through a
fundamental shift in the state of artificial intelligence toward consciousness,
a shift similar to what took place for humans through the process of natural
selection and evolution. As such, this paper aims to theoretically explore the
requirements for the emergence of consciousness in AI. It also provides a
principled understanding of how conscious AI can be detected and how it might
be manifested in contrast to the dominant paradigm that seeks to ultimately
create machines that are linguistically indistinguishable from humans.","['Hadi Esmaeilzadeh', 'Reza Vaezi']",2021-05-12 15:53:44+00:00,2022-05-20 21:27:08+00:00,http://arxiv.org/pdf/2105.07879v2,cs.AI,"['cs.AI', 'cs.CL', 'cs.CY']","conscious ai recent advances in artificial intelligence (ai) have achieved human-scale
speed and accuracy for classification tasks. in turn, these capabilities have
made ai a viable replacement for many human activities that at their core
involve classification, such as basic mechanical and analytical tasks in
low-level service jobs. current systems do not need to be conscious to
recognize patterns and classify them. however, for ai to progress to more
complicated tasks requiring intuition and empathy, it must develop capabilities
such as metathinking, creativity, and empathy akin to human self-awareness or
consciousness. we contend that such a paradigm shift is possible only through a
fundamental shift in the state of artificial intelligence toward consciousness,
a shift similar to what took place for humans through the process of natural
selection and evolution. as such, this paper aims to theoretically explore the
requirements for the emergence of consciousness in ai. it also provides a
principled understanding of how conscious ai can be detected and how it might
be manifested in contrast to the dominant paradigm that seeks to ultimately
create machines that are linguistically indistinguishable from humans."
To Trust or Not to Trust a Regressor: Estimating and Explaining Trustworthiness of Regression Predictions,"In hybrid human-AI systems, users need to decide whether or not to trust an
algorithmic prediction while the true error in the prediction is unknown. To
accommodate such settings, we introduce RETRO-VIZ, a method for (i) estimating
and (ii) explaining trustworthiness of regression predictions. It consists of
RETRO, a quantitative estimate of the trustworthiness of a prediction, and VIZ,
a visual explanation that helps users identify the reasons for the (lack of)
trustworthiness of a prediction. We find that RETRO-scores negatively correlate
with prediction error across 117 experimental settings, indicating that RETRO
provides a useful measure to distinguish trustworthy predictions from
untrustworthy ones. In a user study with 41 participants, we find that
VIZ-explanations help users identify whether a prediction is trustworthy or
not: on average, 95.1% of participants correctly select the more trustworthy
prediction, given a pair of predictions. In addition, an average of 75.6% of
participants can accurately describe why a prediction seems to be (not)
trustworthy. Finally, we find that the vast majority of users subjectively
experience RETRO-VIZ as a useful tool to assess the trustworthiness of
algorithmic predictions.","['Kim de Bie', 'Ana Lucic', 'Hinda Haned']",2021-04-14 17:04:20+00:00,2021-07-28 13:29:09+00:00,http://arxiv.org/pdf/2104.06982v2,cs.AI,['cs.AI'],"to trust or not to trust a regressor: estimating and explaining trustworthiness of regression predictions in hybrid human-ai systems, users need to decide whether or not to trust an
algorithmic prediction while the true error in the prediction is unknown. to
accommodate such settings, we introduce retro-viz, a method for (i) estimating
and (ii) explaining trustworthiness of regression predictions. it consists of
retro, a quantitative estimate of the trustworthiness of a prediction, and viz,
a visual explanation that helps users identify the reasons for the (lack of)
trustworthiness of a prediction. we find that retro-scores negatively correlate
with prediction error across 117 experimental settings, indicating that retro
provides a useful measure to distinguish trustworthy predictions from
untrustworthy ones. in a user study with 41 participants, we find that
viz-explanations help users identify whether a prediction is trustworthy or
not: on average, 95.1% of participants correctly select the more trustworthy
prediction, given a pair of predictions. in addition, an average of 75.6% of
participants can accurately describe why a prediction seems to be (not)
trustworthy. finally, we find that the vast majority of users subjectively
experience retro-viz as a useful tool to assess the trustworthiness of
algorithmic predictions."
"What Is Consciousness? Artificial Intelligence, Real Intelligence, Quantum Mind, And Qualia","We approach the question ""What is Consciousness?"" in a new way, not as
Descartes' ""systematic doubt"", but as how organisms find their way in their
world. Finding one's way involves finding possible uses of features of the
world that might be beneficial or avoiding those that might be harmful.
""Possible uses of X to accomplish Y"" are ""Affordances"". The number of uses of X
is indefinite (or unknown), the different uses are unordered, are not listable,
and are not deducible from one another. All biological adaptations are either
affordances seized by heritable variation and selection or, far faster, by the
organism acting in its world finding uses of X to accomplish Y. Based on this,
we reach rather astonishing conclusions: (1) Artificial general intelligence
based on universal Turing machines (UTMs) is not possible, since UTMs cannot
""find"" novel affordances. (2) Brain-mind is not purely classical physics for no
classical physics system can be an analogue computer whose dynamical behaviour
can be isomorphic to ""possible uses"". (3) Brain mind must be partly
quantum-supported by increasing evidence at 6.0 sigma to 7.3 sigma. (4) Based
on Heisenberg's interpretation of the quantum state as ""potentia"" converted to
""actuals"" by measurement, where this interpretation is not a substance dualism,
a natural hypothesis is that mind actualizes potentia. This is supported at 5.2
sigma. Then mind's actualizations of entangled brain-mind-world states are
experienced as qualia and allow ""seeing"" or ""perceiving"" of uses of X to
accomplish Y. We can and do jury-rig. Computers cannot. (5) Beyond familiar
quantum computers, we discuss the potentialities of trans-Turing-systems.","['Stuart A. Kauffman', 'Andrea Roli']",2021-04-12 11:20:21+00:00,2022-06-29 16:20:02+00:00,http://arxiv.org/pdf/2106.15515v4,physics.soc-ph,"['physics.soc-ph', 'cs.AI', 'physics.bio-ph', 'physics.hist-ph']","what is consciousness? artificial intelligence, real intelligence, quantum mind, and qualia we approach the question ""what is consciousness?"" in a new way, not as
descartes' ""systematic doubt"", but as how organisms find their way in their
world. finding one's way involves finding possible uses of features of the
world that might be beneficial or avoiding those that might be harmful.
""possible uses of x to accomplish y"" are ""affordances"". the number of uses of x
is indefinite (or unknown), the different uses are unordered, are not listable,
and are not deducible from one another. all biological adaptations are either
affordances seized by heritable variation and selection or, far faster, by the
organism acting in its world finding uses of x to accomplish y. based on this,
we reach rather astonishing conclusions: (1) artificial general intelligence
based on universal turing machines (utms) is not possible, since utms cannot
""find"" novel affordances. (2) brain-mind is not purely classical physics for no
classical physics system can be an analogue computer whose dynamical behaviour
can be isomorphic to ""possible uses"". (3) brain mind must be partly
quantum-supported by increasing evidence at 6.0 sigma to 7.3 sigma. (4) based
on heisenberg's interpretation of the quantum state as ""potentia"" converted to
""actuals"" by measurement, where this interpretation is not a substance dualism,
a natural hypothesis is that mind actualizes potentia. this is supported at 5.2
sigma. then mind's actualizations of entangled brain-mind-world states are
experienced as qualia and allow ""seeing"" or ""perceiving"" of uses of x to
accomplish y. we can and do jury-rig. computers cannot. (5) beyond familiar
quantum computers, we discuss the potentialities of trans-turing-systems."
The General Theory of General Intelligence: A Pragmatic Patternist Perspective,"A multi-decade exploration into the theoretical foundations of artificial and
natural general intelligence, which has been expressed in a series of books and
papers and used to guide a series of practical and research-prototype software
systems, is reviewed at a moderate level of detail. The review covers
underlying philosophies (patternist philosophy of mind, foundational
phenomenological and logical ontology), formalizations of the concept of
intelligence, and a proposed high level architecture for AGI systems partly
driven by these formalizations and philosophies. The implementation of specific
cognitive processes such as logical reasoning, program learning, clustering and
attention allocation in the context and language of this high level
architecture is considered, as is the importance of a common (e.g. typed
metagraph based) knowledge representation for enabling ""cognitive synergy""
between the various processes. The specifics of human-like cognitive
architecture are presented as manifestations of these general principles, and
key aspects of machine consciousness and machine ethics are also treated in
this context. Lessons for practical implementation of advanced AGI in
frameworks such as OpenCog Hyperon are briefly considered.",['Ben Goertzel'],2021-03-28 10:11:25+00:00,2021-04-04 04:30:42+00:00,http://arxiv.org/pdf/2103.15100v3,cs.AI,['cs.AI'],"the general theory of general intelligence: a pragmatic patternist perspective a multi-decade exploration into the theoretical foundations of artificial and
natural general intelligence, which has been expressed in a series of books and
papers and used to guide a series of practical and research-prototype software
systems, is reviewed at a moderate level of detail. the review covers
underlying philosophies (patternist philosophy of mind, foundational
phenomenological and logical ontology), formalizations of the concept of
intelligence, and a proposed high level architecture for agi systems partly
driven by these formalizations and philosophies. the implementation of specific
cognitive processes such as logical reasoning, program learning, clustering and
attention allocation in the context and language of this high level
architecture is considered, as is the importance of a common (e.g. typed
metagraph based) knowledge representation for enabling ""cognitive synergy""
between the various processes. the specifics of human-like cognitive
architecture are presented as manifestations of these general principles, and
key aspects of machine consciousness and machine ethics are also treated in
this context. lessons for practical implementation of advanced agi in
frameworks such as opencog hyperon are briefly considered."
"What is it Like to Be a Bot: Simulated, Situated, Structurally Coherent Qualia (S3Q) Theory of Consciousness","A novel representationalist theory of consciousness is presented that is
grounded in neuroscience and provides a path to artificially conscious
computing. Central to the theory are representational affordances of the
conscious experience based on the generation of qualia, the fundamental unit of
the conscious representation. The current approach is focused on understanding
the balance of simulation, situatedness, and structural coherence of artificial
conscious representations through converging evidence from neuroscientific and
modeling experiments. Representations instantiating a suitable balance of
situated and structurally coherent simulation-based qualia are hypothesized to
afford the agent the flexibilities required to succeed in rapidly changing
environments.","['K. Schmidt', 'J. Culbertson', 'C. Cox', 'H. S. Clouse', 'O. Larue', 'M. Molineaux', 'S. Rogers']",2021-03-13 02:07:13+00:00,2021-03-13 02:07:13+00:00,http://arxiv.org/pdf/2103.12638v1,q-bio.NC,['q-bio.NC'],"what is it like to be a bot: simulated, situated, structurally coherent qualia (s3q) theory of consciousness a novel representationalist theory of consciousness is presented that is
grounded in neuroscience and provides a path to artificially conscious
computing. central to the theory are representational affordances of the
conscious experience based on the generation of qualia, the fundamental unit of
the conscious representation. the current approach is focused on understanding
the balance of simulation, situatedness, and structural coherence of artificial
conscious representations through converging evidence from neuroscientific and
modeling experiments. representations instantiating a suitable balance of
situated and structurally coherent simulation-based qualia are hypothesized to
afford the agent the flexibilities required to succeed in rapidly changing
environments."
Disambiguating Affective Stimulus Associations for Robot Perception and Dialogue,"Effectively recognising and applying emotions to interactions is a highly
desirable trait for social robots. Implicitly understanding how subjects
experience different kinds of actions and objects in the world is crucial for
natural HRI interactions, with the possibility to perform positive actions and
avoid negative actions. In this paper, we utilize the NICO robot's appearance
and capabilities to give the NICO the ability to model a coherent affective
association between a perceived auditory stimulus and a temporally asynchronous
emotion expression. This is done by combining evaluations of emotional valence
from vision and language. NICO uses this information to make decisions about
when to extend conversations in order to accrue more affective information if
the representation of the association is not coherent. Our primary contribution
is providing a NICO robot with the ability to learn the affective associations
between a perceived auditory stimulus and an emotional expression. NICO is able
to do this for both individual subjects and specific stimuli, with the aid of
an emotion-driven dialogue system that rectifies emotional expression
incoherences. The robot is then able to use this information to determine a
subject's enjoyment of perceived auditory stimuli in a real HRI scenario.","['Henrique Siqueira', 'Alexander Sutherland', 'Pablo Barros', 'Mattias Kerzel', 'Sven Magg', 'Stefan Wermter']",2021-03-05 20:55:48+00:00,2021-03-05 20:55:48+00:00,http://arxiv.org/pdf/2103.03940v1,cs.RO,"['cs.RO', 'cs.CL', 'cs.CV']","disambiguating affective stimulus associations for robot perception and dialogue effectively recognising and applying emotions to interactions is a highly
desirable trait for social robots. implicitly understanding how subjects
experience different kinds of actions and objects in the world is crucial for
natural hri interactions, with the possibility to perform positive actions and
avoid negative actions. in this paper, we utilize the nico robot's appearance
and capabilities to give the nico the ability to model a coherent affective
association between a perceived auditory stimulus and a temporally asynchronous
emotion expression. this is done by combining evaluations of emotional valence
from vision and language. nico uses this information to make decisions about
when to extend conversations in order to accrue more affective information if
the representation of the association is not coherent. our primary contribution
is providing a nico robot with the ability to learn the affective associations
between a perceived auditory stimulus and an emotional expression. nico is able
to do this for both individual subjects and specific stimuli, with the aid of
an emotion-driven dialogue system that rectifies emotional expression
incoherences. the robot is then able to use this information to determine a
subject's enjoyment of perceived auditory stimuli in a real hri scenario."
Occipital and left temporal instantaneous amplitude and frequency oscillations correlated with access and phenomenal consciousness,"Given the hard problem of consciousness (Chalmers, 1995) there are no brain
electrophysiological correlates of the subjective experience (the felt quality
of redness or the redness of red, the experience of dark and light, the quality
of depth in a visual field, the sound of a clarinet, the smell of mothball,
bodily sensations from pains to orgasms, mental images that are conjured up
internally, the felt quality of emotion, the experience of a stream of
conscious thought or the phenomenology of thought). However, there are brain
occipital and left temporal electrophysiological correlates of the subjective
experience (Pereira, 2015). Notwithstanding, as evoked signal, the change in
event-related brain potentials phase (frequency is the change in phase over
time) is instantaneous, that is, the frequency will transiently be infinite: a
transient peak in frequency (positive or negative), if any, is instantaneous in
electroencephalogram averaging or filtering that the event-related brain
potentials required and the underlying structure of the event-related brain
potentials in the frequency domain cannot be accounted, for example, by the
Wavelet Transform (WT) or the Fast Fourier Transform (FFT) analysis, because
they require that frequency is derived by convolution rather than by
differentiation. However, as I show in the current original research report,
one suitable method for analyse the instantaneous change in event-related brain
potentials phase and accounted for a transient peak in frequency (positive or
negative), if any, in the underlying structure of the event-related brain
potentials is the Empirical Mode Decomposition with post processing (Xie et
al., 2014) Ensemble Empirical Mode Decomposition (postEEMD) and Hilbert-Huang
Transform (HHT).",['Vitor Manuel Dinis Pereira'],2020-12-26 16:30:40+00:00,2021-03-05 18:36:30+00:00,http://arxiv.org/pdf/2101.10056v3,q-bio.NC,['q-bio.NC'],"occipital and left temporal instantaneous amplitude and frequency oscillations correlated with access and phenomenal consciousness given the hard problem of consciousness (chalmers, 1995) there are no brain
electrophysiological correlates of the subjective experience (the felt quality
of redness or the redness of red, the experience of dark and light, the quality
of depth in a visual field, the sound of a clarinet, the smell of mothball,
bodily sensations from pains to orgasms, mental images that are conjured up
internally, the felt quality of emotion, the experience of a stream of
conscious thought or the phenomenology of thought). however, there are brain
occipital and left temporal electrophysiological correlates of the subjective
experience (pereira, 2015). notwithstanding, as evoked signal, the change in
event-related brain potentials phase (frequency is the change in phase over
time) is instantaneous, that is, the frequency will transiently be infinite: a
transient peak in frequency (positive or negative), if any, is instantaneous in
electroencephalogram averaging or filtering that the event-related brain
potentials required and the underlying structure of the event-related brain
potentials in the frequency domain cannot be accounted, for example, by the
wavelet transform (wt) or the fast fourier transform (fft) analysis, because
they require that frequency is derived by convolution rather than by
differentiation. however, as i show in the current original research report,
one suitable method for analyse the instantaneous change in event-related brain
potentials phase and accounted for a transient peak in frequency (positive or
negative), if any, in the underlying structure of the event-related brain
potentials is the empirical mode decomposition with post processing (xie et
al., 2014) ensemble empirical mode decomposition (posteemd) and hilbert-huang
transform (hht)."
Digital me ontology and ethics,"This paper addresses ontology and ethics of an AI agent called digital me. We
define digital me as autonomous, decision-making, and learning agent,
representing an individual and having practically immortal own life. It is
assumed that digital me is equipped with the big-five personality model,
ensuring that it provides a model of some aspects of a strong AI:
consciousness, free will, and intentionality. As computer-based personality
judgments are more accurate than those made by humans, digital me can judge the
personality of the individual represented by the digital me, other individuals'
personalities, and other digital me-s. We describe seven ontological qualities
of digital me: a) double-layer status of Digital Being versus digital me, b)
digital me versus real me, c) mind-digital me and body-digital me, d) digital
me versus doppelganger (shadow digital me), e) non-human time concept, f)
social quality, g) practical immortality. We argue that with the advancement of
AI's sciences and technologies, there exist two digital me thresholds. The
first threshold defines digital me having some (rudimentarily) form of
consciousness, free will, and intentionality. The second threshold assumes that
digital me is equipped with moral learning capabilities, implying that, in
principle, digital me could develop their own ethics which significantly
differs from human's understanding of ethics. Finally we discuss the
implications of digital me metaethics, normative and applied ethics, the
implementation of the Golden Rule in digital me-s, and we suggest two sets of
normative principles for digital me: consequentialist and duty based digital me
principles.","['Ljupco Kocarev', 'Jasna Koteska']",2020-12-22 09:54:04+00:00,2020-12-22 09:54:04+00:00,http://arxiv.org/pdf/2012.14325v1,cs.AI,"['cs.AI', 'cs.CY']","digital me ontology and ethics this paper addresses ontology and ethics of an ai agent called digital me. we
define digital me as autonomous, decision-making, and learning agent,
representing an individual and having practically immortal own life. it is
assumed that digital me is equipped with the big-five personality model,
ensuring that it provides a model of some aspects of a strong ai:
consciousness, free will, and intentionality. as computer-based personality
judgments are more accurate than those made by humans, digital me can judge the
personality of the individual represented by the digital me, other individuals'
personalities, and other digital me-s. we describe seven ontological qualities
of digital me: a) double-layer status of digital being versus digital me, b)
digital me versus real me, c) mind-digital me and body-digital me, d) digital
me versus doppelganger (shadow digital me), e) non-human time concept, f)
social quality, g) practical immortality. we argue that with the advancement of
ai's sciences and technologies, there exist two digital me thresholds. the
first threshold defines digital me having some (rudimentarily) form of
consciousness, free will, and intentionality. the second threshold assumes that
digital me is equipped with moral learning capabilities, implying that, in
principle, digital me could develop their own ethics which significantly
differs from human's understanding of ethics. finally we discuss the
implications of digital me metaethics, normative and applied ethics, the
implementation of the golden rule in digital me-s, and we suggest two sets of
normative principles for digital me: consequentialist and duty based digital me
principles."
An Artificial Consciousness Model and its relations with Philosophy of Mind,"This work seeks to study the beneficial properties that an autonomous agent
can obtain by implementing a cognitive architecture similar to the one of
conscious beings. Along this document, a conscious model of autonomous agent
based in a global workspace architecture is presented. We describe how this
agent is viewed from different perspectives of philosophy of mind, being
inspired by their ideas. The goal of this model is to create autonomous agents
able to navigate within an environment composed of multiple independent
magnitudes, adapting to its surroundings in order to find the best possible
position in base of its inner preferences. The purpose of the model is to test
the effectiveness of many cognitive mechanisms that are incorporated, such as
an attention mechanism for magnitude selection, pos-session of inner feelings
and preferences, usage of a memory system to storage beliefs and past
experiences, and incorporating a global workspace which controls and integrates
information processed by all the subsystem of the model. We show in a large
experiment set how an autonomous agent can benefit from having a cognitive
architecture such as the one described.","['Eduardo C. Garrido-Merchán', 'Martin Molina', 'Francisco M. Mendoza']",2020-11-30 00:24:17+00:00,2020-12-01 17:27:10+00:00,http://arxiv.org/pdf/2011.14475v2,cs.AI,['cs.AI'],"an artificial consciousness model and its relations with philosophy of mind this work seeks to study the beneficial properties that an autonomous agent
can obtain by implementing a cognitive architecture similar to the one of
conscious beings. along this document, a conscious model of autonomous agent
based in a global workspace architecture is presented. we describe how this
agent is viewed from different perspectives of philosophy of mind, being
inspired by their ideas. the goal of this model is to create autonomous agents
able to navigate within an environment composed of multiple independent
magnitudes, adapting to its surroundings in order to find the best possible
position in base of its inner preferences. the purpose of the model is to test
the effectiveness of many cognitive mechanisms that are incorporated, such as
an attention mechanism for magnitude selection, pos-session of inner feelings
and preferences, usage of a memory system to storage beliefs and past
experiences, and incorporating a global workspace which controls and integrates
information processed by all the subsystem of the model. we show in a large
experiment set how an autonomous agent can benefit from having a cognitive
architecture such as the one described."
A Theoretical Computer Science Perspective on Consciousness,"The quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. This paper
studies consciousness from the perspective of theoretical computer science. It
formalizes the Global Workspace Theory (GWT) originated by cognitive
neuroscientist Bernard Baars and further developed by him, Stanislas Dehaene,
and others. Our major contribution lies in the precise formal definition of a
Conscious Turing Machine (CTM), also called a Conscious AI. We define the CTM
in the spirit of Alan Turing's simple yet powerful definition of a computer,
the Turing Machine (TM). We are not looking for a complex model of the brain
nor of cognition but for a simple model of (the admittedly complex concept of)
consciousness. After formally defining CTM, we give a formal definition of
consciousness in CTM. We then suggest why the CTM has the feeling of
consciousness. The reasonableness of the definitions and explanations can be
judged by how well they agree with commonly accepted intuitive concepts of
human consciousness, the breadth of related concepts that the model explains
easily and naturally, and the extent of its agreement with scientific evidence.","['Manuel Blum', 'Lenore Blum']",2020-11-18 11:28:37+00:00,2021-08-23 18:40:52+00:00,http://arxiv.org/pdf/2011.09850v4,cs.AI,"['cs.AI', '68T01, 68T40, 68242,', 'F.0; I.2']","a theoretical computer science perspective on consciousness the quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. this paper
studies consciousness from the perspective of theoretical computer science. it
formalizes the global workspace theory (gwt) originated by cognitive
neuroscientist bernard baars and further developed by him, stanislas dehaene,
and others. our major contribution lies in the precise formal definition of a
conscious turing machine (ctm), also called a conscious ai. we define the ctm
in the spirit of alan turing's simple yet powerful definition of a computer,
the turing machine (tm). we are not looking for a complex model of the brain
nor of cognition but for a simple model of (the admittedly complex concept of)
consciousness. after formally defining ctm, we give a formal definition of
consciousness in ctm. we then suggest why the ctm has the feeling of
consciousness. the reasonableness of the definitions and explanations can be
judged by how well they agree with commonly accepted intuitive concepts of
human consciousness, the breadth of related concepts that the model explains
easily and naturally, and the extent of its agreement with scientific evidence."
Minimizing Robot Navigation-Graph For Position-Based Predictability By Humans,"In situations where humans and robots are moving in the same space whilst
performing their own tasks, predictable paths taken by mobile robots can not
only make the environment feel safer, but humans can also help with the
navigation in the space by avoiding path conflicts or not blocking the way. So
predictable paths become vital. The cognitive effort for the human to predict
the robot's path becomes untenable as the number of robots increases. As the
number of humans increase, it also makes it harder for the robots to move while
considering the motion of multiple humans. Additionally, if new people are
entering the space -- like in restaurants, banks, and hospitals -- they would
have less familiarity with the trajectories typically taken by the robots; this
further increases the needs for predictable robot motion along paths.
  With this in mind, we propose to minimize the navigation-graph of the robot
for position-based predictability, which is predictability from just the
current position of the robot. This is important since the human cannot be
expected to keep track of the goals and prior actions of the robot in addition
to doing their own tasks. In this paper, we define measures for position-based
predictability, then present and evaluate a hill-climbing algorithm to minimize
the navigation-graph (directed graph) of robot motion. This is followed by the
results of our human-subject experiments which support our proposed
methodology.","['Sriram Gopalakrishnan', 'Subbarao Kambhampati']",2020-10-28 22:09:10+00:00,2022-01-11 23:28:57+00:00,http://arxiv.org/pdf/2010.15255v2,cs.AI,['cs.AI'],"minimizing robot navigation-graph for position-based predictability by humans in situations where humans and robots are moving in the same space whilst
performing their own tasks, predictable paths taken by mobile robots can not
only make the environment feel safer, but humans can also help with the
navigation in the space by avoiding path conflicts or not blocking the way. so
predictable paths become vital. the cognitive effort for the human to predict
the robot's path becomes untenable as the number of robots increases. as the
number of humans increase, it also makes it harder for the robots to move while
considering the motion of multiple humans. additionally, if new people are
entering the space -- like in restaurants, banks, and hospitals -- they would
have less familiarity with the trajectories typically taken by the robots; this
further increases the needs for predictable robot motion along paths.
  with this in mind, we propose to minimize the navigation-graph of the robot
for position-based predictability, which is predictability from just the
current position of the robot. this is important since the human cannot be
expected to keep track of the goals and prior actions of the robot in addition
to doing their own tasks. in this paper, we define measures for position-based
predictability, then present and evaluate a hill-climbing algorithm to minimize
the navigation-graph (directed graph) of robot motion. this is followed by the
results of our human-subject experiments which support our proposed
methodology."
A Blast From the Past: Personalizing Predictions of Video-Induced Emotions using Personal Memories as Context,"A key challenge in the accurate prediction of viewers' emotional responses to
video stimuli in real-world applications is accounting for person- and
situation-specific variation. An important contextual influence shaping
individuals' subjective experience of a video is the personal memories that it
triggers in them. Prior research has found that this memory influence explains
more variation in video-induced emotions than other contextual variables
commonly used for personalizing predictions, such as viewers' demographics or
personality. In this article, we show that (1) automatic analysis of text
describing their video-triggered memories can account for variation in viewers'
emotional responses, and (2) that combining such an analysis with that of a
video's audiovisual content enhances the accuracy of automatic predictions. We
discuss the relevance of these findings for improving on state of the art
approaches to automated affective video analysis in personalized contexts.","['Bernd Dudzik', 'Joost Broekens', 'Mark Neerincx', 'Hayley Hung']",2020-08-27 13:06:10+00:00,2020-08-27 13:06:10+00:00,http://arxiv.org/pdf/2008.12096v1,cs.HC,"['cs.HC', 'cs.AI']","a blast from the past: personalizing predictions of video-induced emotions using personal memories as context a key challenge in the accurate prediction of viewers' emotional responses to
video stimuli in real-world applications is accounting for person- and
situation-specific variation. an important contextual influence shaping
individuals' subjective experience of a video is the personal memories that it
triggers in them. prior research has found that this memory influence explains
more variation in video-induced emotions than other contextual variables
commonly used for personalizing predictions, such as viewers' demographics or
personality. in this article, we show that (1) automatic analysis of text
describing their video-triggered memories can account for variation in viewers'
emotional responses, and (2) that combining such an analysis with that of a
video's audiovisual content enhances the accuracy of automatic predictions. we
discuss the relevance of these findings for improving on state of the art
approaches to automated affective video analysis in personalized contexts."
On the Evolution of Subjective Experience,"Subjective Experience (SE) is part of the ancient mind-body problem, which
continues to be one of deepest mysteries of science. Despite major advances in
many fields, there is still no plausible causal link between SE and its
realization in the body. The core issue is the incompatibility of objective
(3rd person) public science with subjective (1st person) private experience.
Any scientific approach to SE assumes that it arose from extended evolutionary
processes and that examining evolutionary history should help us understand it.
While the core mystery remains, converging evidence from theoretical,
experimental, and computational studies yields strong constraints on SE and
some suggestions for further research. All animals confront many of the same
fitness challenges. They all need some kind of internal model to relate their
life goals and actionable sensed information to action. We understand the
evolution of the bodily aspects of human perception and emotion, but not the
SE. The first evolutionary evidence for SE appears in vertebrates and much of
its neural substrate and simulation mechanism is preserved in mammals and
humans. People exhibit the same phenomena, but there are remaining mysteries of
everyday experience that are demonstrably incompatible with current
neuroscience. In spite of this limitation, there is considerable progress on
understanding the role of SE in the success of prostheses.",['Jerome A. Feldman'],2020-08-18 17:54:39+00:00,2022-03-25 18:16:35+00:00,http://arxiv.org/pdf/2008.08073v3,q-bio.NC,"['q-bio.NC', 'cs.NE', 'q-bio.PE']","on the evolution of subjective experience subjective experience (se) is part of the ancient mind-body problem, which
continues to be one of deepest mysteries of science. despite major advances in
many fields, there is still no plausible causal link between se and its
realization in the body. the core issue is the incompatibility of objective
(3rd person) public science with subjective (1st person) private experience.
any scientific approach to se assumes that it arose from extended evolutionary
processes and that examining evolutionary history should help us understand it.
while the core mystery remains, converging evidence from theoretical,
experimental, and computational studies yields strong constraints on se and
some suggestions for further research. all animals confront many of the same
fitness challenges. they all need some kind of internal model to relate their
life goals and actionable sensed information to action. we understand the
evolution of the bodily aspects of human perception and emotion, but not the
se. the first evolutionary evidence for se appears in vertebrates and much of
its neural substrate and simulation mechanism is preserved in mammals and
humans. people exhibit the same phenomena, but there are remaining mysteries of
everyday experience that are demonstrably incompatible with current
neuroscience. in spite of this limitation, there is considerable progress on
understanding the role of se in the success of prostheses."
Whole-brain models to explore altered states of consciousness from the bottom up,"The scope of human consciousness includes states departing from what most of
us experience as ordinary wakefulness. These altered states of consciousness
constitute a prime opportunity to study how global changes in brain activity
relate to different varieties of subjective experience. We consider the problem
of explaining how global signatures of altered consciousness arise from the
interplay between large-scale connectivity and local dynamical rules that can
be traced to known properties of neural tissue. For this purpose, we advocate a
research program aimed at bridging the gap between bottom-up generative models
of whole-brain activity and the top-down signatures proposed by theories of
consciousness. Throughout this paper, we define altered states of
consciousness, discuss relevant signatures of consciousness observed in brain
activity, and introduce whole-brain models to explore the mechanisms of altered
consciousness from the bottom-up. We discuss the potential of our proposal in
view of the current state of the art, give specific examples of how this
research agenda might play out, and emphasise how a systematic investigation of
altered states of consciousness via bottom-up modelling may help us better
understand the biophysical, informational, and dynamical underpinnings of
consciousness.","['Rodrigo Cofré', 'Rubén Herzog', 'Pedro A. M. Mediano', 'Juan Piccinini', 'Fernando E. Rosas', 'Yonatan Sanz Perl', 'Enzo Tagliazucchi']",2020-08-06 17:54:37+00:00,2020-08-06 17:54:37+00:00,http://arxiv.org/pdf/2008.02788v1,q-bio.NC,['q-bio.NC'],"whole-brain models to explore altered states of consciousness from the bottom up the scope of human consciousness includes states departing from what most of
us experience as ordinary wakefulness. these altered states of consciousness
constitute a prime opportunity to study how global changes in brain activity
relate to different varieties of subjective experience. we consider the problem
of explaining how global signatures of altered consciousness arise from the
interplay between large-scale connectivity and local dynamical rules that can
be traced to known properties of neural tissue. for this purpose, we advocate a
research program aimed at bridging the gap between bottom-up generative models
of whole-brain activity and the top-down signatures proposed by theories of
consciousness. throughout this paper, we define altered states of
consciousness, discuss relevant signatures of consciousness observed in brain
activity, and introduce whole-brain models to explore the mechanisms of altered
consciousness from the bottom-up. we discuss the potential of our proposal in
view of the current state of the art, give specific examples of how this
research agenda might play out, and emphasise how a systematic investigation of
altered states of consciousness via bottom-up modelling may help us better
understand the biophysical, informational, and dynamical underpinnings of
consciousness."
ConsciousControlFlow(CCF): A Demonstration for conscious Artificial Intelligence,"In this demo, we present ConsciousControlFlow(CCF), a prototype system to
demonstrate conscious Artificial Intelligence (AI). The system is based on the
computational model for consciousness and the hierarchy of needs. CCF supports
typical scenarios to show the behaviors and the mental activities of conscious
AI. We demonstrate that CCF provides a useful tool for effective machine
consciousness demonstration and human behavior study assistance.","['Hongzhi Wang', 'Bozhou Chen', 'Yueyang Xu', 'Kaixin Zhang', 'Shengwen Zheng']",2020-04-09 06:28:26+00:00,2021-02-06 02:43:24+00:00,http://arxiv.org/pdf/2004.04376v2,cs.AI,['cs.AI'],"consciouscontrolflow(ccf): a demonstration for conscious artificial intelligence in this demo, we present consciouscontrolflow(ccf), a prototype system to
demonstrate conscious artificial intelligence (ai). the system is based on the
computational model for consciousness and the hierarchy of needs. ccf supports
typical scenarios to show the behaviors and the mental activities of conscious
ai. we demonstrate that ccf provides a useful tool for effective machine
consciousness demonstration and human behavior study assistance."
Reward Shaping for Human Learning via Inverse Reinforcement Learning,"Humans are spectacular reinforcement learners, constantly learning from and
adjusting to experience and feedback. Unfortunately, this doesn't necessarily
mean humans are fast learners. When tasks are challenging, learning can become
unacceptably slow. Fortunately, humans do not have to learn tabula rasa, and
learning speed can be greatly increased with learning aids. In this work we
validate a new type of learning aid -- reward shaping for humans via inverse
reinforcement learning (IRL). The goal of this aid is to increase the speed
with which humans can learn good policies for specific tasks. Furthermore this
approach compliments alternative machine learning techniques such as safety
features that try to prevent individuals from making poor decisions. To achieve
our results we first extend a well known IRL algorithm via kernel methods.
Afterwards we conduct two human subjects experiments using an online game where
players have limited time to learn a good policy. We show with statistical
significance that players who receive our learning aid are able to approach
desired policies more quickly than the control group.","['Mark A. Rucker', 'Layne T. Watson', 'Matthew S. Gerber', 'Laura E. Barnes']",2020-02-25 14:44:25+00:00,2022-12-15 16:00:42+00:00,http://arxiv.org/pdf/2002.10904v3,cs.LG,"['cs.LG', 'stat.ML']","reward shaping for human learning via inverse reinforcement learning humans are spectacular reinforcement learners, constantly learning from and
adjusting to experience and feedback. unfortunately, this doesn't necessarily
mean humans are fast learners. when tasks are challenging, learning can become
unacceptably slow. fortunately, humans do not have to learn tabula rasa, and
learning speed can be greatly increased with learning aids. in this work we
validate a new type of learning aid -- reward shaping for humans via inverse
reinforcement learning (irl). the goal of this aid is to increase the speed
with which humans can learn good policies for specific tasks. furthermore this
approach compliments alternative machine learning techniques such as safety
features that try to prevent individuals from making poor decisions. to achieve
our results we first extend a well known irl algorithm via kernel methods.
afterwards we conduct two human subjects experiments using an online game where
players have limited time to learn a good policy. we show with statistical
significance that players who receive our learning aid are able to approach
desired policies more quickly than the control group."
Synaptic clock as a neural substrate of consciousness,"In this theoretical work the temporal aspect of consciousness is analyzed. We
start from the notion that while conscious experience seems to change
constantly, yet for any of its contents to be consciously perceived they must
last for some non-zero duration of time, which appears to constitute certain
conflict. We posit that, in terms of phenomenological analysis of
consciousness, the temporal aspect, and this apparent conflict in particular,
might be the most basic property, likely inherent to any conceivable form of
consciousness. It is then outlined how taking this perspective offers a
concrete way of relating the properties of consciousness directly to the neural
plasticity mechanisms of learning and memory, and specifying how exactly
subjective experience might be related to processes of information integration.
In particular, we propose synaptic clock to constitute a content-specific
neural substrate of consciousness, explaining how it would correspond to this
temporal aspect. Then, we propose a viewpoint, in which moments of subjective
time have different durations, depending on the type of information processed,
proportional to the time units of corresponding synaptic clocks, and being in
principle different for different brain regions and nervous systems in
different animal species. Relation and possible contributions of this viewpoint
to the extensional model of time consciousness are discussed. Finally, we
consider the two alternative views on the structure of consciousness, namely a
static and a dynamic one, and argue in favor of the latter, proposing that
consciousness can be best understood if change is considered its only
dimension.",['Bartosz Jura'],2020-02-18 16:43:58+00:00,2022-03-05 21:16:46+00:00,http://arxiv.org/pdf/2002.07716v2,q-bio.NC,['q-bio.NC'],"synaptic clock as a neural substrate of consciousness in this theoretical work the temporal aspect of consciousness is analyzed. we
start from the notion that while conscious experience seems to change
constantly, yet for any of its contents to be consciously perceived they must
last for some non-zero duration of time, which appears to constitute certain
conflict. we posit that, in terms of phenomenological analysis of
consciousness, the temporal aspect, and this apparent conflict in particular,
might be the most basic property, likely inherent to any conceivable form of
consciousness. it is then outlined how taking this perspective offers a
concrete way of relating the properties of consciousness directly to the neural
plasticity mechanisms of learning and memory, and specifying how exactly
subjective experience might be related to processes of information integration.
in particular, we propose synaptic clock to constitute a content-specific
neural substrate of consciousness, explaining how it would correspond to this
temporal aspect. then, we propose a viewpoint, in which moments of subjective
time have different durations, depending on the type of information processed,
proportional to the time units of corresponding synaptic clocks, and being in
principle different for different brain regions and nervous systems in
different animal species. relation and possible contributions of this viewpoint
to the extensional model of time consciousness are discussed. finally, we
consider the two alternative views on the structure of consciousness, namely a
static and a dynamic one, and argue in favor of the latter, proposing that
consciousness can be best understood if change is considered its only
dimension."
A Machine Consciousness architecture based on Deep Learning and Gaussian Processes,"Recent developments in machine learning have pushed the tasks that machines
can do outside the boundaries of what was thought to be possible years ago.
Methodologies such as deep learning or generative models have achieved complex
tasks such as generating art pictures or literature automatically. On the other
hand, symbolic resources have also been developed further and behave well in
problems such as the ones proposed by common sense reasoning. Machine
Consciousness is a field that has been deeply studied and several theories
based in the functionalism philosophical theory like the global workspace
theory or information integration have been proposed that try to explain the
ariseness of consciousness in machines. In this work, we propose an
architecture that may arise consciousness in a machine based in the global
workspace theory and in the assumption that consciousness appear in machines
that has cognitive processes and exhibit conscious behaviour. This architecture
is based in processes that use the recent developments in artificial
intelligence models which output are these correlated activities. For every one
of the modules of this architecture, we provide detailed explanations of the
models involved and how they communicate with each other to create the
cognitive architecture.","['Eduardo C. Garrido Merchán', 'Martín Molina']",2020-02-02 23:18:17+00:00,2020-03-14 00:01:23+00:00,http://arxiv.org/pdf/2002.00509v2,cs.AI,['cs.AI'],"a machine consciousness architecture based on deep learning and gaussian processes recent developments in machine learning have pushed the tasks that machines
can do outside the boundaries of what was thought to be possible years ago.
methodologies such as deep learning or generative models have achieved complex
tasks such as generating art pictures or literature automatically. on the other
hand, symbolic resources have also been developed further and behave well in
problems such as the ones proposed by common sense reasoning. machine
consciousness is a field that has been deeply studied and several theories
based in the functionalism philosophical theory like the global workspace
theory or information integration have been proposed that try to explain the
ariseness of consciousness in machines. in this work, we propose an
architecture that may arise consciousness in a machine based in the global
workspace theory and in the assumption that consciousness appear in machines
that has cognitive processes and exhibit conscious behaviour. this architecture
is based in processes that use the recent developments in artificial
intelligence models which output are these correlated activities. for every one
of the modules of this architecture, we provide detailed explanations of the
models involved and how they communicate with each other to create the
cognitive architecture."
Consciousness and Automated Reasoning,"This paper aims at demonstrating how a first-order logic reasoning system in
combination with a large knowledge base can be understood as an artificial
consciousness system. For this we review some aspects from the area of
philosophy of mind and in particular Tononi's Information Integration Theory
(IIT) and Baars' Global Workspace Theory. These will be applied to the
reasoning system Hyper with ConceptNet as a knowledge base within a scenario of
commonsense and cognitive reasoning. Finally we demonstrate that such a system
is very well able to do conscious mind wandering.","['Ulrike Barthelmeß', 'Ulrich Furbach', 'Claudia Schon']",2020-01-26 11:43:48+00:00,2020-07-22 10:08:33+00:00,http://arxiv.org/pdf/2001.09442v3,cs.AI,['cs.AI'],"consciousness and automated reasoning this paper aims at demonstrating how a first-order logic reasoning system in
combination with a large knowledge base can be understood as an artificial
consciousness system. for this we review some aspects from the area of
philosophy of mind and in particular tononi's information integration theory
(iit) and baars' global workspace theory. these will be applied to the
reasoning system hyper with conceptnet as a knowledge base within a scenario of
commonsense and cognitive reasoning. finally we demonstrate that such a system
is very well able to do conscious mind wandering."
Towards Explainable Music Emotion Recognition: The Route via Mid-level Features,"Emotional aspects play an important part in our interaction with music.
However, modelling these aspects in MIR systems have been notoriously
challenging since emotion is an inherently abstract and subjective experience,
thus making it difficult to quantify or predict in the first place, and to make
sense of the predictions in the next. In an attempt to create a model that can
give a musically meaningful and intuitive explanation for its predictions, we
propose a VGG-style deep neural network that learns to predict emotional
characteristics of a musical piece together with (and based on)
human-interpretable, mid-level perceptual features. We compare this to
predicting emotion directly with an identical network that does not take into
account the mid-level features and observe that the loss in predictive
performance of going through the mid-level features is surprisingly low, on
average. The design of our network allows us to visualize the effects of
perceptual features on individual emotion predictions, and we argue that the
small loss in performance in going through the mid-level features is justified
by the gain in explainability of the predictions.","['Shreyan Chowdhury', 'Andreu Vall', 'Verena Haunschmid', 'Gerhard Widmer']",2019-07-08 12:58:02+00:00,2019-07-08 12:58:02+00:00,http://arxiv.org/pdf/1907.03572v1,cs.SD,"['cs.SD', 'cs.LG', 'stat.ML']","towards explainable music emotion recognition: the route via mid-level features emotional aspects play an important part in our interaction with music.
however, modelling these aspects in mir systems have been notoriously
challenging since emotion is an inherently abstract and subjective experience,
thus making it difficult to quantify or predict in the first place, and to make
sense of the predictions in the next. in an attempt to create a model that can
give a musically meaningful and intuitive explanation for its predictions, we
propose a vgg-style deep neural network that learns to predict emotional
characteristics of a musical piece together with (and based on)
human-interpretable, mid-level perceptual features. we compare this to
predicting emotion directly with an identical network that does not take into
account the mid-level features and observe that the loss in predictive
performance of going through the mid-level features is surprisingly low, on
average. the design of our network allows us to visualize the effects of
perceptual features on individual emotion predictions, and we argue that the
small loss in performance in going through the mid-level features is justified
by the gain in explainability of the predictions."
Information Flow Theory (IFT) of Biologic and Machine Consciousness: Implications for Artificial General Intelligence and the Technological Singularity,"The subjective experience of consciousness is at once familiar and yet deeply
mysterious. Strategies exploring the top-down mechanisms of conscious thought
within the human brain have been unable to produce a generalized explanatory
theory that scales through evolution and can be applied to artificial systems.
Information Flow Theory (IFT) provides a novel framework for understanding both
the development and nature of consciousness in any system capable of processing
information. In prioritizing the direction of information flow over information
computation, IFT produces a range of unexpected predictions. The purpose of
this manuscript is to introduce the basic concepts of IFT and explore the
manifold implications regarding artificial intelligence, superhuman
consciousness, and our basic perception of reality.",['B. S. Bleier'],2019-06-21 15:01:25+00:00,2019-06-21 15:01:25+00:00,http://arxiv.org/pdf/1907.00703v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.ET', 'cs.IT', 'math.IT']","information flow theory (ift) of biologic and machine consciousness: implications for artificial general intelligence and the technological singularity the subjective experience of consciousness is at once familiar and yet deeply
mysterious. strategies exploring the top-down mechanisms of conscious thought
within the human brain have been unable to produce a generalized explanatory
theory that scales through evolution and can be applied to artificial systems.
information flow theory (ift) provides a novel framework for understanding both
the development and nature of consciousness in any system capable of processing
information. in prioritizing the direction of information flow over information
computation, ift produces a range of unexpected predictions. the purpose of
this manuscript is to introduce the basic concepts of ift and explore the
manifold implications regarding artificial intelligence, superhuman
consciousness, and our basic perception of reality."
Low-dimensional Embodied Semantics for Music and Language,"Embodied cognition states that semantics is encoded in the brain as firing
patterns of neural circuits, which are learned according to the statistical
structure of human multimodal experience. However, each human brain is
idiosyncratically biased, according to its subjective experience history,
making this biological semantic machinery noisy with respect to the overall
semantics inherent to media artifacts, such as music and language excerpts. We
propose to represent shared semantics using low-dimensional vector embeddings
by jointly modeling several brains from human subjects. We show these
unsupervised efficient representations outperform the original high-dimensional
fMRI voxel spaces in proxy music genre and language topic classification tasks.
We further show that joint modeling of several subjects increases the semantic
richness of the learned latent vector spaces.","['Francisco Afonso Raposo', 'David Martins de Matos', 'Ricardo Ribeiro']",2019-06-20 11:09:01+00:00,2019-06-20 11:09:01+00:00,http://arxiv.org/pdf/1906.11759v1,q-bio.NC,"['q-bio.NC', 'cs.IR', 'cs.LG', 'cs.SD', 'eess.AS', 'stat.ML', 'I.2.6; H.5.5; H.5.1; I.2.7']","low-dimensional embodied semantics for music and language embodied cognition states that semantics is encoded in the brain as firing
patterns of neural circuits, which are learned according to the statistical
structure of human multimodal experience. however, each human brain is
idiosyncratically biased, according to its subjective experience history,
making this biological semantic machinery noisy with respect to the overall
semantics inherent to media artifacts, such as music and language excerpts. we
propose to represent shared semantics using low-dimensional vector embeddings
by jointly modeling several brains from human subjects. we show these
unsupervised efficient representations outperform the original high-dimensional
fmri voxel spaces in proxy music genre and language topic classification tasks.
we further show that joint modeling of several subjects increases the semantic
richness of the learned latent vector spaces."
Awareness as inference in a higher-order state space,"Humans have the ability to report the contents of their subjective experience
- we can say to each other, ""I am aware of X"". The decision processes that
support these reports about mental contents remain poorly understood. In this
article I propose a computational framework that characterises awareness
reports as metacognitive decisions (inference) about a generative model of
perceptual content. This account is motivated from the perspective of how
flexible hierarchical state spaces are built during learning and
decision-making. Internal states supporting awareness reports, unlike those
covarying with perceptual contents, are simple and abstract, varying along a
one-dimensional continuum from absent to present. A critical feature of this
architecture is that it is both higher-order and asymmetric: a vast number of
perceptual states is nested under ""present"", but a much smaller number of
possible states nested under ""absent"". Via simulations I show that this
asymmetry provides a natural account of observations of ""global ignition"" in
brain imaging studies of awareness reports.",['Stephen M. Fleming'],2019-05-31 10:26:26+00:00,2019-12-03 11:24:09+00:00,http://arxiv.org/pdf/1906.00728v3,q-bio.NC,['q-bio.NC'],"awareness as inference in a higher-order state space humans have the ability to report the contents of their subjective experience
- we can say to each other, ""i am aware of x"". the decision processes that
support these reports about mental contents remain poorly understood. in this
article i propose a computational framework that characterises awareness
reports as metacognitive decisions (inference) about a generative model of
perceptual content. this account is motivated from the perspective of how
flexible hierarchical state spaces are built during learning and
decision-making. internal states supporting awareness reports, unlike those
covarying with perceptual contents, are simple and abstract, varying along a
one-dimensional continuum from absent to present. a critical feature of this
architecture is that it is both higher-order and asymmetric: a vast number of
perceptual states is nested under ""present"", but a much smaller number of
possible states nested under ""absent"". via simulations i show that this
asymmetry provides a natural account of observations of ""global ignition"" in
brain imaging studies of awareness reports."
Artificial Consciousness and Security,"This paper describes a possible way to improve computer security by
implementing a program which implements the following three features related to
a weak notion of artificial consciousness: (partial) self-monitoring, ability
to compute the truth of quantifier-free propositions and the ability to
communicate with the user. The integrity of the program could be enhanced by
using a trusted computing approach, that is to say a hardware module that is at
the root of a chain of trust. This paper outlines a possible approach but does
not refer to an implementation (which would need further work), but the author
believes that an implementation using current processors, a debugger, a
monitoring program and a trusted processing module is currently possible.",['Andrew Powell'],2019-05-11 11:21:05+00:00,2019-05-11 11:21:05+00:00,http://arxiv.org/pdf/1905.11807v1,cs.AI,['cs.AI'],"artificial consciousness and security this paper describes a possible way to improve computer security by
implementing a program which implements the following three features related to
a weak notion of artificial consciousness: (partial) self-monitoring, ability
to compute the truth of quantifier-free propositions and the ability to
communicate with the user. the integrity of the program could be enhanced by
using a trusted computing approach, that is to say a hardware module that is at
the root of a chain of trust. this paper outlines a possible approach but does
not refer to an implementation (which would need further work), but the author
believes that an implementation using current processors, a debugger, a
monitoring program and a trusted processing module is currently possible."
The meta-problem and the transfer of knowledge between theories of consciousness: a software engineer's take,"This contribution examines two radically different explanations of our
phenomenal intuitions, one reductive and one strongly non-reductive, and
identifies two germane ideas that could benefit many other theories of
consciousness. Firstly, the ability of sophisticated agent architectures with a
purely physical implementation to support certain functional forms of qualia or
proto-qualia appears to entail the possibility of machine consciousness with
qualia, not only for reductive theories but also for the nonreductive ones that
regard consciousness as ubiquitous in Nature. Secondly, analysis of
introspective psychological material seems to hint that, under the threshold of
our ordinary waking awareness, there exist further 'submerged' or 'subliminal'
layers of consciousness which constitute a hidden foundation and support and
another source of our phenomenal intuitions. These 'submerged' layers might
help explain certain puzzling phenomena concerning subliminal perception, such
as the apparently 'unconscious' multisensory integration and learning of
subliminal stimuli.",['Marcel Kvassay'],2019-02-18 19:17:44+00:00,2019-02-18 19:17:44+00:00,http://arxiv.org/pdf/1903.03418v1,q-bio.NC,"['q-bio.NC', 'cs.AI']","the meta-problem and the transfer of knowledge between theories of consciousness: a software engineer's take this contribution examines two radically different explanations of our
phenomenal intuitions, one reductive and one strongly non-reductive, and
identifies two germane ideas that could benefit many other theories of
consciousness. firstly, the ability of sophisticated agent architectures with a
purely physical implementation to support certain functional forms of qualia or
proto-qualia appears to entail the possibility of machine consciousness with
qualia, not only for reductive theories but also for the nonreductive ones that
regard consciousness as ubiquitous in nature. secondly, analysis of
introspective psychological material seems to hint that, under the threshold of
our ordinary waking awareness, there exist further 'submerged' or 'subliminal'
layers of consciousness which constitute a hidden foundation and support and
another source of our phenomenal intuitions. these 'submerged' layers might
help explain certain puzzling phenomena concerning subliminal perception, such
as the apparently 'unconscious' multisensory integration and learning of
subliminal stimuli."
Evolving the pulmonary nodules diagnosis from classical approaches to deep learning aided decision support: three decades development course and future prospect,"Lung cancer is the commonest cause of cancer deaths worldwide, and its
mortality can be reduced significantly by performing early diagnosis and
screening. Since the 1960s, driven by the pressing needs to accurately and
effectively interpret the massive volume of chest images generated daily,
computer-assisted diagnosis of pulmonary nodule has opened up new opportunities
to relax the limitation from physicians' subjectivity, experiences and fatigue.
And the fair access to the reliable and affordable computer-assisted diagnosis
will fight the inequalities in incidence and mortality between populations. It
has been witnessed that significant and remarkable advances have been achieved
since the 1980s, and consistent endeavors have been exerted to deal with the
grand challenges on how to accurately detect the pulmonary nodules with high
sensitivity at low false-positives rate as well as on how to precisely
differentiate between benign and malignant nodules. There is a lack of
comprehensive examination of the techniques' development which is evolving the
pulmonary nodules diagnosis from classical approaches to machine
learning-assisted decision support. The main goal of this investigation is to
provide a comprehensive state-of-the-art review of the computer-assisted
nodules detection and benign-malignant classification techniques developed over
3 decades, which have evolved from the complicated ad hoc analysis pipeline of
conventional approaches to the simplified seamlessly integrated deep learning
techniques. This review also identifies challenges and highlights opportunities
for future work in learning models, learning algorithms and enhancement schemes
for bridging current state to future prospect and satisfying future demand.","['Bo Liu', 'Wenhao Chi', 'Xinran Li', 'Peng Li', 'Wenhua Liang', 'Haiping Liu', 'Wei Wang', 'Jianxing He']",2019-01-23 13:04:59+00:00,2020-04-24 17:31:24+00:00,http://arxiv.org/pdf/1901.07858v3,cs.CV,"['cs.CV', 'cs.LG']","evolving the pulmonary nodules diagnosis from classical approaches to deep learning aided decision support: three decades development course and future prospect lung cancer is the commonest cause of cancer deaths worldwide, and its
mortality can be reduced significantly by performing early diagnosis and
screening. since the 1960s, driven by the pressing needs to accurately and
effectively interpret the massive volume of chest images generated daily,
computer-assisted diagnosis of pulmonary nodule has opened up new opportunities
to relax the limitation from physicians' subjectivity, experiences and fatigue.
and the fair access to the reliable and affordable computer-assisted diagnosis
will fight the inequalities in incidence and mortality between populations. it
has been witnessed that significant and remarkable advances have been achieved
since the 1980s, and consistent endeavors have been exerted to deal with the
grand challenges on how to accurately detect the pulmonary nodules with high
sensitivity at low false-positives rate as well as on how to precisely
differentiate between benign and malignant nodules. there is a lack of
comprehensive examination of the techniques' development which is evolving the
pulmonary nodules diagnosis from classical approaches to machine
learning-assisted decision support. the main goal of this investigation is to
provide a comprehensive state-of-the-art review of the computer-assisted
nodules detection and benign-malignant classification techniques developed over
3 decades, which have evolved from the complicated ad hoc analysis pipeline of
conventional approaches to the simplified seamlessly integrated deep learning
techniques. this review also identifies challenges and highlights opportunities
for future work in learning models, learning algorithms and enhancement schemes
for bridging current state to future prospect and satisfying future demand."
Theory of Cognitive Relativity: A Promising Paradigm for True AI,"The rise of deep learning has brought artificial intelligence (AI) to the
forefront. The ultimate goal of AI is to realize machines with human mind and
consciousness, but existing achievements mainly simulate intelligent behavior
on computer platforms. These achievements all belong to weak AI rather than
strong AI. How to achieve strong AI is not known yet in the field of
intelligence science. Currently, this field is calling for a new paradigm,
especially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a
simple and elegant set of first principles about the nature of intelligence, at
least including the Principle of World's Relativity and the Principle of
Symbol's Relativity. The Principle of World's Relativity states that the
subjective world an intelligent agent can observe is strongly constrained by
the way it perceives the objective world. The Principle of Symbol's Relativity
states that an intelligent agent can use any physical symbol system to express
what it observes in its subjective world. The two principles are derived from
scientific facts and life experience. Thought experiments show that they are
important to understand high-level intelligence and necessary to establish a
scientific theory of mind and consciousness. Rather than brain-like
intelligence, the TCR indeed advocates a promising change in direction to
realize true AI, i.e. artificial general intelligence or artificial
consciousness, particularly different from humans' and animals'. Furthermore, a
TCR creed has been presented and extended to reveal the secrets of
consciousness and to guide realization of conscious machines. In the sense that
true AI could be diversely implemented in a brain-different way, the TCR would
probably drive an intelligence revolution in combination with some additional
first principles.",['Yujian Li'],2018-12-01 04:01:03+00:00,2018-12-20 06:59:22+00:00,http://arxiv.org/pdf/1812.00136v3,cs.AI,['cs.AI'],"theory of cognitive relativity: a promising paradigm for true ai the rise of deep learning has brought artificial intelligence (ai) to the
forefront. the ultimate goal of ai is to realize machines with human mind and
consciousness, but existing achievements mainly simulate intelligent behavior
on computer platforms. these achievements all belong to weak ai rather than
strong ai. how to achieve strong ai is not known yet in the field of
intelligence science. currently, this field is calling for a new paradigm,
especially theory of cognitive relativity (tcr). the tcr aims to summarize a
simple and elegant set of first principles about the nature of intelligence, at
least including the principle of world's relativity and the principle of
symbol's relativity. the principle of world's relativity states that the
subjective world an intelligent agent can observe is strongly constrained by
the way it perceives the objective world. the principle of symbol's relativity
states that an intelligent agent can use any physical symbol system to express
what it observes in its subjective world. the two principles are derived from
scientific facts and life experience. thought experiments show that they are
important to understand high-level intelligence and necessary to establish a
scientific theory of mind and consciousness. rather than brain-like
intelligence, the tcr indeed advocates a promising change in direction to
realize true ai, i.e. artificial general intelligence or artificial
consciousness, particularly different from humans' and animals'. furthermore, a
tcr creed has been presented and extended to reveal the secrets of
consciousness and to guide realization of conscious machines. in the sense that
true ai could be diversely implemented in a brain-different way, the tcr would
probably drive an intelligence revolution in combination with some additional
first principles."
A rule-based system proposal to aid in the evaluation and decision-making in external beam radiation treatment planning,"As part of a plan launched by the Ministry of Health of Brazil to increase
the availability of linear accelerators for radiotherapy treatment for the
whole country, for which Varian Medical Systems company has won the bidding, a
technical cooperation agreement was signed inviting Brazilian Scientific and
Technological Institutions to participate in a technology transfer program. As
a result, jointly, the Eldorado Research Institute and the Center for
Biomedical Engineering of the University of Campinas presents in this work, the
concepts behind of a proposed rule engine to aid in the evaluation and
decision-making in radiotherapy treatment planning. Normally, the determination
of the radiation dose for a given patient is a complex and intensive procedure,
which requires a lot of domain knowledge and subjective experience from the
oncologists' team. In order to help them in this complex task, and
additionally, provide an auxiliary tool for less experienced oncologists, it is
presented a project conception of a software system that will make use of a
hybrid data-oriented approach. The proposed rule engine will apply both
inference mechanism and expression evaluation to verify and accredit the
quality of an external beam radiation treatment plan by considering, at first,
the 3D-conformal radiotherapy (3DCRT) technique.","['R. C. Fernandes', 'T. M. Machado', 'H. J. Onisto', 'A. D. Muñoz', 'R. O. Silva', 'L. R. Domingues', 'G. C. Fonseca', 'J. E. Bertuzzo', 'M. T. Pereira', 'B. Biazotto', 'E. T. Costa']",2018-11-29 19:49:53+00:00,2018-11-29 19:49:53+00:00,http://arxiv.org/pdf/1811.12454v1,cs.SE,"['cs.SE', 'cs.AI']","a rule-based system proposal to aid in the evaluation and decision-making in external beam radiation treatment planning as part of a plan launched by the ministry of health of brazil to increase
the availability of linear accelerators for radiotherapy treatment for the
whole country, for which varian medical systems company has won the bidding, a
technical cooperation agreement was signed inviting brazilian scientific and
technological institutions to participate in a technology transfer program. as
a result, jointly, the eldorado research institute and the center for
biomedical engineering of the university of campinas presents in this work, the
concepts behind of a proposed rule engine to aid in the evaluation and
decision-making in radiotherapy treatment planning. normally, the determination
of the radiation dose for a given patient is a complex and intensive procedure,
which requires a lot of domain knowledge and subjective experience from the
oncologists' team. in order to help them in this complex task, and
additionally, provide an auxiliary tool for less experienced oncologists, it is
presented a project conception of a software system that will make use of a
hybrid data-oriented approach. the proposed rule engine will apply both
inference mechanism and expression evaluation to verify and accredit the
quality of an external beam radiation treatment plan by considering, at first,
the 3d-conformal radiotherapy (3dcrt) technique."
Towards a Science of Mind,"The ancient mind/body problem continues to be one of deepest mysteries of
science and of the human spirit. Despite major advances in many fields, there
is still no plausible link between subjective experience (qualia) and its
realization in the body. This paper outlines some of the elements of a rigorous
science of mind (SoM) - key ideas include scientific realism of mind, agnostic
mysterianism, careful attention to language, and a focus on concrete
(touchstone) questions and results. A core suggestion is to focus effort on the
(still mysterious) mapping from neural activity to subjective experience.",['Jerome Feldman'],2018-11-06 18:02:40+00:00,2019-07-29 16:58:06+00:00,http://arxiv.org/pdf/1811.06825v3,cs.GL,"['cs.GL', 'cs.AI', 'q-bio.NC']","towards a science of mind the ancient mind/body problem continues to be one of deepest mysteries of
science and of the human spirit. despite major advances in many fields, there
is still no plausible link between subjective experience (qualia) and its
realization in the body. this paper outlines some of the elements of a rigorous
science of mind (som) - key ideas include scientific realism of mind, agnostic
mysterianism, careful attention to language, and a focus on concrete
(touchstone) questions and results. a core suggestion is to focus effort on the
(still mysterious) mapping from neural activity to subjective experience."
Can quantum physics help solve the hard problem of consciousness? A hypothesis based on entangled spins and photons,"The hard problem of consciousness is the question how subjective experience
arises from brain matter. I suggest exploring the possibility that quantum
physics could be part of the answer. The simultaneous unity and complexity of
subjective experience is difficult to understand from a classical physics
perspective. In contrast, quantum entanglement is naturally both complex and
unified. Moreover the concept of matter is much more subtle in quantum physics
compared to classical physics, and quantum computing shows that quantum effects
can be useful for information processing. Building on recent progress in
quantum technology and neuroscience, I propose a concrete hypothesis as a basis
for further investigation, namely that subjective experience is related to the
dynamics of a complex entangled state of spins, which is continuously generated
and updated through the exchange of photons. Spins in condensed matter systems
at room or body temperature can have coherence times in the relevant range for
subjective experience (milliseconds to seconds). Photons are well suited for
distributing entanglement over macroscopic distances. Neurons emit photons,
reactive oxygen species in the mitochondria being likely sources. Opsins,
light-sensitive proteins that are plausible single-photon detectors, exist in
the brain and are evolutionarily conserved, suggesting that they serve a
function. We have recently shown by detailed numerical modeling that axons can
plausibly act as photonic waveguides. The oxygen molecule, which has non-zero
electronic spin and emits photons, might serve as an interface between photons
and spins. The achievable photon rates seem to be more than sufficient to
support the bandwidth of subjective experience. The proposed hypothesis raises
many interesting experimental and theoretical questions in neuroscience,
quantum physics, evolutionary biology, psychophysics, and philosophy.",['Christoph Simon'],2018-09-08 20:04:22+00:00,2018-09-08 20:04:22+00:00,http://arxiv.org/pdf/1809.03490v1,q-bio.NC,"['q-bio.NC', 'physics.bio-ph', 'quant-ph']","can quantum physics help solve the hard problem of consciousness? a hypothesis based on entangled spins and photons the hard problem of consciousness is the question how subjective experience
arises from brain matter. i suggest exploring the possibility that quantum
physics could be part of the answer. the simultaneous unity and complexity of
subjective experience is difficult to understand from a classical physics
perspective. in contrast, quantum entanglement is naturally both complex and
unified. moreover the concept of matter is much more subtle in quantum physics
compared to classical physics, and quantum computing shows that quantum effects
can be useful for information processing. building on recent progress in
quantum technology and neuroscience, i propose a concrete hypothesis as a basis
for further investigation, namely that subjective experience is related to the
dynamics of a complex entangled state of spins, which is continuously generated
and updated through the exchange of photons. spins in condensed matter systems
at room or body temperature can have coherence times in the relevant range for
subjective experience (milliseconds to seconds). photons are well suited for
distributing entanglement over macroscopic distances. neurons emit photons,
reactive oxygen species in the mitochondria being likely sources. opsins,
light-sensitive proteins that are plausible single-photon detectors, exist in
the brain and are evolutionarily conserved, suggesting that they serve a
function. we have recently shown by detailed numerical modeling that axons can
plausibly act as photonic waveguides. the oxygen molecule, which has non-zero
electronic spin and emits photons, might serve as an interface between photons
and spins. the achievable photon rates seem to be more than sufficient to
support the bandwidth of subjective experience. the proposed hypothesis raises
many interesting experimental and theoretical questions in neuroscience,
quantum physics, evolutionary biology, psychophysics, and philosophy."
Null Dynamical State Models of Human Cognitive Dysfunction,"The hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. We address this question in three stages. First, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. For this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. Second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. In this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. This state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. In the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. Drastic change in any of these environmental inputs
can again lead to inoperative programs. By examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. Our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence.",['M. J. Gagen'],2017-12-25 05:46:19+00:00,2017-12-25 05:46:19+00:00,http://arxiv.org/pdf/1712.09014v1,cs.AI,"['cs.AI', 'cs.LG', 'cs.NE']","null dynamical state models of human cognitive dysfunction the hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. we address this question in three stages. first, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. for this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. in this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. this state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. in the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. drastic change in any of these environmental inputs
can again lead to inoperative programs. by examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence."
Detecting Qualia in Natural and Artificial Agents,"The Hard Problem of consciousness has been dismissed as an illusion. By
showing that computers are capable of experiencing, we show that they are at
least rudimentarily conscious with potential to eventually reach
superconsciousness. The main contribution of the paper is a test for confirming
certain subjective experiences in a tested agent. We follow with analysis of
benefits and problems with conscious machines and implications of such
capability on future of computing, machine rights and artificial intelligence
safety.",['Roman V. Yampolskiy'],2017-12-11 20:53:47+00:00,2017-12-11 20:53:47+00:00,http://arxiv.org/pdf/1712.04020v1,cs.AI,['cs.AI'],"detecting qualia in natural and artificial agents the hard problem of consciousness has been dismissed as an illusion. by
showing that computers are capable of experiencing, we show that they are at
least rudimentarily conscious with potential to eventually reach
superconsciousness. the main contribution of the paper is a test for confirming
certain subjective experiences in a tested agent. we follow with analysis of
benefits and problems with conscious machines and implications of such
capability on future of computing, machine rights and artificial intelligence
safety."
Neural correlates of flow using auditory evoked potential suppression,"""Flow"" is a hyper-engaged state of consciousness most commonly described in
athletics, popularly termed ""being in the zone."" Quantitative research into
flow has been hampered by the disruptive nature of gathering subjective
reports. Here we show that a passive probe (suppression of Auditory Evoked
Potential in EEG) that allowed our participants to remain engaged in a
first-person shooting game while we continually tracked the depth of their
immersion corresponded with the participants' subjective experiences, and with
their objective performance levels. Comparing this time-varying record of flow
against the overall EEG record, we identified neural correlates of flow in the
anterior cingulate cortex and the temporal pole. These areas displayed
increased beta band activity, mutual connectivity, and feedback connectivity
with primary motor cortex. These results corroborate the notion that the flow
state is an objective and quantifiable state of consciousness, which we
identify and characterize across subjective, behavioral and neural measures.","['Kyongsik Yun', 'Saeran Doh', 'Elisa Carrus', 'Daw-An Wu', 'Shinsuke Shimojo']",2017-11-19 04:37:58+00:00,2017-11-24 22:30:51+00:00,http://arxiv.org/pdf/1711.06967v4,q-bio.NC,['q-bio.NC'],"neural correlates of flow using auditory evoked potential suppression ""flow"" is a hyper-engaged state of consciousness most commonly described in
athletics, popularly termed ""being in the zone."" quantitative research into
flow has been hampered by the disruptive nature of gathering subjective
reports. here we show that a passive probe (suppression of auditory evoked
potential in eeg) that allowed our participants to remain engaged in a
first-person shooting game while we continually tracked the depth of their
immersion corresponded with the participants' subjective experiences, and with
their objective performance levels. comparing this time-varying record of flow
against the overall eeg record, we identified neural correlates of flow in the
anterior cingulate cortex and the temporal pole. these areas displayed
increased beta band activity, mutual connectivity, and feedback connectivity
with primary motor cortex. these results corroborate the notion that the flow
state is an objective and quantifiable state of consciousness, which we
identify and characterize across subjective, behavioral and neural measures."
Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning,"Pain is a subjective experience commonly measured through patient's self
report. While there exist numerous situations in which automatic pain
estimation methods may be preferred, inter-subject variability in physiological
and behavioral pain responses has hindered the development of such methods. In
this work, we address this problem by introducing a novel personalized
multitask machine learning method for pain estimation based on individual
physiological and behavioral pain response profiles, and show its advantages in
a dataset containing multimodal responses to nociceptive heat pain.","['Daniel Lopez-Martinez', 'Ognjen Rudovic', 'Rosalind Picard']",2017-11-10 22:36:27+00:00,2017-11-10 22:36:27+00:00,http://arxiv.org/pdf/1711.04036v1,cs.AI,"['cs.AI', 'cs.HC']","physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning pain is a subjective experience commonly measured through patient's self
report. while there exist numerous situations in which automatic pain
estimation methods may be preferred, inter-subject variability in physiological
and behavioral pain responses has hindered the development of such methods. in
this work, we address this problem by introducing a novel personalized
multitask machine learning method for pain estimation based on individual
physiological and behavioral pain response profiles, and show its advantages in
a dataset containing multimodal responses to nociceptive heat pain."
Musical NeuroPicks: a consumer-grade BCI for on-demand music streaming services,"We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used in popular
on-demand music streaming services. Our study resulted into two variants,
differing in terms of performance and execution time, and hence, subserving
distinct applications in online streaming music platforms. The first method,
NeuroPicks, is extremely accurate but slower. It is based on the
well-established neuroscientific concepts of brainwave frequency bands,
activation asymmetry index and cross frequency coupling (CFC). The second
method, NeuroPicksVQ, offers prompt predictions of lower credibility and relies
on a custom-built version of vector quantization procedure that facilitates a
novel parameterization of the music-modulated brainwaves. Beyond the feature
engineering step, both methods exploit the inherent efficiency of extreme
learning machines (ELMs) so as to translate, in a personalized fashion, the
derived patterns into a listener's score. NeuroPicks method may find
applications as an integral part of contemporary music recommendation systems,
while NeuroPicksVQ can control the selection of music tracks. Encouraging
experimental results, from a pragmatic use of the systems, are presented.","['Fotis Kalaganis', 'Dimitrios A. Adamos', 'Nikos Laskaris']",2017-09-04 18:55:35+00:00,2017-09-04 18:55:35+00:00,http://arxiv.org/pdf/1709.01116v1,q-bio.NC,"['q-bio.NC', 'cs.CY', 'cs.HC', 'cs.MM']","musical neuropicks: a consumer-grade bci for on-demand music streaming services we investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable eeg-devices for translating listener's
subjective experience of music into scores that can be used in popular
on-demand music streaming services. our study resulted into two variants,
differing in terms of performance and execution time, and hence, subserving
distinct applications in online streaming music platforms. the first method,
neuropicks, is extremely accurate but slower. it is based on the
well-established neuroscientific concepts of brainwave frequency bands,
activation asymmetry index and cross frequency coupling (cfc). the second
method, neuropicksvq, offers prompt predictions of lower credibility and relies
on a custom-built version of vector quantization procedure that facilitates a
novel parameterization of the music-modulated brainwaves. beyond the feature
engineering step, both methods exploit the inherent efficiency of extreme
learning machines (elms) so as to translate, in a personalized fashion, the
derived patterns into a listener's score. neuropicks method may find
applications as an integral part of contemporary music recommendation systems,
while neuropicksvq can control the selection of music tracks. encouraging
experimental results, from a pragmatic use of the systems, are presented."
Are there optical communication channels in the brain?,"Despite great progress in neuroscience, there are still fundamental
unanswered questions about the brain, including the origin of subjective
experience and consciousness. Some answers might rely on new physical
mechanisms. Given that biophotons have been discovered in the brain, it is
interesting to explore if neurons use photonic communication in addition to the
well-studied electro-chemical signals. Such photonic communication in the brain
would require waveguides. Here we review recent work [S. Kumar, K. Boone, J.
Tuszynski, P. Barclay, and C. Simon, Scientific Reports 6, 36508 (2016)]
suggesting that myelinated axons could serve as photonic waveguides. The light
transmission in the myelinated axon was modeled, taking into account its
realistic imperfections, and experiments were proposed both in-vivo and
in-vitro to test this hypothesis. Potential implications for quantum biology
are discussed.","['Parisa Zarkeshian', 'Sourabh Kumar', 'Jack Tuszynski', 'Paul Barclay', 'Christoph Simon']",2017-08-23 22:54:52+00:00,2017-08-23 22:54:52+00:00,http://arxiv.org/pdf/1708.08887v1,physics.bio-ph,"['physics.bio-ph', 'physics.optics', 'q-bio.NC', 'quant-ph']","are there optical communication channels in the brain? despite great progress in neuroscience, there are still fundamental
unanswered questions about the brain, including the origin of subjective
experience and consciousness. some answers might rely on new physical
mechanisms. given that biophotons have been discovered in the brain, it is
interesting to explore if neurons use photonic communication in addition to the
well-studied electro-chemical signals. such photonic communication in the brain
would require waveguides. here we review recent work [s. kumar, k. boone, j.
tuszynski, p. barclay, and c. simon, scientific reports 6, 36508 (2016)]
suggesting that myelinated axons could serve as photonic waveguides. the light
transmission in the myelinated axon was modeled, taking into account its
realistic imperfections, and experiments were proposed both in-vivo and
in-vitro to test this hypothesis. potential implications for quantum biology
are discussed."
Multi-task Neural Networks for Personalized Pain Recognition from Physiological Signals,"Pain is a complex and subjective experience that poses a number of
measurement challenges. While self-report by the patient is viewed as the gold
standard of pain assessment, this approach fails when patients cannot verbally
communicate pain intensity or lack normal mental abilities. Here, we present a
pain intensity measurement method based on physiological signals. Specifically,
we implement a multi-task learning approach based on neural networks that
accounts for individual differences in pain responses while still leveraging
data from across the population. We test our method in a dataset containing
multi-modal physiological responses to nociceptive pain.","['Daniel Lopez-Martinez', 'Rosalind Picard']",2017-08-17 05:38:56+00:00,2017-09-04 19:23:11+00:00,http://arxiv.org/pdf/1708.08755v2,cs.CY,"['cs.CY', 'cs.LG', 'q-bio.NC']","multi-task neural networks for personalized pain recognition from physiological signals pain is a complex and subjective experience that poses a number of
measurement challenges. while self-report by the patient is viewed as the gold
standard of pain assessment, this approach fails when patients cannot verbally
communicate pain intensity or lack normal mental abilities. here, we present a
pain intensity measurement method based on physiological signals. specifically,
we implement a multi-task learning approach based on neural networks that
accounts for individual differences in pain responses while still leveraging
data from across the population. we test our method in a dataset containing
multi-modal physiological responses to nociceptive pain."
What modern vision science reveals about the awareness puzzle: Summary-statistic encoding plus decision limits underlie the richness of visual perception and its quirky failures,"There is a fundamental puzzle in understanding our awareness of the visual
world. On one hand, our subjective experience is one of a rich visual world,
which we perceive effortlessly. However, when we actually test perception,
observers know surprisingly little. A number of tasks, from search, through
inattentional blindness, to change blindness, suggest that there is
surprisingly little awareness or perception without attention. Meanwhile,
another set of tasks, such as multiple object tracking, dual-task performance,
and visual working memory tasks suggest that both attention and working memory
have low capacity. These two components together - poor perception without
attention, and greatly limited capacity for attention and memory - imply that
perception is impoverished.
  How can we make sense of this awareness puzzle, of the riddle of our rich
subjective experience coupled with poor performance on experimental tasks? I
suggest that, looked at in the right way, there is in fact no awareness puzzle.
In particular, I will argue that the tasks that show limits are inherently
difficult tasks, and that there exists a unified explanation for both the rich
subjective experience and the apparent limits.",['Ruth Rosenholtz'],2017-06-08 20:41:50+00:00,2017-06-08 20:41:50+00:00,http://arxiv.org/pdf/1706.02764v1,q-bio.NC,['q-bio.NC'],"what modern vision science reveals about the awareness puzzle: summary-statistic encoding plus decision limits underlie the richness of visual perception and its quirky failures there is a fundamental puzzle in understanding our awareness of the visual
world. on one hand, our subjective experience is one of a rich visual world,
which we perceive effortlessly. however, when we actually test perception,
observers know surprisingly little. a number of tasks, from search, through
inattentional blindness, to change blindness, suggest that there is
surprisingly little awareness or perception without attention. meanwhile,
another set of tasks, such as multiple object tracking, dual-task performance,
and visual working memory tasks suggest that both attention and working memory
have low capacity. these two components together - poor perception without
attention, and greatly limited capacity for attention and memory - imply that
perception is impoverished.
  how can we make sense of this awareness puzzle, of the riddle of our rich
subjective experience coupled with poor performance on experimental tasks? i
suggest that, looked at in the right way, there is in fact no awareness puzzle.
in particular, i will argue that the tasks that show limits are inherently
difficult tasks, and that there exists a unified explanation for both the rich
subjective experience and the apparent limits."
The Impact of Flow in an EEG-based Brain Computer Interface,"Major issues in Brain Computer Interfaces (BCIs) include low usability and
poor user performance. This paper tackles them by ensuring the users to be in a
state of immersion, control and motivation, called state of flow. Indeed, in
various disciplines, being in the state of flow was shown to improve
performances and learning. Hence, we intended to draw BCI users in a flow state
to improve both their subjective experience and their performances. In a Motor
Imagery BCI game, we manipulated flow in two ways: 1) by adapting the task
difficulty and 2) by using background music. Results showed that the difficulty
adaptation induced a higher flow state, however music had no effect. There was
a positive correlation between subjective flow scores and offline performance,
although the flow factors had no effect (adaptation) or negative effect (music)
on online performance. Overall, favouring the flow state seems a promising
approach for enhancing users' satisfaction, although its complexity requires
more thorough investigations.","['Jelena Mladenović', 'Jérémy Frey', 'Manon Bonnet-Save', 'Jérémie Mattout', 'Fabien Lotte']",2017-06-06 12:21:44+00:00,2017-06-06 12:21:44+00:00,http://arxiv.org/pdf/1706.01728v1,q-bio.NC,"['q-bio.NC', 'cs.HC']","the impact of flow in an eeg-based brain computer interface major issues in brain computer interfaces (bcis) include low usability and
poor user performance. this paper tackles them by ensuring the users to be in a
state of immersion, control and motivation, called state of flow. indeed, in
various disciplines, being in the state of flow was shown to improve
performances and learning. hence, we intended to draw bci users in a flow state
to improve both their subjective experience and their performances. in a motor
imagery bci game, we manipulated flow in two ways: 1) by adapting the task
difficulty and 2) by using background music. results showed that the difficulty
adaptation induced a higher flow state, however music had no effect. there was
a positive correlation between subjective flow scores and offline performance,
although the flow factors had no effect (adaptation) or negative effect (music)
on online performance. overall, favouring the flow state seems a promising
approach for enhancing users' satisfaction, although its complexity requires
more thorough investigations."
The Morphospace of Consciousness,"We construct a complexity-based morphospace to study systems-level properties
of conscious & intelligent systems. The axes of this space label 3 complexity
types: autonomous, cognitive & social. Given recent proposals to synthesize
consciousness, a generic complexity-based conceptualization provides a useful
framework for identifying defining features of conscious & synthetic systems.
Based on current clinical scales of consciousness that measure cognitive
awareness and wakefulness, we take a perspective on how contemporary
artificially intelligent machines & synthetically engineered life forms measure
on these scales. It turns out that awareness & wakefulness can be associated to
computational & autonomous complexity respectively. Subsequently, building on
insights from cognitive robotics, we examine the function that consciousness
serves, & argue the role of consciousness as an evolutionary game-theoretic
strategy. This makes the case for a third type of complexity for describing
consciousness: social complexity. Having identified these complexity types,
allows for a representation of both, biological & synthetic systems in a common
morphospace. A consequence of this classification is a taxonomy of possible
conscious machines. We identify four types of consciousness, based on
embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii)
group consciousness (resulting from group interactions), & (iv) simulated
consciousness (embodied by virtual agents within a simulated reality). This
taxonomy helps in the investigation of comparative signatures of consciousness
across domains, in order to highlight design principles necessary to engineer
conscious machines. This is particularly relevant in the light of recent
developments at the crossroads of cognitive neuroscience, biomedical
engineering, artificial intelligence & biomimetics.","['Xerxes D. Arsiwalla', 'Ricard Sole', 'Clement Moulin-Frier', 'Ivan Herreros', 'Marti Sanchez-Fibla', 'Paul Verschure']",2017-05-31 17:45:39+00:00,2018-11-24 23:05:40+00:00,http://arxiv.org/pdf/1705.11190v3,q-bio.NC,"['q-bio.NC', 'cond-mat.dis-nn', 'cs.AI', 'physics.bio-ph']","the morphospace of consciousness we construct a complexity-based morphospace to study systems-level properties
of conscious & intelligent systems. the axes of this space label 3 complexity
types: autonomous, cognitive & social. given recent proposals to synthesize
consciousness, a generic complexity-based conceptualization provides a useful
framework for identifying defining features of conscious & synthetic systems.
based on current clinical scales of consciousness that measure cognitive
awareness and wakefulness, we take a perspective on how contemporary
artificially intelligent machines & synthetically engineered life forms measure
on these scales. it turns out that awareness & wakefulness can be associated to
computational & autonomous complexity respectively. subsequently, building on
insights from cognitive robotics, we examine the function that consciousness
serves, & argue the role of consciousness as an evolutionary game-theoretic
strategy. this makes the case for a third type of complexity for describing
consciousness: social complexity. having identified these complexity types,
allows for a representation of both, biological & synthetic systems in a common
morphospace. a consequence of this classification is a taxonomy of possible
conscious machines. we identify four types of consciousness, based on
embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii)
group consciousness (resulting from group interactions), & (iv) simulated
consciousness (embodied by virtual agents within a simulated reality). this
taxonomy helps in the investigation of comparative signatures of consciousness
across domains, in order to highlight design principles necessary to engineer
conscious machines. this is particularly relevant in the light of recent
developments at the crossroads of cognitive neuroscience, biomedical
engineering, artificial intelligence & biomimetics."
A Mathematical Framework for Consciousness in Neural Networks,"This paper presents a novel mathematical framework for bridging the
explanatory gap (Levine, 1983) between consciousness and its physical
correlates. Specifically, we propose that qualia correspond to singularities in
the mathematical representations of neural network topology. Crucially, we do
not claim that qualia are singularities or that singularities ""explain"" why
qualia feel as they do. Instead, we propose that singularities serve as
principled, coordinate-invariant markers of points where attempts at purely
quantitative description of a system's dynamics reach an in-principle limit. By
integrating these formal markers of irreducibility into models of the physical
correlates of consciousness, we establish a framework that recognizes qualia as
phenomena inherently beyond reduction to complexity, computation, or
information. This approach draws on insights from philosophy of mind,
mathematics, cognitive neuroscience, and artificial intelligence (AI). It does
not solve the hard problem of consciousness (Chalmers, 1995), but it advances
the discourse by integrating the irreducible nature of qualia into a rigorous,
physicalist framework. While primarily theoretical, these insights also open
avenues for future AI and artificial consciousness (AC) research, suggesting
that recognizing and harnessing irreducible topological features may be an
important unlock in moving beyond incremental, scale-based improvements and
toward artificial general intelligence (AGI) and AC.",['T. R. Lima'],2017-04-04 18:32:58+00:00,2024-12-10 14:40:14+00:00,http://arxiv.org/pdf/1704.01148v6,q-bio.NC,"['q-bio.NC', 'cs.AI']","a mathematical framework for consciousness in neural networks this paper presents a novel mathematical framework for bridging the
explanatory gap (levine, 1983) between consciousness and its physical
correlates. specifically, we propose that qualia correspond to singularities in
the mathematical representations of neural network topology. crucially, we do
not claim that qualia are singularities or that singularities ""explain"" why
qualia feel as they do. instead, we propose that singularities serve as
principled, coordinate-invariant markers of points where attempts at purely
quantitative description of a system's dynamics reach an in-principle limit. by
integrating these formal markers of irreducibility into models of the physical
correlates of consciousness, we establish a framework that recognizes qualia as
phenomena inherently beyond reduction to complexity, computation, or
information. this approach draws on insights from philosophy of mind,
mathematics, cognitive neuroscience, and artificial intelligence (ai). it does
not solve the hard problem of consciousness (chalmers, 1995), but it advances
the discourse by integrating the irreducible nature of qualia into a rigorous,
physicalist framework. while primarily theoretical, these insights also open
avenues for future ai and artificial consciousness (ac) research, suggesting
that recognizing and harnessing irreducible topological features may be an
important unlock in moving beyond incremental, scale-based improvements and
toward artificial general intelligence (agi) and ac."
An affective computational model for machine consciousness,"In the past, several models of consciousness have become popular and have led
to the development of models for machine consciousness with varying degrees of
success and challenges for simulation and implementations. Moreover, affective
computing attributes that involve emotions, behavior and personality have not
been the focus of models of consciousness as they lacked motivation for
deployment in software applications and robots. The affective attributes are
important factors for the future of machine consciousness with the rise of
technologies that can assist humans. Personality and affection hence can give
an additional flavor for the computational model of consciousness in humanoid
robotics. Recent advances in areas of machine learning with a focus on deep
learning can further help in developing aspects of machine consciousness in
areas that can better replicate human sensory perceptions such as speech
recognition and vision. With such advancements, one encounters further
challenges in developing models that can synchronize different aspects of
affective computing. In this paper, we review some existing models of
consciousnesses and present an affective computational model that would enable
the human touch and feel for robotic systems.",['Rohitash Chandra'],2017-01-02 09:48:47+00:00,2017-01-02 09:48:47+00:00,http://arxiv.org/pdf/1701.00349v1,cs.AI,['cs.AI'],"an affective computational model for machine consciousness in the past, several models of consciousness have become popular and have led
to the development of models for machine consciousness with varying degrees of
success and challenges for simulation and implementations. moreover, affective
computing attributes that involve emotions, behavior and personality have not
been the focus of models of consciousness as they lacked motivation for
deployment in software applications and robots. the affective attributes are
important factors for the future of machine consciousness with the rise of
technologies that can assist humans. personality and affection hence can give
an additional flavor for the computational model of consciousness in humanoid
robotics. recent advances in areas of machine learning with a focus on deep
learning can further help in developing aspects of machine consciousness in
areas that can better replicate human sensory perceptions such as speech
recognition and vision. with such advancements, one encounters further
challenges in developing models that can synchronize different aspects of
affective computing. in this paper, we review some existing models of
consciousnesses and present an affective computational model that would enable
the human touch and feel for robotic systems."
Computing Integrated Information,"Integrated information theory (IIT) has established itself as one of the
leading theories for the study of consciousness. IIT essentially proposes that
quantitative consciousness is identical to maximally integrated conceptual
information, quantified by a measure called $\Phi^{max}$, and that
phenomenological experience corresponds to the associated set of maximally
irreducible cause-effect repertoires of a physical system being in a certain
state. However, in order to ultimately apply the theory to experimental data, a
sufficiently general formulation is needed. With the current work, we provide
this general formulation, which comprehensively and parsimoniously expresses
$\Phi^{max}$ in the language of probabilistic models. Here, the stochastic
process describing a system under scrutiny corresponds to a first-order
time-invariant Markov process, and all necessary mathematical operations for
the definition of $\Phi^{max}$ are fully specified by a system's joint
probability distribution over two adjacent points in discrete time. We present
a detailed constructive rule for the decomposition of a system into two
disjoint subsystems based on flexible marginalization and factorization of this
joint distribution. Furthermore, we suspend the approach of interventional
calculus based on system perturbations, which allows us to omit undefined
conditional distributions and virtualization. We validate our formulation in a
previously established discrete example system, in which we furthermore address
the previously unexplored theoretical issue of quale underdetermination due to
non-uniqueness of maximally irreducible cause-effect repertoires, which in turn
also entails the sensitivity of $\Phi^{max}$ to the shape of the conceptual
structure in qualia space. In constructive spirit, we propose several
modifications of the framework in order to address some of these issues.","['Stephan Krohn', 'Dirk Ostwald']",2016-10-12 07:47:28+00:00,2017-03-03 11:01:11+00:00,http://arxiv.org/pdf/1610.03627v2,q-bio.NC,['q-bio.NC'],"computing integrated information integrated information theory (iit) has established itself as one of the
leading theories for the study of consciousness. iit essentially proposes that
quantitative consciousness is identical to maximally integrated conceptual
information, quantified by a measure called $\phi^{max}$, and that
phenomenological experience corresponds to the associated set of maximally
irreducible cause-effect repertoires of a physical system being in a certain
state. however, in order to ultimately apply the theory to experimental data, a
sufficiently general formulation is needed. with the current work, we provide
this general formulation, which comprehensively and parsimoniously expresses
$\phi^{max}$ in the language of probabilistic models. here, the stochastic
process describing a system under scrutiny corresponds to a first-order
time-invariant markov process, and all necessary mathematical operations for
the definition of $\phi^{max}$ are fully specified by a system's joint
probability distribution over two adjacent points in discrete time. we present
a detailed constructive rule for the decomposition of a system into two
disjoint subsystems based on flexible marginalization and factorization of this
joint distribution. furthermore, we suspend the approach of interventional
calculus based on system perturbations, which allows us to omit undefined
conditional distributions and virtualization. we validate our formulation in a
previously established discrete example system, in which we furthermore address
the previously unexplored theoretical issue of quale underdetermination due to
non-uniqueness of maximally irreducible cause-effect repertoires, which in turn
also entails the sensitivity of $\phi^{max}$ to the shape of the conceptual
structure in qualia space. in constructive spirit, we propose several
modifications of the framework in order to address some of these issues."
Neural correlates of self-generated imagery and cognition throughout the sleep cycle,"Humans have been aware for thousands of years that sleep comes in many forms,
accompanied by different kinds of mental content. We review the first-person
report literature on the frequency and type of content experienced in various
stages of sleep, showing that different sleep stages are dissociable at the
subjective level. We then relate these subjective differences to the growing
literature differentiating the various sleep stages at the neurophysiological
level, including evidence from electrophysiology, neurochemistry, and
functional neuroimaging. We suggest that there is emerging evidence for
relationships between sleep stage, neurophysiological activity, and subjective
experiences. Specifically, we emphasize that functional neuroimaging work
suggests a parallel between activation and deactivation of default network and
visual network brain areas and the varying frequency and intensity of imagery
and dream mentation across sleep stages; additionally, frontoparietal control
network activity across sleep stages may parallel levels of cognitive control
and meta-awareness. Together these findings suggest intriguing brain-mind
isomorphisms and may serve as a first step toward a comprehensive understanding
of the relationship between neurophysiology and psychology in sleep and
dreaming.","['Kieran C. R. Fox', 'Manesh Girn']",2016-10-06 01:27:48+00:00,2016-10-06 01:27:48+00:00,http://arxiv.org/pdf/1610.01704v1,q-bio.NC,['q-bio.NC'],"neural correlates of self-generated imagery and cognition throughout the sleep cycle humans have been aware for thousands of years that sleep comes in many forms,
accompanied by different kinds of mental content. we review the first-person
report literature on the frequency and type of content experienced in various
stages of sleep, showing that different sleep stages are dissociable at the
subjective level. we then relate these subjective differences to the growing
literature differentiating the various sleep stages at the neurophysiological
level, including evidence from electrophysiology, neurochemistry, and
functional neuroimaging. we suggest that there is emerging evidence for
relationships between sleep stage, neurophysiological activity, and subjective
experiences. specifically, we emphasize that functional neuroimaging work
suggests a parallel between activation and deactivation of default network and
visual network brain areas and the varying frequency and intensity of imagery
and dream mentation across sleep stages; additionally, frontoparietal control
network activity across sleep stages may parallel levels of cognitive control
and meta-awareness. together these findings suggest intriguing brain-mind
isomorphisms and may serve as a first step toward a comprehensive understanding
of the relationship between neurophysiology and psychology in sleep and
dreaming."
A Consumer BCI for Automated Music Evaluation Within a Popular On-Demand Music Streaming Service - Taking Listener's Brainwaves to Extremes,"We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used for the automated
annotation of music in popular on-demand streaming services. Based on the
established -neuroscientifically sound- concepts of brainwave frequency bands,
activation asymmetry index and cross-frequency-coupling (CFC), we introduce a
Brain Computer Interface (BCI) system that automatically assigns a rating score
to the listened song. Our research operated in two distinct stages: i) a
generic feature engineering stage, in which features from signal-analytics were
ranked and selected based on their ability to associate music induced
perturbations in brainwaves with listener's appraisal of music. ii) a
personalization stage, during which the efficiency of ex- treme learning
machines (ELMs) is exploited so as to translate the derived pat- terns into a
listener's score. Encouraging experimental results, from a pragmatic use of the
system, are presented.","['Fotis Kalaganis', 'Dimitrios A. Adamos', 'Nikos Laskaris']",2016-09-20 22:29:02+00:00,2016-09-30 11:06:37+00:00,http://arxiv.org/pdf/1609.06374v2,cs.AI,"['cs.AI', 'cs.CY', 'cs.HC', 'cs.MM', 'cs.NE']","a consumer bci for automated music evaluation within a popular on-demand music streaming service - taking listener's brainwaves to extremes we investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable eeg-devices for translating listener's
subjective experience of music into scores that can be used for the automated
annotation of music in popular on-demand streaming services. based on the
established -neuroscientifically sound- concepts of brainwave frequency bands,
activation asymmetry index and cross-frequency-coupling (cfc), we introduce a
brain computer interface (bci) system that automatically assigns a rating score
to the listened song. our research operated in two distinct stages: i) a
generic feature engineering stage, in which features from signal-analytics were
ranked and selected based on their ability to associate music induced
perturbations in brainwaves with listener's appraisal of music. ii) a
personalization stage, during which the efficiency of ex- treme learning
machines (elms) is exploited so as to translate the derived pat- terns into a
listener's score. encouraging experimental results, from a pragmatic use of the
system, are presented."
How to avoid ethically relevant Machine Consciousness,"This paper discusses the root cause of systems perceiving the self experience
and how to exploit adaptive and learning features without introducing ethically
problematic system properties.",['Aleksander Lodwich'],2016-05-31 21:52:13+00:00,2016-06-06 10:53:16+00:00,http://arxiv.org/pdf/1606.00058v2,cs.AI,['cs.AI'],"how to avoid ethically relevant machine consciousness this paper discusses the root cause of systems perceiving the self experience
and how to exploit adaptive and learning features without introducing ethically
problematic system properties."
Memory shapes time perception and intertemporal choices,"There is a consensus that human and non-human subjects experience temporal
distortions in many stages of their perceptual and decision-making systems.
Similarly, intertemporal choice research has shown that decision-makers
undervalue future outcomes relative to immediate ones. Here we combine
techniques from information theory and artificial intelligence to show how both
temporal distortions and intertemporal choice preferences can be explained as a
consequence of the coding efficiency of sensorimotor representation. In
particular, the model implies that interactions that constrain future behavior
are perceived as being both longer in duration and more valuable. Furthermore,
using simulations of artificial agents, we investigate how memory constraints
enforce a renormalization of the perceived timescales. Our results show that
qualitatively different discount functions, such as exponential and hyperbolic
discounting, arise as a consequence of an agent's probabilistic model of the
world.","['Pedro A. Ortega', 'Naftali Tishby']",2016-04-18 13:17:55+00:00,2016-05-29 18:39:52+00:00,http://arxiv.org/pdf/1604.05129v2,q-bio.NC,"['q-bio.NC', 'cs.AI', 'stat.ML']","memory shapes time perception and intertemporal choices there is a consensus that human and non-human subjects experience temporal
distortions in many stages of their perceptual and decision-making systems.
similarly, intertemporal choice research has shown that decision-makers
undervalue future outcomes relative to immediate ones. here we combine
techniques from information theory and artificial intelligence to show how both
temporal distortions and intertemporal choice preferences can be explained as a
consequence of the coding efficiency of sensorimotor representation. in
particular, the model implies that interactions that constrain future behavior
are perceived as being both longer in duration and more valuable. furthermore,
using simulations of artificial agents, we investigate how memory constraints
enforce a renormalization of the perceived timescales. our results show that
qualitatively different discount functions, such as exponential and hyperbolic
discounting, arise as a consequence of an agent's probabilistic model of the
world."
The method of artificial systems,"This document is written with the intention to describe in detail a method
and means by which a computer program can reason about the world and in so
doing, increase its analogue to a living system. As the literature is rife and
it is apparent we, as scientists and engineers, have not found the solution,
this document will attempt the solution by grounding its intellectual arguments
within tenets of human cognition in Western philosophy. The result will be a
characteristic description of a method to describe an artificial system
analogous to that performed for a human. The approach was the substance of my
Master's thesis, explored more deeply during the course of my postdoc research.
It focuses primarily on context awareness and choice set within a boundary of
available epistemology, which serves to describe it. Expanded upon, such a
description strives to discover agreement with Kant's critique of reason to
understand how it could be applied to define the architecture of its design.
The intention has never been to mimic human or biological systems, rather, to
understand the profoundly fundamental rules, when leveraged correctly, results
in an artificial consciousness as noumenon while in keeping with the perception
of it as phenomenon.",['Christopher A. Tucker'],2015-07-06 10:52:08+00:00,2017-05-21 13:37:02+00:00,http://arxiv.org/pdf/1507.01384v2,cs.AI,['cs.AI'],"the method of artificial systems this document is written with the intention to describe in detail a method
and means by which a computer program can reason about the world and in so
doing, increase its analogue to a living system. as the literature is rife and
it is apparent we, as scientists and engineers, have not found the solution,
this document will attempt the solution by grounding its intellectual arguments
within tenets of human cognition in western philosophy. the result will be a
characteristic description of a method to describe an artificial system
analogous to that performed for a human. the approach was the substance of my
master's thesis, explored more deeply during the course of my postdoc research.
it focuses primarily on context awareness and choice set within a boundary of
available epistemology, which serves to describe it. expanded upon, such a
description strives to discover agreement with kant's critique of reason to
understand how it could be applied to define the architecture of its design.
the intention has never been to mimic human or biological systems, rather, to
understand the profoundly fundamental rules, when leveraged correctly, results
in an artificial consciousness as noumenon while in keeping with the perception
of it as phenomenon."
"Comment on ""Clustering by fast search and find of density peaks""","In [1], a clustering algorithm was given to find the centers of clusters
quickly. However, the accuracy of this algorithm heavily depend on the
threshold value of d-c. Furthermore, [1] has not provided any efficient way to
select the threshold value of d-c, that is, one can have to estimate the value
of d_c depend on one's subjective experience. In this paper, based on the data
field [2], we propose a new way to automatically extract the threshold value of
d_c from the original data set by using the potential entropy of data field.
For any data set to be clustered, the most reasonable value of d_c can be
objectively calculated from the data set by using our proposed method. The same
experiments in [1] are redone with our proposed method on the same experimental
data set used in [1], the results of which shows that the problem to calculate
the threshold value of d_c in [1] has been solved by using our method.","['Shuliang Wang', 'Dakui Wang', 'Caoyuan Li', 'Yan Li']",2015-01-18 05:15:55+00:00,2015-01-20 03:41:28+00:00,http://arxiv.org/pdf/1501.04267v2,cs.LG,['cs.LG'],"comment on ""clustering by fast search and find of density peaks"" in [1], a clustering algorithm was given to find the centers of clusters
quickly. however, the accuracy of this algorithm heavily depend on the
threshold value of d-c. furthermore, [1] has not provided any efficient way to
select the threshold value of d-c, that is, one can have to estimate the value
of d_c depend on one's subjective experience. in this paper, based on the data
field [2], we propose a new way to automatically extract the threshold value of
d_c from the original data set by using the potential entropy of data field.
for any data set to be clustered, the most reasonable value of d_c can be
objectively calculated from the data set by using our proposed method. the same
experiments in [1] are redone with our proposed method on the same experimental
data set used in [1], the results of which shows that the problem to calculate
the threshold value of d_c in [1] has been solved by using our method."
Text to Multi-level MindMaps: A Novel Method for Hierarchical Visual Abstraction of Natural Language Text,"MindMapping is a well-known technique used in note taking, which encourages
learning and studying. MindMapping has been manually adopted to help present
knowledge and concepts in a visual form. Unfortunately, there is no reliable
automated approach to generate MindMaps from Natural Language text. This work
firstly introduces MindMap Multilevel Visualization concept which is to jointly
visualize and summarize textual information. The visualization is achieved
pictorially across multiple levels using semantic information (i.e. ontology),
while the summarization is achieved by the information in the highest levels as
they represent abstract information in the text. This work also presents the
first automated approach that takes a text input and generates a MindMap
visualization out of it. The approach could visualize text documents in
multilevel MindMaps, in which a high-level MindMap node could be expanded into
child MindMaps. \ignore{ As far as we know, this is the first work that view
MindMapping as a new approach to jointly summarize and visualize textual
information.} The proposed method involves understanding of the input text and
converting it into intermediate Detailed Meaning Representation (DMR). The DMR
is then visualized with two modes; Single level or Multiple levels, which is
convenient for larger text. The generated MindMaps from both approaches were
evaluated based on Human Subject experiments performed on Amazon Mechanical
Turk with various parameter settings.","['Mohamed Elhoseiny', 'Ahmed Elgammal']",2014-08-01 03:18:56+00:00,2014-12-23 06:27:03+00:00,http://arxiv.org/pdf/1408.1031v2,cs.CL,"['cs.CL', 'cs.HC']","text to multi-level mindmaps: a novel method for hierarchical visual abstraction of natural language text mindmapping is a well-known technique used in note taking, which encourages
learning and studying. mindmapping has been manually adopted to help present
knowledge and concepts in a visual form. unfortunately, there is no reliable
automated approach to generate mindmaps from natural language text. this work
firstly introduces mindmap multilevel visualization concept which is to jointly
visualize and summarize textual information. the visualization is achieved
pictorially across multiple levels using semantic information (i.e. ontology),
while the summarization is achieved by the information in the highest levels as
they represent abstract information in the text. this work also presents the
first automated approach that takes a text input and generates a mindmap
visualization out of it. the approach could visualize text documents in
multilevel mindmaps, in which a high-level mindmap node could be expanded into
child mindmaps. \ignore{ as far as we know, this is the first work that view
mindmapping as a new approach to jointly summarize and visualize textual
information.} the proposed method involves understanding of the input text and
converting it into intermediate detailed meaning representation (dmr). the dmr
is then visualized with two modes; single level or multiple levels, which is
convenient for larger text. the generated mindmaps from both approaches were
evaluated based on human subject experiments performed on amazon mechanical
turk with various parameter settings."
What Is It Like to Be a Brain Simulation?,"We frame the question of what kind of subjective experience a brain
simulation would have in contrast to a biological brain. We discuss the brain
prosthesis thought experiment. We evaluate how the experience of the brain
simulation might differ from the biological, according to a number of
hypotheses about experience and the properties of simulation. Then, we identify
finer questions relating to the original inquiry, and answer them from both a
general physicalist, and panexperientialist perspective.",['Eray Özkural'],2014-02-01 17:19:53+00:00,2014-02-01 17:19:53+00:00,http://arxiv.org/pdf/1402.5379v1,cs.AI,"['cs.AI', '68T01']","what is it like to be a brain simulation? we frame the question of what kind of subjective experience a brain
simulation would have in contrast to a biological brain. we discuss the brain
prosthesis thought experiment. we evaluate how the experience of the brain
simulation might differ from the biological, according to a number of
hypotheses about experience and the properties of simulation. then, we identify
finer questions relating to the original inquiry, and answer them from both a
general physicalist, and panexperientialist perspective."
Mining Determinism in Human Strategic Behavior,"This work lies in the fusion of experimental economics and data mining. It
continues author's previous work on mining behaviour rules of human subjects
from experimental data, where game-theoretic predictions partially fail to
work. Game-theoretic predictions aka equilibria only tend to success with
experienced subjects on specific games, what is rarely given. Apart from game
theory, contemporary experimental economics offers a number of alternative
models. In relevant literature, these models are always biased by psychological
and near-psychological theories and are claimed to be proven by the data. This
work introduces a data mining approach to the problem without using vast
psychological background. Apart from determinism, no other biases are regarded.
Two datasets from different human subject experiments are taken for evaluation.
The first one is a repeated mixed strategy zero sum game and the second -
repeated ultimatum game. As result, the way of mining deterministic
regularities in human strategic behaviour is described and evaluated. As future
work, the design of a new representation formalism is discussed.",['Rustam Tagiew'],2012-11-11 11:27:01+00:00,2012-11-11 11:27:01+00:00,http://arxiv.org/pdf/1211.2399v1,cs.GT,"['cs.GT', 'cs.AI']","mining determinism in human strategic behavior this work lies in the fusion of experimental economics and data mining. it
continues author's previous work on mining behaviour rules of human subjects
from experimental data, where game-theoretic predictions partially fail to
work. game-theoretic predictions aka equilibria only tend to success with
experienced subjects on specific games, what is rarely given. apart from game
theory, contemporary experimental economics offers a number of alternative
models. in relevant literature, these models are always biased by psychological
and near-psychological theories and are claimed to be proven by the data. this
work introduces a data mining approach to the problem without using vast
psychological background. apart from determinism, no other biases are regarded.
two datasets from different human subject experiments are taken for evaluation.
the first one is a repeated mixed strategy zero sum game and the second -
repeated ultimatum game. as result, the way of mining deterministic
regularities in human strategic behaviour is described and evaluated. as future
work, the design of a new representation formalism is discussed."
Conscious Machines and Consciousness Oriented Programming,"In this paper, we investigate the following question: how could you write
such computer programs that can work like conscious beings? The motivation
behind this question is that we want to create such applications that can see
the future. The aim of this paper is to provide an overall conceptual framework
for this new approach to machine consciousness. So we introduce a new
programming paradigm called Consciousness Oriented Programming (COP).",['Norbert Bátfai'],2011-08-14 12:27:39+00:00,2011-08-14 12:27:39+00:00,http://arxiv.org/pdf/1108.2865v1,cs.AI,"['cs.AI', '68T35', 'I.2.5; F.1.1']","conscious machines and consciousness oriented programming in this paper, we investigate the following question: how could you write
such computer programs that can work like conscious beings? the motivation
behind this question is that we want to create such applications that can see
the future. the aim of this paper is to provide an overall conceptual framework
for this new approach to machine consciousness. so we introduce a new
programming paradigm called consciousness oriented programming (cop)."
Not only a lack of right definitions: Arguments for a shift in information-processing paradigm,"Machine Consciousness and Machine Intelligence are not simply new buzzwords
that occupy our imagination. Over the last decades, we witness an unprecedented
rise in attempts to create machines with human-like features and capabilities.
However, despite widespread sympathy and abundant funding, progress in these
enterprises is far from being satisfactory. The reasons for this are twofold:
First, the notions of cognition and intelligence (usually borrowed from human
behavior studies) are notoriously blurred and ill-defined, and second, the
basic concepts underpinning the whole discourse are by themselves either
undefined or defined very vaguely. That leads to improper and inadequate
research goals determination, which I will illustrate with some examples drawn
from recent documents issued by DARPA and the European Commission. On the other
hand, I would like to propose some remedies that, I hope, would improve the
current state-of-the-art disgrace.",['Emanuel Diamant'],2010-09-01 02:37:54+00:00,2010-09-01 02:37:54+00:00,http://arxiv.org/pdf/1009.0077v1,cs.AI,"['cs.AI', 'q-bio.NC']","not only a lack of right definitions: arguments for a shift in information-processing paradigm machine consciousness and machine intelligence are not simply new buzzwords
that occupy our imagination. over the last decades, we witness an unprecedented
rise in attempts to create machines with human-like features and capabilities.
however, despite widespread sympathy and abundant funding, progress in these
enterprises is far from being satisfactory. the reasons for this are twofold:
first, the notions of cognition and intelligence (usually borrowed from human
behavior studies) are notoriously blurred and ill-defined, and second, the
basic concepts underpinning the whole discourse are by themselves either
undefined or defined very vaguely. that leads to improper and inadequate
research goals determination, which i will illustrate with some examples drawn
from recent documents issued by darpa and the european commission. on the other
hand, i would like to propose some remedies that, i hope, would improve the
current state-of-the-art disgrace."
Logical Evaluation of Consciousness: For Incorporating Consciousness into Machine Architecture,"Machine Consciousness is the study of consciousness in a biological,
philosophical, mathematical and physical perspective and designing a model that
can fit into a programmable system architecture. Prime objective of the study
is to make the system architecture behave consciously like a biological model
does. Present work has developed a feasible definition of consciousness, that
characterizes consciousness with four parameters i.e., parasitic, symbiotic,
self referral and reproduction. Present work has also developed a biologically
inspired consciousness architecture that has following layers: quantum layer,
cellular layer, organ layer and behavioral layer and traced the characteristics
of consciousness at each layer. Finally, the work has estimated physical and
algorithmic architecture to devise a system that can behave consciously.","['C. N. Padhy', 'R. R. Panda']",2010-02-01 04:07:34+00:00,2010-02-01 04:07:34+00:00,http://arxiv.org/pdf/1002.0177v1,cs.AI,['cs.AI'],"logical evaluation of consciousness: for incorporating consciousness into machine architecture machine consciousness is the study of consciousness in a biological,
philosophical, mathematical and physical perspective and designing a model that
can fit into a programmable system architecture. prime objective of the study
is to make the system architecture behave consciously like a biological model
does. present work has developed a feasible definition of consciousness, that
characterizes consciousness with four parameters i.e., parasitic, symbiotic,
self referral and reproduction. present work has also developed a biologically
inspired consciousness architecture that has following layers: quantum layer,
cellular layer, organ layer and behavioral layer and traced the characteristics
of consciousness at each layer. finally, the work has estimated physical and
algorithmic architecture to devise a system that can behave consciously."
Quantum formalism to describe binocular rivalry,"On the basis of the general character and operation of the process of
perception, a formalism is sought to mathematically describe the subjective or
abstract/mental process of perception. It is shown that the formalism of
orthodox quantum theory of measurement, where the observer plays a key role, is
a broader mathematical foundation which can be adopted to describe the dynamics
of the subjective experience. The mathematical formalism describes the
psychophysical dynamics of the subjective or cognitive experience as
communicated to us by the subject. Subsequently, the formalism is used to
describe simple perception processes and, in particular, to describe the
probability distribution of dominance duration obtained from the testimony of
subjects experiencing binocular rivalry. Using this theory and parameters based
on known values of neuronal oscillation frequencies and firing rates, the
calculated probability distribution of dominance duration of rival states in
binocular rivalry under various conditions is found to be in good agreement
with available experimental data. This theory naturally explains an observed
marked increase in dominance duration in binocular rivalry upon periodic
interruption of stimulus and yields testable predictions for the distribution
of perceptual alteration in time.",['Efstratios Manousakis'],2007-09-28 02:17:02+00:00,2009-10-13 19:09:22+00:00,http://arxiv.org/pdf/0709.4516v2,q-bio.NC,['q-bio.NC'],"quantum formalism to describe binocular rivalry on the basis of the general character and operation of the process of
perception, a formalism is sought to mathematically describe the subjective or
abstract/mental process of perception. it is shown that the formalism of
orthodox quantum theory of measurement, where the observer plays a key role, is
a broader mathematical foundation which can be adopted to describe the dynamics
of the subjective experience. the mathematical formalism describes the
psychophysical dynamics of the subjective or cognitive experience as
communicated to us by the subject. subsequently, the formalism is used to
describe simple perception processes and, in particular, to describe the
probability distribution of dominance duration obtained from the testimony of
subjects experiencing binocular rivalry. using this theory and parameters based
on known values of neuronal oscillation frequencies and firing rates, the
calculated probability distribution of dominance duration of rival states in
binocular rivalry under various conditions is found to be in good agreement
with available experimental data. this theory naturally explains an observed
marked increase in dominance duration in binocular rivalry upon periodic
interruption of stimulus and yields testable predictions for the distribution
of perceptual alteration in time."
Biological nonlocality and the mind-brain interaction problem: comments on a new empirical approach,"Up to now, we have been faced with an age old fundamental dilemma posed by
the mind-brain interaction problem, i.e. how is it that the mind which is
subjective and immaterial, can interact with the brain which is objective and
material? Analysis of recent experiments appears to indicate that quantum
mechanics may have a role to play in the resolution of the mind-brain
interaction problem in the form of biological entanglement and nonlocality.
This analysis, when coupled with ongoing and proposed experiments, may help us
to simultaneously resolve related issues such as whether mental events can
initiate neural events, the transference of conscious subjective experience,
the measurement problem and the binding problem.",['Fred Thaheld'],2005-10-19 13:30:25+00:00,2005-10-19 13:30:25+00:00,http://arxiv.org/pdf/q-bio/0510039v1,q-bio.NC,"['q-bio.NC', 'quant-ph']","biological nonlocality and the mind-brain interaction problem: comments on a new empirical approach up to now, we have been faced with an age old fundamental dilemma posed by
the mind-brain interaction problem, i.e. how is it that the mind which is
subjective and immaterial, can interact with the brain which is objective and
material? analysis of recent experiments appears to indicate that quantum
mechanics may have a role to play in the resolution of the mind-brain
interaction problem in the form of biological entanglement and nonlocality.
this analysis, when coupled with ongoing and proposed experiments, may help us
to simultaneously resolve related issues such as whether mental events can
initiate neural events, the transference of conscious subjective experience,
the measurement problem and the binding problem."
The Physics of 'Now',"The world is four-dimensional according to fundamental physics, governed by
basic laws that operate in a spacetime that has no unique division into space
and time. Yet our subjective experience is divided into present, past, and
future. This paper discusses the origin of this division in terms of simple
models of information gathering and utilizing systems (IGUSes). Past, present,
and future are not properties of four-dimensional spacetime but notions
describing how individual IGUSes process information. Their origin is to be
found in how these IGUSes evolved or were constructed. The past, present, and
future of an IGUS is consistent with the four-dimensional laws of physics and
can be described in four-dimensional terms. The present, for instance, is not a
moment of time in the sense of a spacelike surface in spacetime. Rather there
is a localized notion of present at each point along an IGUS' world line. The
common present of many localized IGUSes is an approximate notion appropriate
when they are sufficiently close to each other and have relative velocities
much less than that of light. But modes of organization that are different from
present, past and future can be imagined that are consistent with the physical
laws. We speculate why the present, past, and future organization might be
favored by evolution and therefore a cognitive universal.",['James B. Hartle'],2004-02-27 21:59:47+00:00,2004-05-21 22:45:51+00:00,http://arxiv.org/pdf/gr-qc/0403001v2,gr-qc,"['gr-qc', 'physics.pop-ph', 'q-bio.NC']","the physics of 'now' the world is four-dimensional according to fundamental physics, governed by
basic laws that operate in a spacetime that has no unique division into space
and time. yet our subjective experience is divided into present, past, and
future. this paper discusses the origin of this division in terms of simple
models of information gathering and utilizing systems (iguses). past, present,
and future are not properties of four-dimensional spacetime but notions
describing how individual iguses process information. their origin is to be
found in how these iguses evolved or were constructed. the past, present, and
future of an igus is consistent with the four-dimensional laws of physics and
can be described in four-dimensional terms. the present, for instance, is not a
moment of time in the sense of a spacelike surface in spacetime. rather there
is a localized notion of present at each point along an igus' world line. the
common present of many localized iguses is an approximate notion appropriate
when they are sufficiently close to each other and have relative velocities
much less than that of light. but modes of organization that are different from
present, past and future can be imagined that are consistent with the physical
laws. we speculate why the present, past, and future organization might be
favored by evolution and therefore a cognitive universal."
