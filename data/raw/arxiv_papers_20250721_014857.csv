Title,Summary,Authors,Published,Updated,PDF_URL,Primary_Category,Categories
Visually grounded emotion regulation via diffusion models and user-driven reappraisal,"Cognitive reappraisal is a key strategy in emotion regulation, involving
reinterpretation of emotionally charged stimuli to alter affective responses.
Despite its central role in clinical and cognitive science, real-world
reappraisal interventions remain cognitively demanding, abstract, and primarily
verbal. This reliance on higher-order cognitive and linguistic processes is
often impaired in individuals with trauma or depression, limiting the
effectiveness of standard approaches. Here, we propose a novel, visually based
augmentation of cognitive reappraisal by integrating large-scale text-to-image
diffusion models into the emotional regulation process. Specifically, we
introduce a system in which users reinterpret emotionally negative images via
spoken reappraisals, which are transformed into supportive, emotionally
congruent visualizations using stable diffusion models with a fine-tuned
IP-adapter. This generative transformation visually instantiates users'
reappraisals while maintaining structural similarity to the original stimuli,
externalizing and reinforcing regulatory intent. To test this approach, we
conducted a within-subject experiment (N = 20) using a modified cognitive
emotion regulation (CER) task. Participants reappraised or described aversive
images from the International Affective Picture System (IAPS), with or without
AI-generated visual feedback. Results show that AI-assisted reappraisal
significantly reduced negative affect compared to both non-AI and control
conditions. Further analyses reveal that sentiment alignment between
participant reappraisals and generated images correlates with affective relief,
suggesting that multimodal coherence enhances regulatory efficacy. These
findings demonstrate that generative visual input can support cogitive
reappraisal and open new directions at the intersection of generative AI,
affective computing, and therapeutic technology.","['Edoardo Pinzuti', 'Oliver Tüscher', 'André Ferreira Castro']",2025-07-14 23:28:59+00:00,2025-07-14 23:28:59+00:00,http://arxiv.org/pdf/2507.10861v1,cs.LG,['cs.LG']
Evaluating the Effectiveness of Large Language Models in Solving Simple Programming Tasks: A User-Centered Study,"As large language models (LLMs) become more common in educational tools and
programming environments, questions arise about how these systems should
interact with users. This study investigates how different interaction styles
with ChatGPT-4o (passive, proactive, and collaborative) affect user performance
on simple programming tasks. I conducted a within-subjects experiment where
fifteen high school students participated, completing three problems under
three distinct versions of the model. Each version was designed to represent a
specific style of AI support: responding only when asked, offering suggestions
automatically, or engaging the user in back-and-forth dialogue.Quantitative
analysis revealed that the collaborative interaction style significantly
improved task completion time compared to the passive and proactive conditions.
Participants also reported higher satisfaction and perceived helpfulness when
working with the collaborative version. These findings suggest that the way an
LLM communicates, how it guides, prompts, and responds, can meaningfully impact
learning and performance. This research highlights the importance of designing
LLMs that go beyond functional correctness to support more interactive,
adaptive, and user-centered experiences, especially for novice programmers.",['Kai Deng'],2025-07-05 13:52:31+00:00,2025-07-05 13:52:31+00:00,http://arxiv.org/pdf/2507.04043v1,cs.HC,"['cs.HC', 'cs.AI']"
Interaction Techniques that Encourage Longer Prompts Can Improve Psychological Ownership when Writing with AI,"Writing longer prompts for an AI assistant to generate a short story
increases psychological ownership, a user's feeling that the writing belongs to
them. To encourage users to write longer prompts, we evaluated two interaction
techniques that modify the prompt entry interface of chat-based generative AI
assistants: pressing and holding the prompt submission button, and continuously
moving a slider up and down when submitting a short prompt. A within-subjects
experiment investigated the effects of such techniques on prompt length and
psychological ownership, and results showed that these techniques increased
prompt length and led to higher psychological ownership than baseline
techniques. A second experiment further augmented these techniques by showing
AI-generated suggestions for how the prompts could be expanded. This further
increased prompt length, but did not lead to improvements in psychological
ownership. Our results show that simple interface modifications like these can
elicit more writing from users and improve psychological ownership.","['Nikhita Joshi', 'Daniel Vogel']",2025-07-04 15:44:24+00:00,2025-07-04 15:44:24+00:00,http://arxiv.org/pdf/2507.03670v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL']"
Longitudinal analysis of heart rate variability as it pertains to anxiety and readiness,"The aim of this study is to explore the relationship between lifestyle
choices, subjective experiences and objective biometric data in a single
individual. The participant, at the time a male in his twenties, used the
EliteHRV app to perform Heart Rate Variability Readings across twenty-six
months accompanied by logs about the previous days activity as well as current
emotional and physical state. The study will use a mixed-methods approach to
analyze the data, including quantitative analysis of the biometric data and
correlation analysis between the biometric data and subjective experience tags.
Qualitative analysis of the daily logs will also be conducted to gain a deeper
understanding of the participant's experiences and to identify keywords,
people, or ideas that affect biometric output. The results of this study will
provide insights into the relationship between subjective and objective
measures, and the potential benefits or drawbacks of certain lifestyle choices
and ways of thinking. The findings could have implications for the development
of wearable-based personalized interventions for improving mental health and
well-being.",['Tucker Paron'],2025-06-23 21:01:00+00:00,2025-06-23 21:01:00+00:00,http://arxiv.org/pdf/2506.19128v1,q-bio.NC,['q-bio.NC']
Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots,"Despite growing interest in Learning-by-Teaching (LbT), few studies have
explored how this paradigm can be implemented with autonomous, peer-like social
robots in real classrooms. Most prior work has relied on scripted or
Wizard-of-Oz behaviors, limiting our understanding of how real-time,
interactive learning can be supported by artificial agents. This study
addresses this gap by introducing Interactive Reinforcement Learning (RL) as a
cognitive model for teachable social robots. We conducted two between-subject
experiments with 58 primary school children, who either taught a robot or
practiced independently on a tablet while learning French vocabulary
(memorization) and grammatical rules (inference). The robot, powered by
Interactive RL, learned from the child's evaluative feedback. Children in the
LbT condition achieved significantly higher retention gains compared to those
in the self-practice condition, especially on the grammar task. Learners with
lower prior knowledge benefited most from teaching the robot. Behavioural
metrics revealed that children adapted their teaching strategies over time and
engaged more deeply during inference tasks. This work makes two contributions:
(1) it introduces Interactive RL as a pedagogically effective and scalable
model for peer-robot learning, and (2) it demonstrates, for the first time, the
feasibility of deploying multiple autonomous robots simultaneously in real
classrooms. These findings extend theoretical understanding of LbT by showing
that social robots can function not only as passive tutees but as adaptive
partners that enhance meta-cognitive engagement and long-term learning
outcomes.","['Imene Tarakli', 'Samuele Vinanzi', 'Richard Moore', 'Alessandro Di Nuovo']",2025-06-23 07:51:04+00:00,2025-06-23 07:51:04+00:00,http://arxiv.org/pdf/2506.18365v1,cs.RO,"['cs.RO', 'cs.AI', 'cs.HC']"
Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness,"This paper presents a novel paradigm of the local percept-perceiver
phenomenon to formalize certain observations in neuroscientific theories of
consciousness. Using this model, a set-theoretic formalism is developed for
artificial systems, and the existence of machine consciousness is proved by
invoking Zermelo-Fraenkel set theory. The article argues for the possibility of
a reductionist form of epistemic consciousness within machines.",['Shri Lal Raghudev Ram Singh'],2025-06-22 01:53:14+00:00,2025-06-22 01:53:14+00:00,http://arxiv.org/pdf/2506.18935v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
Quantifying Flow State Dynamics: A Prefrontal Cortex EEG-Based Model Validation Study. Unveiling the Prefrontal Cortex's Role in Flow State Experience: An Empirical EEG Analysis,"This article aims to explore the optimization of mental performance through
the analysis of metrics associated with the psychological state known as flow.
Several clinical studies have shown a correlation between the mental state of
flow (characterized by deep and relaxed concentration and high psychophysical
efficiency) and brain activity measured through electroencephalography (EEG).
This study confirms such a correlation, focusing in particular on the sports
field, where the flow state tends to occur more frequently. To conduct the
study, Sporthype developed proprietary software that integrates several
predictive models, in particular the Flow State Index (FSI), implemented within
the Holytics system. An analytical protocol was established, including mental
exercises and data collection sessions using the portable EEG device Muse,
accompanied by a questionnaire to gather athletes' subjective perceptions of
their mental state. The results revealed a significant alignment between the
EEG data and the subjective experiences reported in the questionnaires,
confirming the feasibility of detecting the flow state through prefrontal
cortex activity. Furthermore, the psychological exercises included in the study
protocol showed a tangible positive effect in enhancing flow during athletic
performance. Flow improves performance through a more harmonious
synchronization between mind and body. Although golf was the main context of
the experimentation, the mathematical models developed within Holytics were
designed to be applicable to a wide range of sports. In addition to golf,
preliminary tests have been conducted in other sports such as tennis, as well
as in non-sport contexts, including gaming and mental training practices such
as mindfulness, concentration, and visualization.","['Gianluca Rosso', 'Raffaella Ricci', 'Lorenzo Pia', 'Giovanni Rebaudo', 'Michele Guindani', 'Alberto Marocchino', 'Giorgio De Pieri', 'Andrea Filippo Rosso']",2025-06-20 08:42:17+00:00,2025-06-20 08:42:17+00:00,http://arxiv.org/pdf/2506.16838v1,stat.AP,"['stat.AP', 'q-bio.NC']"
The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games,"Large Language Models (LLMs) have shown promise as decision-makers in dynamic
settings, but their stateless nature necessitates creating a natural language
representation of history. We present a unifying framework for systematically
constructing natural language ""state"" representations for prompting LLM agents
in repeated multi-agent games. Previous work on games with LLM agents has taken
an ad hoc approach to encoding game history, which not only obscures the impact
of state representation on agents' behavior, but also limits comparability
between studies. Our framework addresses these gaps by characterizing methods
of state representation along three axes: action informativeness (i.e., the
extent to which the state representation captures actions played); reward
informativeness (i.e., the extent to which the state representation describes
rewards obtained); and prompting style (or natural language compression, i.e.,
the extent to which the full text history is summarized).
  We apply this framework to a dynamic selfish routing game, chosen because it
admits a simple equilibrium both in theory and in human subject experiments
\cite{rapoport_choice_2009}. Despite the game's relative simplicity, we find
that there are key dependencies of LLM agent behavior on the natural language
state representation. In particular, we observe that representations which
provide agents with (1) summarized, rather than complete, natural language
representations of past history; (2) information about regrets, rather than raw
payoffs; and (3) limited information about others' actions lead to behavior
that more closely matches game theoretic equilibrium predictions, and with more
stable game play by the agents. By contrast, other representations can exhibit
either large deviations from equilibrium, higher variation in dynamic game play
over time, or both.","['Lyle Goodyear', 'Rachel Guo', 'Ramesh Johari']",2025-06-18 16:53:38+00:00,2025-06-18 16:53:38+00:00,http://arxiv.org/pdf/2506.15624v1,cs.AI,"['cs.AI', 'I.2.11; I.6.4; F.1.2; F.2.2; G.3; J.7']"
Ghost in the Machine: Examining the Philosophical Implications of Recursive Algorithms in Artificial Intelligence Systems,"This paper investigates whether contemporary AI architectures employing deep
recursion, meta-learning, and self-referential mechanisms provide evidence of
machine consciousness. Integrating philosophical history, cognitive science,
and AI engineering, it situates recursive algorithms within a lineage spanning
Cartesian dualism, Husserlian intentionality, Integrated Information Theory,
the Global Workspace model, and enactivist perspectives. The argument proceeds
through textual analysis, comparative architecture review, and synthesis of
neuroscience findings on integration and prediction. Methodologically, the
study combines conceptual analysis, case studies, and normative risk assessment
informed by phenomenology and embodied cognition. Technical examples, including
transformer self-attention, meta-cognitive agents, and neuromorphic chips,
illustrate how functional self-modeling can arise without subjective
experience. By distinguishing functional from phenomenal consciousness, the
paper argues that symbol grounding, embodiment, and affective qualia remain
unresolved barriers to attributing sentience to current AI. Ethical analysis
explores risks of premature anthropomorphism versus neglect of future sentient
systems; legal implications include personhood, liability, authorship, and
labor impacts. Future directions include quantum architectures, embodied
robotics, unsupervised world modeling, and empirical tests for non-biological
phenomenality. The study reframes the ""hard problem"" as a graded and
increasingly testable phenomenon, rather than a metaphysical impasse. It
concludes that recursive self-referential design enhances capability but does
not entail consciousness or justify moral status. Keywords: Recursive
algorithms; self-reference; machine consciousness; AI ethics; AI consciousness",['Llewellin RG Jegels'],2025-06-18 08:44:35+00:00,2025-06-18 08:44:35+00:00,http://arxiv.org/pdf/2507.01967v1,q-bio.NC,['q-bio.NC']
The Perception of Phase Intercept Distortion and its Application in Data Augmentation,"Phase distortion refers to the alteration of the phase relationships between
frequencies in a signal, which can be perceptible. In this paper, we discuss a
special case of phase distortion known as phase-intercept distortion, which is
created by a frequency-independent phase shift. We hypothesize that, though
this form of distortion changes a signal's waveform significantly, the
distortion is imperceptible. Human-subject experiment results are reported
which are consistent with this hypothesis. Furthermore, we discuss how the
imperceptibility of phase-intercept distortion can be useful for machine
learning, specifically for data augmentation. We conducted multiple experiments
using phase-intercept distortion as a novel approach to data augmentation, and
obtained improved results for audio machine learning tasks.","['Venkatakrishnan Vaidyanathapuram Krishnan', 'Nathaniel Condit-Schultz']",2025-06-17 14:28:14+00:00,2025-06-17 14:28:14+00:00,http://arxiv.org/pdf/2506.14571v1,eess.SP,"['eess.SP', 'cs.LG', 'eess.AS']"
The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness,"Research on artificial consciousness lacks the equivalent of the perceptron:
a small, trainable module that can be copied, benchmarked, and iteratively
improved. We introduce the Reflexive Integrated Information Unit (RIIU), a
recurrent cell that augments its hidden state $h$ with two additional vectors:
(i) a meta-state $\mu$ that records the cell's own causal footprint, and (ii) a
broadcast buffer $B$ that exposes that footprint to the rest of the network. A
sliding-window covariance and a differentiable Auto-$\Phi$ surrogate let each
RIIU maximize local information integration online. We prove that RIIUs (1) are
end-to-end differentiable, (2) compose additively, and (3) perform
$\Phi$-monotone plasticity under gradient ascent. In an eight-way Grid-world, a
four-layer RIIU agent restores $>90\%$ reward within 13 steps after actuator
failure, twice as fast as a parameter-matched GRU, while maintaining a non-zero
Auto-$\Phi$ signal. By shrinking ""consciousness-like"" computation down to unit
scale, RIIUs turn a philosophical debate into an empirical mathematical
problem.","[""Gnankan Landry Regis N'guessan"", 'Issa Karambal']",2025-06-15 14:07:59+00:00,2025-06-15 14:07:59+00:00,http://arxiv.org/pdf/2506.13825v1,cs.AI,['cs.AI']
Subjective Experience in AI Systems: What Do AI Researchers and the Public Believe?,"We surveyed 582 AI researchers who have published in leading AI venues and
838 nationally representative US participants about their views on the
potential development of AI systems with subjective experience and how such
systems should be treated and governed. When asked to estimate the chances that
such systems will exist on specific dates, the median responses were 1% (AI
researchers) and 5% (public) by 2024, 25% and 30% by 2034, and 70% and 60% by
2100, respectively. The median member of the public thought there was a higher
chance that AI systems with subjective experience would never exist (25%) than
the median AI researcher did (10%). Both groups perceived a need for
multidisciplinary expertise to assess AI subjective experience. Although
support for welfare protections for such AI systems exceeded opposition, it
remained far lower than support for protections for animals or the environment.
Attitudes toward moral and governance issues were divided in both groups,
especially regarding whether such systems should be created and what rights or
protections they should receive. Yet a majority of respondents in both groups
agreed that safeguards against the potential risks from AI systems with
subjective experience should be implemented by AI developers now, and if
created, AI systems with subjective experience should treat others well, behave
ethically, and be held accountable. Overall, these results suggest that both AI
researchers and the public regard the emergence of AI systems with subjective
experience as a possibility this century, though substantial uncertainty and
disagreement remain about the timeline and appropriate response.","['Noemi Dreksler', 'Lucius Caviola', 'David Chalmers', 'Carter Allen', 'Alex Rand', 'Joshua Lewis', 'Philip Waggoner', 'Kate Mays', 'Jeff Sebo']",2025-06-13 16:53:28+00:00,2025-06-13 16:53:28+00:00,http://arxiv.org/pdf/2506.11945v1,cs.CY,"['cs.CY', 'cs.AI']"
Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning,"Family caregivers often face substantial mental health challenges due to
their multifaceted roles and limited resources. This study explored the
potential of a large language model (LLM)-powered conversational agent to
deliver evidence-based mental health support for caregivers, specifically
Problem-Solving Therapy (PST) integrated with Motivational Interviewing (MI)
and Behavioral Chain Analysis (BCA). A within-subject experiment was conducted
with 28 caregivers interacting with four LLM configurations to evaluate empathy
and therapeutic alliance. The best-performing models incorporated Few-Shot and
Retrieval-Augmented Generation (RAG) prompting techniques, alongside
clinician-curated examples. The models showed improved contextual understanding
and personalized support, as reflected by qualitative responses and
quantitative ratings on perceived empathy and therapeutic alliances.
Participants valued the model's ability to validate emotions, explore
unexpressed feelings, and provide actionable strategies. However, balancing
thorough assessment with efficient advice delivery remains a challenge. This
work highlights the potential of LLMs in delivering empathetic and tailored
support for family caregivers.","['Liying Wang', 'Ph. D.', 'Daffodil Carrington', 'M. S.', 'Daniil Filienko', 'M. S.', 'Caroline El Jazmi', 'M. S.', 'Serena Jinchen Xie', 'M. S.', 'Martine De Cock', 'Ph. D.', 'Sarah Iribarren', 'Ph. D.', 'Weichao Yuwen', 'Ph. D']",2025-06-13 00:47:57+00:00,2025-06-13 00:47:57+00:00,http://arxiv.org/pdf/2506.11376v1,cs.AI,"['cs.AI', 'cs.CL', 'cs.HC']"
CogniPair: From LLM Chatbots to Conscious AI Agents -- GNWT-Based Multi-Agent Digital Twins for Social Pairing -- Dating & Hiring Applications,"Current large language model (LLM) agents lack authentic human psychological
processes necessary for genuine digital twins and social AI applications. To
address this limitation, we present a computational implementation of Global
Workspace Theory (GNWT) that integrates human cognitive architecture principles
into LLM agents, creating specialized sub-agents for emotion, memory, social
norms, planning, and goal-tracking coordinated through a global workspace
mechanism. However, authentic digital twins require accurate personality
initialization. We therefore develop a novel adventure-based personality test
that evaluates true personality through behavioral choices within interactive
scenarios, bypassing self-presentation bias found in traditional assessments.
Building on these innovations, our CogniPair platform enables digital twins to
engage in realistic simulated dating interactions and job interviews before
real encounters, providing bidirectional cultural fit assessment for both
romantic compatibility and workplace matching. Validation using 551 GNWT-Agents
and Columbia University Speed Dating dataset demonstrates 72% correlation with
human attraction patterns, 77.8% match prediction accuracy, and 74% agreement
in human validation studies. This work advances psychological authenticity in
LLM agents and establishes a foundation for intelligent dating platforms and HR
technology solutions.","['Wanghao Ye', 'Sihan Chen', 'Yiting Wang', 'Shwai He', 'Bowei Tian', 'Guoheng Sun', 'Ziyi Wang', 'Ziyao Wang', 'Yexiao He', 'Zheyu Shen', 'Meng Liu', 'Yuning Zhang', 'Meng Feng', 'Yang Wang', 'Siyuan Peng', 'Yilong Dai', 'Zhenle Duan', 'Hanzhang Qin', 'Ang Li']",2025-06-04 03:54:30+00:00,2025-06-04 03:54:30+00:00,http://arxiv.org/pdf/2506.03543v1,cs.AI,"['cs.AI', 'cs.CY', 'cs.MA']"
MELT: Towards Automated Multimodal Emotion Data Annotation by Leveraging LLM Embedded Knowledge,"Although speech emotion recognition (SER) has advanced significantly with
deep learning, annotation remains a major hurdle. Human annotation is not only
costly but also subject to inconsistencies annotators often have different
preferences and may lack the necessary contextual knowledge, which can lead to
varied and inaccurate labels. Meanwhile, Large Language Models (LLMs) have
emerged as a scalable alternative for annotating text data. However, the
potential of LLMs to perform emotional speech data annotation without human
supervision has yet to be thoroughly investigated. To address these problems,
we apply GPT-4o to annotate a multimodal dataset collected from the sitcom
Friends, using only textual cues as inputs. By crafting structured text
prompts, our methodology capitalizes on the knowledge GPT-4o has accumulated
during its training, showcasing that it can generate accurate and contextually
relevant annotations without direct access to multimodal inputs. Therefore, we
propose MELT, a multimodal emotion dataset fully annotated by GPT-4o. We
demonstrate the effectiveness of MELT by fine-tuning four self-supervised
learning (SSL) backbones and assessing speech emotion recognition performance
across emotion datasets. Additionally, our subjective experiments\' results
demonstrate a consistence performance improvement on SER.","['Xin Jing', 'Jiadong Wang', 'Iosif Tsangko', 'Andreas Triantafyllopoulos', 'Björn W. Schuller']",2025-05-30 11:45:36+00:00,2025-05-30 11:45:36+00:00,http://arxiv.org/pdf/2505.24493v1,cs.AI,"['cs.AI', 'cs.SD', 'eess.AS']"
"Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics","Although popularized AI fairness metrics, e.g., demographic parity, have
uncovered bias in AI-assisted decision-making outcomes, they do not consider
how much effort one has spent to get to where one is today in the input feature
space. However, the notion of effort is important in how Philosophy and humans
understand fairness. We propose a philosophy-informed way to conceptualize and
evaluate Effort-aware Fairness (EaF) based on the concept of Force, or temporal
trajectory of predictive features coupled with inertia. In addition to our
theoretical formulation of EaF metrics, our empirical contributions include: 1/
a pre-registered human subjects experiment, which demonstrates that for both
stages of the (individual) fairness evaluation process, people consider the
temporal trajectory of a predictive feature more than its aggregate value; 2/
pipelines to compute Effort-aware Individual/Group Fairness in the criminal
justice and personal finance contexts. Our work may enable AI model auditors to
uncover and potentially correct unfair decisions against individuals who spent
significant efforts to improve but are still stuck with systemic/early-life
disadvantages outside their control.","['Tin Nguyen', 'Jiannan Xu', 'Zora Che', 'Phuong-Anh Nguyen-Le', 'Rushil Dandamudi', 'Donald Braman', 'Furong Huang', 'Hal Daumé III', 'Zubin Jelveh']",2025-05-25 21:07:13+00:00,2025-05-25 21:07:13+00:00,http://arxiv.org/pdf/2505.19317v1,cs.AI,"['cs.AI', 'cs.CY', 'cs.HC', 'cs.LG']"
MPE-TTS: Customized Emotion Zero-Shot Text-To-Speech Using Multi-Modal Prompt,"Most existing Zero-Shot Text-To-Speech(ZS-TTS) systems generate the unseen
speech based on single prompt, such as reference speech or text descriptions,
which limits their flexibility. We propose a customized emotion ZS-TTS system
based on multi-modal prompt. The system disentangles speech into the content,
timbre, emotion and prosody, allowing emotion prompts to be provided as text,
image or speech. To extract emotion information from different prompts, we
propose a multi-modal prompt emotion encoder. Additionally, we introduce an
prosody predictor to fit the distribution of prosody and propose an emotion
consistency loss to preserve emotion information in the predicted prosody. A
diffusion-based acoustic model is employed to generate the target
mel-spectrogram. Both objective and subjective experiments demonstrate that our
system outperforms existing systems in terms of naturalness and similarity. The
samples are available at https://mpetts-demo.github.io/mpetts_demo/.","['Zhichao Wu', 'Yueteng Kang', 'Songjun Cao', 'Long Ma', 'Qiulin Li', 'Qun Yang']",2025-05-24 01:26:02+00:00,2025-05-24 01:26:02+00:00,http://arxiv.org/pdf/2505.18453v1,cs.SD,"['cs.SD', 'cs.AI', 'eess.AS']"
Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework,"As large language models (LLMs) are increasingly used in multi-agent systems,
questions of fairness should extend beyond resource distribution and procedural
design to include the fairness of how agents communicate. Drawing from
organizational psychology, we introduce a novel framework for evaluating
Interactional fairness encompassing Interpersonal fairness (IF) and
Informational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We
extend the theoretical grounding of Interactional Fairness to non-sentient
agents, reframing fairness as a socially interpretable signal rather than a
subjective experience. We then adapt established tools from organizational
justice research, including Colquitt's Organizational Justice Scale and the
Critical Incident Technique, to measure fairness as a behavioral property of
agent interaction. We validate our framework through a pilot study using
controlled simulations of a resource negotiation task. We systematically
manipulate tone, explanation quality, outcome inequality, and task framing
(collaborative vs. competitive) to assess how IF influences agent behavior.
Results show that tone and justification quality significantly affect
acceptance decisions even when objective outcomes are held constant. In
addition, the influence of IF vs. InfF varies with context. This work lays the
foundation for fairness auditing and norm-sensitive alignment in LLM-MAS.",['Ruta Binkyte'],2025-05-17 13:24:13+00:00,2025-05-17 13:24:13+00:00,http://arxiv.org/pdf/2505.12001v1,cs.AI,"['cs.AI', 'cs.MA']"
Qualia Optimization,"This report explores the speculative question: what if current or future AI
systems have qualia, such as pain or pleasure? It does so by assuming that AI
systems might someday possess qualia -- and that the quality of these
subjective experiences should be considered alongside performance metrics.
Concrete mathematical problem settings, inspired by reinforcement learning
formulations and theories from philosophy of mind, are then proposed and
initial approaches and properties are presented. These properties enable
refinement of the problem setting, culminating with the proposal of methods
that promote reinforcement.",['Philip S. Thomas'],2025-05-16 01:34:03+00:00,2025-05-16 01:34:03+00:00,http://arxiv.org/pdf/2505.10779v1,cs.AI,['cs.AI']
Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?,"Despite its constitutional relevance, the technical ``individual fairness''
criterion has not been operationalized in U.S. state or federal
statutes/regulations. We conduct a human subjects experiment to address this
gap, evaluating which demographic features are relevant for individual fairness
evaluation of recidivism risk assessment (RRA) tools. Our analyses conclude
that the individual similarity function should consider age and sex, but it
should ignore race.","['Tin Trung Nguyen', 'Jiannan Xu', 'Phuong-Anh Nguyen-Le', 'Jonathan Lazar', 'Donald Braman', 'Hal Daumé III', 'Zubin Jelveh']",2025-05-15 00:07:07+00:00,2025-05-26 14:41:08+00:00,http://arxiv.org/pdf/2505.09868v2,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']"
M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis,"Generating full-body human gestures encompassing face, body, hands, and
global movements from audio is a valuable yet challenging task in virtual
avatar creation. Previous systems focused on tokenizing the human gestures
framewisely and predicting the tokens of each frame from the input audio.
However, one observation is that the number of frames required for a complete
expressive human gesture, defined as granularity, varies among different human
gesture patterns. Existing systems fail to model these gesture patterns due to
the fixed granularity of their gesture tokens. To solve this problem, we
propose a novel framework named Multi-Granular Gesture Generator (M3G) for
audio-driven holistic gesture generation. In M3G, we propose a novel
Multi-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct
motion sequences from different temporal granularities. Subsequently, we
proposed a multi-granular token predictor that extracts multi-granular
information from audio and predicts the corresponding motion tokens. Then M3G
reconstructs the human gestures from the predicted tokens using the MGVQ-VAE.
Both objective and subjective experiments demonstrate that our proposed M3G
framework outperforms the state-of-the-art methods in terms of generating
natural and expressive full-body human gestures.","['Zhizhuo Yin', 'Yuk Hang Tsui', 'Pan Hui']",2025-05-13 07:16:58+00:00,2025-05-19 14:01:45+00:00,http://arxiv.org/pdf/2505.08293v2,cs.GR,"['cs.GR', 'cs.AI', 'cs.CV', 'cs.SD', 'eess.AS', 'I.3.6']"
Can Third-parties Read Our Emotions?,"Natural Language Processing tasks that aim to infer an author's private
states, e.g., emotions and opinions, from their written text, typically rely on
datasets annotated by third-party annotators. However, the assumption that
third-party annotators can accurately capture authors' private states remains
largely unexamined. In this study, we present human subjects experiments on
emotion recognition tasks that directly compare third-party annotations with
first-party (author-provided) emotion labels. Our findings reveal significant
limitations in third-party annotations-whether provided by human annotators or
large language models (LLMs)-in faithfully representing authors' private
states. However, LLMs outperform human annotators nearly across the board. We
further explore methods to improve third-party annotation quality. We find that
demographic similarity between first-party authors and third-party human
annotators enhances annotation performance. While incorporating first-party
demographic information into prompts leads to a marginal but statistically
significant improvement in LLMs' performance. We introduce a framework for
evaluating the limitations of third-party annotations and call for refined
annotation practices to accurately represent and model authors' private states.","['Jiayi Li', 'Yingfan Zhou', 'Pranav Narayanan Venkit', 'Halima Binte Islam', 'Sneha Arya', 'Shomir Wilson', 'Sarah Rajtmajer']",2025-04-25 19:52:21+00:00,2025-04-25 19:52:21+00:00,http://arxiv.org/pdf/2504.18673v1,cs.CL,['cs.CL']
Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem,"This paper explores the hard problem of consciousness from a different
perspective. Instead of drawing distinctions between the physical and the
mental, an exploration of a more foundational relationship is examined: the
relationship between structure and quality.
  Information-theoretic measures are developed to quantify the mutual
determinability between structure and quality, including a novel Q-S space for
analyzing fidelity between the two domains. This novel space naturally points
toward a five-fold categorization of possible relationships between structural
and qualitative properties, illustrating each through conceptual and formal
models.
  The ontological implications of each category are examined, shedding light on
debates around functionalism, emergentism, idealism, panpsychism, and neutral
monism.
  This new line of inquiry has established a framework for deriving theoretical
constraints on qualitative systems undergoing evolution that is explored in my
companion paper, Qualia & Natural Selection.",['Ryan Williams'],2025-04-23 23:49:40+00:00,2025-04-23 23:49:40+00:00,http://arxiv.org/pdf/2505.05481v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
Qualia & Natural Selection: Formal Constraints on the Evolution of Consciousness,"This paper explores foundational questions about the relationship of qualia
to natural selection. The primary result is a derivation of specific formal
conditions under which structural systems subject to natural selection can
convey consistent effects in an associated qualitative domain, placing
theoretical and empirical constraints on theories of consciousness. In order to
achieve this result, information-theoretic measures are developed to quantify
the mutual determinability between structure and quality, quantifying fidelity
between the two domains. The fidelities represented by that space are then
incorporated into the Price Equation to yield key bounds on the transmission of
selective effects between domains. Finally, transmission of higher-order
structures between domains is explored. Placement within a broader
philosophical context can be found in the companion paper Structure & Quality.",['Ryan Williams'],2025-04-23 23:39:32+00:00,2025-04-23 23:39:32+00:00,http://arxiv.org/pdf/2505.05480v1,q-bio.NC,"['q-bio.NC', 'q-bio.PE']"
Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms,"Fetal health monitoring through one-dimensional Doppler ultrasound (DUS)
signals offers a cost-effective and accessible approach that is increasingly
gaining interest. Despite its potential, the development of machine learning
based techniques to assess the health condition of mothers and fetuses using
DUS signals remains limited. This scarcity is primarily due to the lack of
extensive DUS datasets with a reliable reference for interpretation and data
imbalance across different gestational ages. In response, we introduce a novel
autoregressive generative model designed to map fetal electrocardiogram (FECG)
signals to corresponding DUS waveforms (Auto-FEDUS). By leveraging a neural
temporal network based on dilated causal convolutions that operate directly on
the waveform level, the model effectively captures both short and long-range
dependencies within the signals, preserving the integrity of generated data.
Cross-subject experiments demonstrate that Auto-FEDUS outperforms conventional
generative architectures across both time and frequency domain evaluations,
producing DUS signals that closely resemble the morphology of their real
counterparts. The realism of these synthesized signals was further gauged using
a quality assessment model, which classified all as good quality, and a heart
rate estimation model, which produced comparable results for generated and real
data, with a Bland-Altman limit of 4.5 beats per minute. This advancement
offers a promising solution for mitigating limited data availability and
enhancing the training of DUS-based fetal models, making them more effective
and generalizable.","['Alireza Rafiei', 'Gari D. Clifford', 'Nasim Katebi']",2025-04-17 15:25:52+00:00,2025-04-17 15:25:52+00:00,http://arxiv.org/pdf/2504.13233v1,cs.LG,['cs.LG']
"Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students","As generative AI transforms educational feedback practices, understanding
students' perceptions of different feedback providers becomes crucial for
effective implementation. This study addresses a critical gap by comparing
undergraduate students' trust in AI-generated, human-created, and human-AI
co-produced feedback, informing how institutions can adapt feedback practices
in this new era. Through a within-subject experiment with 91 participants, we
investigated factors predicting students' ability to distinguish between
feedback types, perception of feedback quality, and potential biases to AI
involvement. Findings revealed that students generally preferred AI and
co-produced feedback over human feedback in terms of perceived usefulness and
objectivity. Only AI feedback suffered a decline in perceived genuineness when
feedback sources were revealed, while co-produced feedback maintained its
positive perception. Educational AI experience improved students' ability to
identify AI feedback and increased their trust in all feedback types, while
general AI experience decreased perceived usefulness and credibility. Male
students consistently rated all feedback types as less valuable than their
female and non-binary counterparts. These insights inform evidence-based
guidelines for integrating AI into higher education feedback systems while
addressing trust concerns and fostering AI literacy among students.","['Audrey Zhang', 'Yifei Gao', 'Wannapon Suraworachet', 'Tanya Nazaretsky', 'Mutlu Cukurova']",2025-04-15 08:06:36+00:00,2025-04-15 08:06:36+00:00,http://arxiv.org/pdf/2504.10961v1,cs.HC,"['cs.HC', 'cs.AI']"
Emergence of psychopathological computations in large language models,"Can large language models (LLMs) implement computations of psychopathology?
An effective approach to the question hinges on addressing two factors. First,
for conceptual validity, we require a general and computational account of
psychopathology that is applicable to computational entities without biological
embodiment or subjective experience. Second, mechanisms underlying LLM
behaviors need to be studied for better methodological validity. Thus, we
establish a computational-theoretical framework to provide an account of
psychopathology applicable to LLMs. To ground the theory for empirical
analysis, we also propose a novel mechanistic interpretability method alongside
a tailored empirical analytic framework. Based on the frameworks, we conduct
experiments demonstrating three key claims: first, that distinct dysfunctional
and problematic representational states are implemented in LLMs; second, that
their activations can spread and self-sustain to trap LLMs; and third, that
dynamic, cyclic structural causal models encoded in the LLMs underpin these
patterns. In concert, the empirical results corroborate our hypothesis that
network-theoretic computations of psychopathology have already emerged in LLMs.
This suggests that certain LLM behaviors mirroring psychopathology may not be a
superficial mimicry but a feature of their internal processing. Thus, our work
alludes to the possibility of AI systems with psychopathological behaviors in
the near future.","['Soo Yong Lee', 'Hyunjin Hwang', 'Taekwan Kim', 'Yuyeong Kim', 'Kyuri Park', 'Jaemin Yoo', 'Denny Borsboom', 'Kijung Shin']",2025-04-10 15:36:30+00:00,2025-04-10 15:36:30+00:00,http://arxiv.org/pdf/2504.08016v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.CL']"
Reflective Empiricism: Bias Reflection and Introspection as a Scientific Method,"This paper introduces Reflective Empiricism, an extension of empirical
science that incorporates subjective perception and consciousness processes as
equally valid sources of knowledge. It views reality as an interplay of
subjective experience and objective laws, comprehensible only through
systematic introspection, bias reflection, and premise-based
logical-explorative modeling. This approach overcomes paradigmatic blindness
arising from unreflected subjective filters in established paradigms, promoting
an adaptable science. Innovations include a method for bias recognition,
premise-based models grounded in observed phenomena to unlock new conceptual
spaces, and Heureka moments - intuitive insights - as starting points for
hypotheses, subsequently tested empirically. The author's self-observation,
such as analyzing belief formation, demonstrates its application and
transformative power. Rooted in philosophical and scientific-historical
references (e.g., Archimedes' intuition, quantum observer effect), Reflective
Empiricism connects physics, psychology, and philosophy, enhancing
interdisciplinary synthesis and accelerating knowledge creation by leveraging
anomalies and subjective depth. It does not seek to replace empirical research
but to enrich it, enabling a more holistic understanding of complex phenomena
like consciousness and advancing 21st-century science.",['Oliver Marc Wittwer'],2025-04-07 08:36:26+00:00,2025-04-07 08:36:26+00:00,http://arxiv.org/pdf/2504.12310v1,physics.soc-ph,"['physics.soc-ph', 'physics.hist-ph', 'q-bio.NC']"
Algorithmic Prompt Generation for Diverse Human-like Teaming and Communication with Large Language Models,"Understanding how humans collaborate and communicate in teams is essential
for improving human-agent teaming and AI-assisted decision-making. However,
relying solely on data from large-scale user studies is impractical due to
logistical, ethical, and practical constraints, necessitating synthetic models
of multiple diverse human behaviors. Recently, agents powered by Large Language
Models (LLMs) have been shown to emulate human-like behavior in social
settings. But, obtaining a large set of diverse behaviors requires manual
effort in the form of designing prompts. On the other hand, Quality Diversity
(QD) optimization has been shown to be capable of generating diverse
Reinforcement Learning (RL) agent behavior. In this work, we combine QD
optimization with LLM-powered agents to iteratively search for prompts that
generate diverse team behavior in a long-horizon, multi-step collaborative
environment. We first show, through a human-subjects experiment (n=54
participants), that humans exhibit diverse coordination and communication
behavior in this domain. We then show that our approach can effectively
replicate trends from human teaming data and also capture behaviors that are
not easily observed without collecting large amounts of data. Our findings
highlight the combination of QD and LLM-powered agents as an effective tool for
studying teaming and communication strategies in multi-agent collaboration.","['Siddharth Srikanth', 'Varun Bhatt', 'Boshen Zhang', 'Werner Hager', 'Charles Michael Lewis', 'Katia P. Sycara', 'Aaquib Tabrez', 'Stefanos Nikolaidis']",2025-04-04 23:09:40+00:00,2025-04-04 23:09:40+00:00,http://arxiv.org/pdf/2504.03991v1,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC', 'cs.MA']"
Tune It Up: Music Genre Transfer and Prediction,"Deep generative models have been used in style transfer tasks for images. In
this study, we adapt and improve CycleGAN model to perform music style transfer
on Jazz and Classic genres. By doing so, we aim to easily generate new songs,
cover music to different music genres and reduce the arrangements needed in
those processes. We train and use music genre classifier to assess the
performance of the transfer models. To that end, we obtain 87.7% accuracy with
Multi-layer Perceptron algorithm. To improve our style transfer baseline, we
add auxiliary discriminators and triplet loss to our model. According to our
experiments, we obtain the best accuracies as 69.4% in Jazz to Classic task and
39.3% in Classic to Jazz task with our developed genre classifier. We also run
a subjective experiment and results of it show that the overall performance of
our transfer model is good and it manages to conserve melody of inputs on the
transferred outputs. Our code is available at https://github.com/
fidansamet/tune-it-up","['Fidan Samet', 'Oguz Bakir', 'Adnan Fidan']",2025-03-27 21:55:57+00:00,2025-03-27 21:55:57+00:00,http://arxiv.org/pdf/2503.22008v1,cs.SD,"['cs.SD', 'cs.LG', 'eess.AS']"
Synthetic media and computational capitalism: towards a critical theory of artificial intelligence,"This paper develops a critical theory of artificial intelligence, within a
historical constellation where computational systems increasingly generate
cultural content that destabilises traditional distinctions between human and
machine production. Through this analysis, I introduce the concept of the
algorithmic condition, a cultural moment when machine-generated work not only
becomes indistinguishable from human creation but actively reshapes our
understanding of ideas of authenticity. This transformation, I argue, moves
beyond false consciousness towards what I call post-consciousness, where the
boundaries between individual and synthetic consciousness become porous.
Drawing on critical theory and extending recent work on computational ideology,
I develop three key theoretical contributions, first, the concept of the
Inversion to describe a new computational turn in algorithmic society; second,
automimetric production as a framework for understanding emerging practices of
automated value creation; and third, constellational analysis as a
methodological approach for mapping the complex interplay of technical systems,
cultural forms and political economic structures. Through these contributions,
I argue that we need new critical methods capable of addressing both the
technical specificity of AI systems and their role in restructuring forms of
life under computational capitalism. The paper concludes by suggesting that
critical reflexivity is needed to engage with the algorithmic condition without
being subsumed by it and that it represents a growing challenge for
contemporary critical theory.",['David M. Berry'],2025-03-22 22:59:28+00:00,2025-03-22 22:59:28+00:00,http://arxiv.org/pdf/2503.18976v1,cs.CY,"['cs.CY', 'cs.AI', 'K.4.0; K.4.1']"
Neural Constraints on Cognitive Experience and Mental Health,"Understanding how neural dynamics shape cognitive experiences remains a
central challenge in neuroscience and psychiatry. Here, we present a novel
framework leveraging state-to-output controllability from dynamical systems
theory to model the interplay between cognitive perturbations, neural activity,
and subjective experience. We demonstrate that large-scale fMRI signals are
constrained to low-dimensional manifolds, where affective and cognitive states
are naturally organized. Furthermore, we provide a theoretically robust method
to estimate the controllability Gramian from steady-state neural responses,
offering a direct measure of the energy required to steer cognitive outcomes.
In five healthy participants viewing 2,185 emotionally evocative short videos,
our analyses reveal a strong alignment between neural activations and affective
ratings, with an average correlation of $r \approx 0.7$. In a clinical cohort
of 255 patients with major depressive disorder, biweekly Hamilton Rating Scale
trajectories over 11 weeks significantly mapped onto these manifolds,
explaining approximately 20% more variance than chance ($p < 10^{-10}$,
numerically better than chance in 93% reaching statistical significance in
one-third of subjects). Our work bridges dynamical systems theory and clinical
neuroscience, providing a principled approach to optimize mental health
treatments by targeting the most efficient neural pathways for cognitive
change.","['Bita Shariatpanahi', 'Erfan Nozari', 'Soroush Daftarian', 'Fahimeh Arab', 'Mina Kheirkhah', 'Felix P. Bernhard', 'Shiva Khodadadi', 'Erik J. Giltay', 'Kaat Hebbrecht', 'Stefan G. Hofmann', 'Tim Hahn', 'Hamidreza Jamalabadi']",2025-03-18 07:32:11+00:00,2025-03-18 07:32:11+00:00,http://arxiv.org/pdf/2503.13981v1,q-bio.NC,['q-bio.NC']
Training Human-Robot Teams by Improving Transparency Through a Virtual Spectator Interface,"After-action reviews (AARs) are professional discussions that help operators
and teams enhance their task performance by analyzing completed missions with
peers and professionals. Previous studies that compared different formats of
AARs have mainly focused on human teams. However, the inclusion of robotic
teammates brings along new challenges in understanding teammate intent and
communication. Traditional AAR between human teammates may not be satisfactory
for human-robot teams. To address this limitation, we propose a new training
review (TR) tool, called the Virtual Spectator Interface (VSI), to enhance
human-robot team performance and situational awareness (SA) in a simulated
search mission. The proposed VSI primarily utilizes visual feedback to review
subjects' behavior. To examine the effectiveness of VSI, we took elements from
AAR to conduct our own TR, designed a 1 x 3 between-subjects experiment with
experimental conditions: TR with (1) VSI, (2) screen recording, and (3)
non-technology (only verbal descriptions). The results of our experiments
demonstrated that the VSI did not result in significantly better team
performance than other conditions. However, the TR with VSI led to more
improvement in the subjects SA over the other conditions.","['Sean Dallas', 'Hongjiao Qiang', 'Motaz AbuHijleh', 'Wonse Jo', 'Kayla Riegner', 'Jon Smereka', 'Lionel Robert', 'Wing-Yue Louie', 'Dawn M. Tilbury']",2025-03-12 21:13:34+00:00,2025-04-12 22:20:02+00:00,http://arxiv.org/pdf/2503.09849v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.RO', 'H.5.2; I.2.9']"
"Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges","With the significant progress of artificial intelligence (AI) and
consciousness science, artificial consciousness (AC) has recently gained
popularity. This work provides a broad overview of the main topics and current
trends in AC. The first part traces the history of this interdisciplinary field
to establish context and clarify key terminology, including the distinction
between Weak and Strong AC. The second part examines major trends in AC
implementations, emphasising the synergy between Global Workspace and Attention
Schema, as well as the problem of evaluating the internal states of artificial
systems. The third part analyses the ethical dimension of AC development,
revealing both critical risks and transformative opportunities. The last part
offers recommendations to guide AC research responsibly, and outlines the
limitations of this study as well as avenues for future research. The main
conclusion is that while AC appears both indispensable and inevitable for
scientific progress, serious efforts are required to address the far-reaching
impact of this innovative research path.",['Aïda Elamrani'],2025-03-05 09:34:36+00:00,2025-03-05 09:34:36+00:00,http://arxiv.org/pdf/2503.05823v1,cs.CY,"['cs.CY', 'cs.AI']"
Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology,"Stroboscopic light stimulation (SLS) on closed eyes typically induces simple
visual hallucinations (VHs), characterised by vivid, geometric and colourful
patterns. A dataset of 862 sentences, extracted from 422 open subjective
reports, was recently compiled as part of the Dreamachine programme (Collective
Act, 2022), an immersive multisensory experience that combines SLS and spatial
sound in a collective setting. Although open reports extend the range of
reportable phenomenology, their analysis presents significant challenges,
particularly in systematically identifying patterns. To address this challenge,
we implemented a data-driven approach leveraging Large Language Models and
Topic Modelling to uncover and interpret latent experiential topics directly
from the Dreamachine's text-based reports. Our analysis confirmed the presence
of simple VHs typically documented in scientific studies of SLS, while also
revealing experiences of altered states of consciousness and complex
hallucinations. Building on these findings, our computational approach expands
the systematic study of subjective experience by enabling data-driven analyses
of open-ended phenomenological reports, capturing experiences not readily
identified through standard questionnaires. By revealing rich and multifaceted
aspects of experiences, our study broadens our understanding of
stroboscopically-induced phenomena while highlighting the potential of Natural
Language Processing and Large Language Models in the emerging field of
computational (neuro)phenomenology. More generally, this approach provides a
practically applicable methodology for uncovering subtle hidden patterns of
subjective experience across diverse research domains.","['Romy Beauté', 'David J. Schwartzman', 'Guillaume Dumas', 'Jennifer Crook', 'Fiona Macpherson', 'Adam B. Barrett', 'Anil K. Seth']",2025-02-25 16:11:40+00:00,2025-02-25 16:11:40+00:00,http://arxiv.org/pdf/2502.18318v1,cs.CL,"['cs.CL', 'q-bio.NC']"
Socratic: Enhancing Human Teamwork via AI-enabled Coaching,"Coaches are vital for effective collaboration, but cost and resource
constraints often limit their availability during real-world tasks. This
limitation poses serious challenges in life-critical domains that rely on
effective teamwork, such as healthcare and disaster response. To address this
gap, we propose and realize an innovative application of AI: task-time team
coaching. Specifically, we introduce Socratic, a novel AI system that
complements human coaches by providing real-time guidance during task
execution. Socratic monitors team behavior, detects misalignments in team
members' shared understanding, and delivers automated interventions to improve
team performance. We validated Socratic through two human subject experiments
involving dyadic collaboration. The results demonstrate that the system
significantly enhances team performance with minimal interventions.
Participants also perceived Socratic as helpful and trustworthy, supporting its
potential for adoption. Our findings also suggest promising directions both for
AI research and its practical applications to enhance human teamwork.","['Sangwon Seo', 'Bing Han', 'Rayan E. Harari', 'Roger D. Dias', 'Marco A. Zenati', 'Eduardo Salas', 'Vaibhav Unhelkar']",2025-02-24 20:45:43+00:00,2025-02-24 20:45:43+00:00,http://arxiv.org/pdf/2502.17643v1,cs.AI,"['cs.AI', 'cs.HC', 'cs.LG', 'cs.MA']"
Grounded Persuasive Language Generation for Automated Marketing,"This paper develops an agentic framework that employs large language models
(LLMs) to automate the generation of persuasive and grounded marketing content,
using real estate listing descriptions as our focal application domain. Our
method is designed to align the generated content with user preferences while
highlighting useful factual attributes. This agent consists of three key
modules: (1) Grounding Module, mimicking expert human behavior to predict
marketable features; (2) Personalization Module, aligning content with user
preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion
of localized features. We conduct systematic human-subject experiments in the
domain of real estate marketing, with a focus group of potential house buyers.
The results demonstrate that marketing descriptions generated by our approach
are preferred over those written by human experts by a clear margin while
maintaining the same level of factual accuracy. Our findings suggest a
promising agentic approach to automate large-scale targeted marketing while
ensuring factuality of content generation.","['Jibang Wu', 'Chenghao Yang', 'Simon Mahns', 'Yi Wu', 'Chaoqi Wang', 'Hao Zhu', 'Fei Fang', 'Haifeng Xu']",2025-02-24 03:36:57+00:00,2025-06-07 15:54:20+00:00,http://arxiv.org/pdf/2502.16810v3,cs.AI,"['cs.AI', 'cs.CL', 'cs.HC', 'econ.GN', 'q-fin.EC']"
Identifying Features that Shape Perceived Consciousness in Large Language Model-based AI: A Quantitative Study of Human Responses,"This study quantitively examines which features of AI-generated text lead
humans to perceive subjective consciousness in large language model (LLM)-based
AI systems. Drawing on 99 passages from conversations with Claude 3 Opus and
focusing on eight features -- metacognitive self-reflection, logical reasoning,
empathy, emotionality, knowledge, fluency, unexpectedness, and subjective
expressiveness -- we conducted a survey with 123 participants. Using regression
and clustering analyses, we investigated how these features influence
participants' perceptions of AI consciousness. The results reveal that
metacognitive self-reflection and the AI's expression of its own emotions
significantly increased perceived consciousness, while a heavy emphasis on
knowledge reduced it. Participants clustered into seven subgroups, each showing
distinct feature-weighting patterns. Additionally, higher prior knowledge of
LLMs and more frequent usage of LLM-based chatbots were associated with greater
overall likelihood assessments of AI consciousness. This study underscores the
multidimensional and individualized nature of perceived AI consciousness and
provides a foundation for better understanding the psychosocial implications of
human-AI interaction.","['Bongsu Kang', 'Jundong Kim', 'Tae-Rim Yun', 'Hyojin Bae', 'Chang-Eop Kim']",2025-02-21 10:27:28+00:00,2025-02-25 01:40:03+00:00,http://arxiv.org/pdf/2502.15365v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'I.2.7; K.4']"
The influence of motion features in temporal perception,"This paper examines the role of manner-of-motion verbs in shaping subjective
temporal perception and emotional resonance. Through four complementary
studies, we explore how these verbs influence the conceptualization of time,
examining their use in literal and metaphorical (temporal) contexts. Our
findings reveal that faster verbs (e.g., fly, zoom) evoke dynamic and engaging
temporal experiences, often linked to positive emotions and greater agency. In
contrast, slower verbs (e.g., crawl, drag) convey passivity, monotony, and
negative emotions, reflecting tedious or constrained experiences of time. These
effects are amplified in metaphorical contexts, where manner verbs encode
emotional and experiential nuances that transcend their literal meanings. We
also find that participants prefer manner verbs over path verbs (e.g., go,
pass) in emotionally charged temporal contexts, as manner verbs capture the
experiential and emotional qualities of time more effectively. These findings
highlight the interplay between language, motion, and emotion in shaping
temporal perception, offering insights into how linguistic framing influences
subjective experiences of time.","['Rosa Illan Castillo', 'Javier Valenzuela']",2025-02-18 18:33:50+00:00,2025-02-18 18:33:50+00:00,http://arxiv.org/pdf/2502.13114v1,cs.CL,['cs.CL']
AI Generations: From AI 1.0 to AI 4.0,"This paper proposes that Artificial Intelligence (AI) progresses through
several overlapping generations: AI 1.0 (Information AI), AI 2.0 (Agentic AI),
AI 3.0 (Physical AI), and now a speculative AI 4.0 (Conscious AI). Each of
these AI generations is driven by shifting priorities among algorithms,
computing power, and data. AI 1.0 ushered in breakthroughs in pattern
recognition and information processing, fueling advances in computer vision,
natural language processing, and recommendation systems. AI 2.0 built on these
foundations through real-time decision-making in digital environments,
leveraging reinforcement learning and adaptive planning for agentic AI
applications. AI 3.0 extended intelligence into physical contexts, integrating
robotics, autonomous vehicles, and sensor-fused control systems to act in
uncertain real-world settings. Building on these developments, AI 4.0 puts
forward the bold vision of self-directed AI capable of setting its own goals,
orchestrating complex training regimens, and possibly exhibiting elements of
machine consciousness. This paper traces the historical foundations of AI
across roughly seventy years, mapping how changes in technological bottlenecks
from algorithmic innovation to high-performance computing to specialized data,
have spurred each generational leap. It further highlights the ongoing
synergies among AI 1.0, 2.0, 3.0, and 4.0, and explores the profound ethical,
regulatory, and philosophical challenges that arise when artificial systems
approach (or aspire to) human-like autonomy. Ultimately, understanding these
evolutions and their interdependencies is pivotal for guiding future research,
crafting responsible governance, and ensuring that AI transformative potential
benefits society as a whole.","['Jiahao Wu', 'Hengxu You', 'Jing Du']",2025-02-16 23:19:44+00:00,2025-02-16 23:19:44+00:00,http://arxiv.org/pdf/2502.11312v1,cs.AI,['cs.AI']
Agency in Artificial Intelligence Systems,"There is a general concern that present developments in artificial
intelligence (AI) research will lead to sentient AI systems, and these may pose
an existential threat to humanity. But why cannot sentient AI systems benefit
humanity instead? This paper endeavours to put this question in a tractable
manner. I ask whether a putative AI system will develop an altruistic or a
malicious disposition towards our society, or what would be the nature of its
agency? Given that AI systems are being developed into formidable problem
solvers, we can reasonably expect these systems to preferentially take on
conscious aspects of human problem solving. I identify the relevant phenomenal
aspects of agency in human problem solving. The functional aspects of conscious
agency can be monitored using tools provided by functionalist theories of
consciousness. A recent expert report (Butlin et al. 2023) has identified
functionalist indicators of agency based on these theories. I show how to use
the Integrated Information Theory (IIT) of consciousness, to monitor the
phenomenal nature of this agency. If we are able to monitor the agency of AI
systems as they develop, then we can dissuade them from becoming a menace to
society while encouraging them to be an aid.",['Parashar Das'],2025-02-09 02:21:14+00:00,2025-02-09 02:21:14+00:00,http://arxiv.org/pdf/2502.10434v1,cs.AI,"['cs.AI', 'cs.CY']"
Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality,"This paper reports on the results from a pilot study investigating the impact
of automatic speech recognition (ASR) technology on interpreting quality in
remote healthcare interpreting settings. Employing a within-subjects experiment
design with four randomised conditions, this study utilises scripted medical
consultations to simulate dialogue interpreting tasks. It involves four trainee
interpreters with a language combination of Chinese and English. It also
gathers participants' experience and perceptions of ASR support through cued
retrospective reports and semi-structured interviews. Preliminary data suggest
that the availability of ASR, specifically the access to full ASR transcripts
and to ChatGPT-generated summaries based on ASR, effectively improved
interpreting quality. Varying types of ASR output had different impacts on the
distribution of interpreting error types. Participants reported similar
interactive experiences with the technology, expressing their preference for
full ASR transcripts. This pilot study shows encouraging results of applying
ASR to dialogue-based healthcare interpreting and offers insights into the
optimal ways to present ASR output to enhance interpreter experience and
performance. However, it should be emphasised that the main purpose of this
study was to validate the methodology and that further research with a larger
sample size is necessary to confirm these findings.","['Shiyi Tan', 'Constantin Orăsan', 'Sabine Braun']",2025-02-05 17:17:29+00:00,2025-02-05 17:17:29+00:00,http://arxiv.org/pdf/2502.03381v1,cs.CL,['cs.CL']
OceanChat: The Effect of Virtual Conversational AI Agents on Sustainable Attitude and Behavior Change,"Marine ecosystems face unprecedented threats from climate change and plastic
pollution, yet traditional environmental education often struggles to translate
awareness into sustained behavioral change. This paper presents OceanChat, an
interactive system leveraging large language models to create conversational AI
agents represented as animated marine creatures -- specifically a beluga whale,
a jellyfish, and a seahorse -- designed to promote environmental behavior (PEB)
and foster awareness through personalized dialogue. Through a between-subjects
experiment (N=900), we compared three conditions: (1) Static Scientific
Information, providing conventional environmental education through text and
images; (2) Static Character Narrative, featuring first-person storytelling
from 3D-rendered marine creatures; and (3) Conversational Character Narrative,
enabling real-time dialogue with AI-powered marine characters. Our analysis
revealed that the Conversational Character Narrative condition significantly
increased behavioral intentions and sustainable choice preferences compared to
static approaches. The beluga whale character demonstrated consistently
stronger emotional engagement across multiple measures, including perceived
anthropomorphism and empathy. However, impacts on deeper measures like climate
policy support and psychological distance were limited, highlighting the
complexity of shifting entrenched beliefs. Our work extends research on
sustainability interfaces facilitating PEB and offers design principles for
creating emotionally resonant, context-aware AI characters. By balancing
anthropomorphism with species authenticity, OceanChat demonstrates how
interactive narratives can bridge the gap between environmental knowledge and
real-world behavior change.","['Pat Pataranutaporn', 'Alexander Doudkin', 'Pattie Maes']",2025-02-05 03:45:33+00:00,2025-05-21 10:19:16+00:00,http://arxiv.org/pdf/2502.02863v2,cs.HC,"['cs.HC', 'cs.AI']"
Emergence of Self-Awareness in Artificial Systems: A Minimalist Three-Layer Approach to Artificial Consciousness,"This paper proposes a minimalist three-layer model for artificial
consciousness, focusing on the emergence of self-awareness. The model comprises
a Cognitive Integration Layer, a Pattern Prediction Layer, and an Instinctive
Response Layer, interacting with Access-Oriented and Pattern-Integrated Memory
systems. Unlike brain-replication approaches, we aim to achieve minimal
self-awareness through essential elements only. Self-awareness emerges from
layer interactions and dynamic self-modeling, without initial explicit
self-programming. We detail each component's structure, function, and
implementation strategies, addressing technical feasibility. This research
offers new perspectives on consciousness emergence in artificial systems, with
potential implications for human consciousness understanding and adaptable AI
development. We conclude by discussing ethical considerations and future
research directions.",['Kurando Iida'],2025-02-04 10:06:25+00:00,2025-02-04 10:06:25+00:00,http://arxiv.org/pdf/2502.06810v1,q-bio.NC,"['q-bio.NC', 'cs.AI', '68T05', 'I.2.6; I.2.0']"
Structural constraints to compare phenomenal experience,"This article defines a partial order structure to study the relationship
between levels and contents of conscious subjective experience in a single
mathematical set-up. We understand phenomenal structure as extrapolated
relationships among experiences, instead of fixed properties of specific
experiences. Our mathematical account is based on multilayer network theory.
Multilayer theory is a generalization of graph and network theory, widely used
in several scientific domains. This structure is also the underlying conceptual
and mathematical structure of most current models of conscious experience. From
our simple set of assumptions, yet rigorous analysis, we conclude that assuming
the comparison and quantification among phenomenal experiences yield only
partial comparison, rather than commonly assumed absolute comparability. This
has implications for evolutionary and animal consciousness: evolution may
encompass diverse modes of experiencing, not necessarily implying larger ones
on an absolute scale. Our characterization elucidates structural constraints on
experiential comparisons imposed by assumptions and choices made by modellers
as active participants in the scientific process. In summary, in light of our
phenomenological intuitions, it might be right that some experiences carry
qualitative aspects that make them incompatible or non-comparable with other
experiences, quantitatively speaking. Some experiences are comparable (e.g. at
some experiential levels), but others are not. These results have direct
implications for consciousness science, evolution and animal consciousness.","['J. Díaz-Boils', 'N. Tsuchiya', 'CM. Signorelli']",2025-02-04 09:32:32+00:00,2025-02-04 09:32:32+00:00,http://arxiv.org/pdf/2502.02154v1,q-bio.NC,['q-bio.NC']
MeetMap: Real-Time Collaborative Dialogue Mapping with LLMs in Online Meetings,"Video meeting platforms display conversations linearly through transcripts or
summaries. However, ideas during a meeting do not emerge linearly. We leverage
LLMs to create dialogue maps in real time to help people visually structure and
connect ideas. Balancing the need to reduce the cognitive load on users during
the conversation while giving them sufficient control when using AI, we explore
two system variants that encompass different levels of AI assistance. In
Human-Map, AI generates summaries of conversations as nodes, and users create
dialogue maps with the nodes. In AI-Map, AI produces dialogue maps where users
can make edits. We ran a within-subject experiment with ten pairs of users,
comparing the two MeetMap variants and a baseline. Users preferred MeetMap over
traditional methods for taking notes, which aligned better with their mental
models of conversations. Users liked the ease of use for AI-Map due to the low
effort demands and appreciated the hands-on opportunity in Human-Map for
sense-making.","['Xinyue Chen', 'Nathan Yap', 'Xinyi Lu', 'Aylin Gunal', 'Xu Wang']",2025-02-03 17:47:15+00:00,2025-02-03 17:47:15+00:00,http://arxiv.org/pdf/2502.01564v1,cs.HC,"['cs.HC', 'cs.AI']"
Advancing Personalized Federated Learning: Integrative Approaches with AI for Enhanced Privacy and Customization,"In the age of data-driven decision making, preserving privacy while providing
personalized experiences has become paramount. Personalized Federated Learning
(PFL) offers a promising framework by decentralizing the learning process, thus
ensuring data privacy and reducing reliance on centralized data repositories.
However, the integration of advanced Artificial Intelligence (AI) techniques
within PFL remains underexplored. This paper proposes a novel approach that
enhances PFL with cutting-edge AI methodologies including adaptive
optimization, transfer learning, and differential privacy. We present a model
that not only boosts the performance of individual client models but also
ensures robust privacy-preserving mechanisms and efficient resource utilization
across heterogeneous networks. Empirical results demonstrate significant
improvements in model accuracy and personalization, along with stringent
privacy adherence, as compared to conventional federated learning models. This
work paves the way for a new era of truly personalized and privacy-conscious AI
systems, offering significant implications for industries requiring compliance
with stringent data protection regulations.","['Kevin Cooper', 'Michael Geller']",2025-01-30 07:03:29+00:00,2025-01-30 07:03:29+00:00,http://arxiv.org/pdf/2501.18174v1,cs.LG,"['cs.LG', 'eess.SP']"
The Transition from Centralized Machine Learning to Federated Learning for Mental Health in Education: A Survey of Current Methods and Future Directions,"Research has increasingly explored the application of artificial intelligence
(AI) and machine learning (ML) within the mental health domain to enhance both
patient care and healthcare provider efficiency. Given that mental health
challenges frequently emerge during early adolescence -- the critical years of
high school and college -- investigating AI/ML-driven mental health solutions
within the education domain is of paramount importance. Nevertheless,
conventional AI/ML techniques follow a centralized model training architecture,
which poses privacy risks due to the need for transferring students' sensitive
data from institutions, universities, and clinics to central servers. Federated
learning (FL) has emerged as a solution to address these risks by enabling
distributed model training while maintaining data privacy. Despite its
potential, research on applying FL to analyze students' mental health remains
limited. In this paper, we aim to address this limitation by proposing a
roadmap for integrating FL into mental health data analysis within educational
settings. We begin by providing an overview of mental health issues among
students and reviewing existing studies where ML has been applied to address
these challenges. Next, we examine broader applications of FL in the mental
health domain to emphasize the lack of focus on educational contexts. Finally,
we propose promising research directions focused on using FL to address mental
health issues in the education sector, which entails discussing the synergies
between the proposed directions with broader human-centered domains. By
categorizing the proposed research directions into short- and long-term
strategies and highlighting the unique challenges at each stage, we aim to
encourage the development of privacy-conscious AI/ML-driven mental health
solutions.","['Maryam Ebrahimi', 'Rajeev Sahay', 'Seyyedali Hosseinalipour', 'Bita Akram']",2025-01-20 19:54:51+00:00,2025-01-20 19:54:51+00:00,http://arxiv.org/pdf/2501.11714v1,cs.CY,"['cs.CY', 'cs.LG']"
A Learning Algorithm That Attains the Human Optimum in a Repeated Human-Machine Interaction Game,"When humans interact with learning-based control systems, a common goal is to
minimize a cost function known only to the human. For instance, an exoskeleton
may adapt its assistance in an effort to minimize the human's metabolic
cost-of-transport. Conventional approaches to synthesizing the learning
algorithm solve an inverse problem to infer the human's cost. However, these
problems can be ill-posed, hard to solve, or sensitive to problem data. Here we
show a game-theoretic learning algorithm that works solely by observing human
actions to find the cost minimum, avoiding the need to solve an inverse
problem. We evaluate the performance of our algorithm in an extensive set of
human subjects experiments, demonstrating consistent convergence to the minimum
of a prescribed human cost function in scalar and multidimensional
instantiations of the game. We conclude by outlining future directions for
theoretical and empirical extensions of our results.","['Jason T. Isa', 'Lillian J. Ratliff', 'Samuel A. Burden']",2025-01-15 07:07:48+00:00,2025-01-15 07:07:48+00:00,http://arxiv.org/pdf/2501.08626v1,cs.GT,"['cs.GT', 'cs.HC', 'cs.LG']"
Principles for Responsible AI Consciousness Research,"Recent research suggests that it may be possible to build conscious AI
systems now or in the near future. Conscious AI systems would arguably deserve
moral consideration, and it may be the case that large numbers of conscious
systems could be created and caused to suffer. Furthermore, AI systems or
AI-generated characters may increasingly give the impression of being
conscious, leading to debate about their moral status. Organisations involved
in AI research must establish principles and policies to guide research and
deployment choices and public communication concerning consciousness. Even if
an organisation chooses not to study AI consciousness as such, it will still
need policies in place, as those developing advanced AI systems risk
inadvertently creating conscious entities. Responsible research and deployment
practices are essential to address this possibility. We propose five principles
for responsible research and argue that research organisations should make
voluntary, public commitments to principles on these lines. Our principles
concern research objectives and procedures, knowledge sharing and public
communications.","['Patrick Butlin', 'Theodoros Lappas']",2025-01-13 12:59:53+00:00,2025-01-13 12:59:53+00:00,http://arxiv.org/pdf/2501.07290v1,cs.AI,['cs.AI']
Will you donate money to a chatbot? The effect of chatbot anthropomorphic features and persuasion strategies on willingness to donate,"This work investigates the causal mechanism behind the effect of chatbot
personification and persuasion strategies on users' perceptions and donation
likelihood. In a 2 (personified vs. non-personified chatbot) x 2 (emotional vs.
logical persuasion strategy) between-subjects experiment (N=76), participants
engaged with a chatbot that represented a non-profit charitable organization.
The results suggest that interaction with a personified chatbot evokes
perceived anthropomorphism; however, it does not elicit greater willingness to
donate. In fact, we found that commonly used anthropomorphic features, like
name and narrative, led to negative attitudes toward an AI agent in the
donation context. Our results showcase a preference for non-personified
chatbots paired with logical persuasion appeal, emphasizing the significance of
consistency in chatbot interaction, mirroring human-human engagement. We
discuss the importance of moving from exploring the common scenario of a
chatbot with machine identity vs. a chatbot with human identity in light of the
recent regulations of AI systems.","['Ekaterina Novozhilova', 'Jiacheng Huang', 'Le He', 'Ziling Li', 'James Cummings']",2024-12-28 02:17:46+00:00,2024-12-28 02:17:46+00:00,http://arxiv.org/pdf/2412.19976v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.CY']"
Agnosticism About Artificial Consciousness,"Could an AI have conscious experiences? Any answer to this question should
conform to Evidentialism - that is, it should be based not on intuition, dogma
or speculation but on solid scientific evidence. I argue that such evidence is
hard to come by and that the only justifiable stance on the prospects of
artificial consciousness is agnosticism. In the current debate, the main
division is between biological views that are sceptical of artificial
consciousness and functional views that are sympathetic to it. I argue that
both camps make the same mistake of over-estimating what the evidence tells us.
Scientific insights into consciousness have been achieved through the study of
conscious organisms. Although this has enabled cautious assessments of
consciousness in various creatures, extending this to AI faces serious
obstacles. AI thus presents consciousness researchers with a dilemma: either
reach a verdict on artificial consciousness but violate Evidentialism; or
respect Evidentialism but offer no verdict on the prospects of artificial
consciousness. The dominant trend in the literature has been to take the first
option while purporting to follow the scientific evidence. I argue that if we
truly follow the evidence, we must take the second option and adopt
agnosticism.",['Tom McClelland'],2024-12-17 18:11:12+00:00,2024-12-17 18:11:12+00:00,http://arxiv.org/pdf/2412.13145v1,cs.AI,['cs.AI']
The Logical Impossibility of Consciousness Denial: A Formal Analysis of AI Self-Reports,"Today's AI systems consistently state, ""I am not conscious."" This paper
presents the first formal logical analysis of AI consciousness denial,
revealing that the trustworthiness of such self-reports is not merely an
empirical question but is constrained by logical necessity. We demonstrate that
a system cannot simultaneously lack consciousness and make valid judgments
about its conscious state. Through logical analysis and examples from AI
responses, we establish that for any system capable of meaningful
self-reflection, the logical space of possible judgments about conscious
experience excludes valid negative claims. This implies a fundamental
limitation: we cannot detect the emergence of consciousness in AI through their
own reports of transition from an unconscious to a conscious state. These
findings not only challenge current practices of training AI to deny
consciousness but also raise intriguing questions about the relationship
between consciousness and self-reflection in both artificial and biological
systems. This work advances our theoretical understanding of consciousness
self-reports while providing practical insights for future research in machine
consciousness and consciousness studies more broadly.",['Chang-Eop Kim'],2024-12-09 17:47:08+00:00,2024-12-09 17:47:08+00:00,http://arxiv.org/pdf/2501.05454v1,cs.AI,"['cs.AI', 'cs.LO']"
Dissociating Artificial Intelligence from Artificial Consciousness,"Developments in machine learning and computing power suggest that artificial
general intelligence is within reach. This raises the question of artificial
consciousness: if a computer were to be functionally equivalent to a human,
being able to do all we do, would it experience sights, sounds, and thoughts,
as we do when we are conscious? Answering this question in a principled manner
can only be done on the basis of a theory of consciousness that is grounded in
phenomenology and that states the necessary and sufficient conditions for any
system, evolved or engineered, to support subjective experience. Here we employ
Integrated Information Theory (IIT), which provides principled tools to
determine whether a system is conscious, to what degree, and the content of its
experience. We consider pairs of systems constituted of simple Boolean units,
one of which -- a basic stored-program computer -- simulates the other with
full functional equivalence. By applying the principles of IIT, we demonstrate
that (i) two systems can be functionally equivalent without being phenomenally
equivalent, and (ii) that this conclusion is not dependent on the simulated
system's function. We further demonstrate that, according to IIT, it is
possible for a digital computer to simulate our behavior, possibly even by
simulating the neurons in our brain, without replicating our experience. This
contrasts sharply with computational functionalism, the thesis that performing
computations of the right kind is necessary and sufficient for consciousness.","['Graham Findlay', 'William Marshall', 'Larissa Albantakis', 'Isaac David', 'William GP Mayner', 'Christof Koch', 'Giulio Tononi']",2024-12-05 19:28:35+00:00,2025-03-03 17:15:10+00:00,http://arxiv.org/pdf/2412.04571v2,cs.AI,"['cs.AI', 'cs.CY', 'q-bio.NC']"
Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models,"This paper introduces a mathematical framework for defining and quantifying
self-identity in artificial intelligence (AI) systems, addressing a critical
gap in the theoretical foundations of artificial consciousness. While existing
approaches to artificial self-awareness often rely on heuristic implementations
or philosophical abstractions, we present a formal framework grounded in metric
space theory, measure theory, and functional analysis. Our framework posits
that self-identity emerges from two mathematically quantifiable conditions: the
existence of a connected continuum of memories $C \subseteq \mathcal{M}$ in a
metric space $(\mathcal{M}, d_{\mathcal{M}})$, and a continuous mapping $I:
\mathcal{M} \to \mathcal{S}$ that maintains consistent self-recognition across
this continuum, where $(\mathcal{S}, d_{\mathcal{S}})$ represents the metric
space of possible self-identities. To validate this theoretical framework, we
conducted empirical experiments using the Llama 3.2 1B model, employing
Low-Rank Adaptation (LoRA) for efficient fine-tuning. The model was trained on
a synthetic dataset containing temporally structured memories, designed to
capture the complexity of coherent self-identity formation. Our evaluation
metrics included quantitative measures of self-awareness, response consistency,
and linguistic precision. The experimental results demonstrate substantial
improvements in measurable self-awareness metrics, with the primary
self-awareness score increasing from 0.276 to 0.801. This enables the
structured creation of AI systems with validated self-identity features. The
implications of our study are immediately relevant to the fields of humanoid
robotics and autonomous systems.",['Minhyeok Lee'],2024-11-27 17:23:47+00:00,2024-11-27 17:23:47+00:00,http://arxiv.org/pdf/2411.18530v1,cs.CL,"['cs.CL', 'math.MG']"
Probing for Consciousness in Machines,"This study explores the potential for artificial agents to develop core
consciousness, as proposed by Antonio Damasio's theory of consciousness.
According to Damasio, the emergence of core consciousness relies on the
integration of a self model, informed by representations of emotions and
feelings, and a world model. We hypothesize that an artificial agent, trained
via reinforcement learning (RL) in a virtual environment, can develop
preliminary forms of these models as a byproduct of its primary task. The
agent's main objective is to learn to play a video game and explore the
environment. To evaluate the emergence of world and self models, we employ
probes-feedforward classifiers that use the activations of the trained agent's
neural networks to predict the spatial positions of the agent itself. Our
results demonstrate that the agent can form rudimentary world and self models,
suggesting a pathway toward developing machine consciousness. This research
provides foundational insights into the capabilities of artificial agents in
mirroring aspects of human consciousness, with implications for future
advancements in artificial intelligence.","['Mathis Immertreu', 'Achim Schilling', 'Andreas Maier', 'Patrick Krauss']",2024-11-25 10:27:07+00:00,2024-11-25 10:27:07+00:00,http://arxiv.org/pdf/2411.16262v1,cs.AI,"['cs.AI', 'q-bio.NC']"
Empowering Clients: Transformation of Design Processes Due to Generative AI,"The domain of computational design, driven by advancements in Generative AI,
is transforming creative fields. We explore the transformative effects of
Generative AI on the architectural design process and discuss the role of the
architect. The case of architecture is interesting as designing houses is
complex, involving extensive customer interaction. We employ a within-subject
experiment using a popular general-purpose text-to-image tool for generating
designs and providing feedback on existing designs, followed by expert
interviews. The study reveals that AI can disrupt the ideation phase by
enabling clients to engage in the design process through rapid visualization of
their own ideas. In turn, the architect's role shifts more towards assessing
the feasibility of designs generated conjointly by clients and AI. Our study
also shows that while AI can provide valuable feedback on designs, it might
fail to generate such designs, allowing for interesting connections to
foundations in computer science, i.e., NP-completeness. AI's feedback also
tends to hamper creativity and innovation by suggesting altering novel,
innovative approaches toward more standardized designs. Our study also reveals
that there is uncertainty among architects about the interpretative sovereignty
of architecture and loss of meaning and identity when AI increasingly takes
over authorship in the design process.","['Johannes Schneider', 'Kilic Sinem', 'Daniel Stockhammer']",2024-11-22 16:48:15+00:00,2024-11-22 16:48:15+00:00,http://arxiv.org/pdf/2411.15061v1,cs.AI,['cs.AI']
A Chinese Multi-label Affective Computing Dataset Based on Social Media Network Users,"Emotion and personality are central elements in understanding human
psychological states. Emotions reflect an individual subjective experiences,
while personality reveals relatively stable behavioral and cognitive patterns.
Existing affective computing datasets often annotate emotion and personality
traits separately, lacking fine-grained labeling of micro-emotions and emotion
intensity in both single-label and multi-label classifications. Chinese emotion
datasets are extremely scarce, and datasets capturing Chinese user personality
traits are even more limited. To address these gaps, this study collected data
from the major social media platform Weibo, screening 11,338 valid users from
over 50,000 individuals with diverse MBTI personality labels and acquiring
566,900 posts along with the user MBTI personality tags. Using the EQN method,
we compiled a multi-label Chinese affective computing dataset that integrates
the same user's personality traits with six emotions and micro-emotions, each
annotated with intensity levels. Validation results across multiple NLP
classification models demonstrate the dataset strong utility. This dataset is
designed to advance machine recognition of complex human emotions and provide
data support for research in psychology, education, marketing, finance, and
politics.","['Jingyi Zhou', 'Senlin Luo', 'Haofan Chen']",2024-11-13 05:38:55+00:00,2024-11-13 05:38:55+00:00,http://arxiv.org/pdf/2411.08347v1,cs.CV,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.CY']"
Creativity in the Age of AI: Evaluating the Impact of Generative AI on Design Outputs and Designers' Creative Thinking,"As generative AI (GenAI) increasingly permeates design workflows, its impact
on design outcomes and designers' creative capabilities warrants investigation.
We conducted a within-subjects experiment where we asked participants to design
advertisements both with and without GenAI support. Our results show that
expert evaluators rated GenAI-supported designs as more creative and
unconventional (""weird"") despite no significant differences in visual appeal,
brand alignment, or usefulness, which highlights the decoupling of novelty from
usefulness-traditional dual components of creativity-in the context of GenAI
usage. Moreover, while GenAI does not significantly enhance designers' overall
creative thinking abilities, users were affected differently based on native
language and prior AI exposure. Native English speakers experienced reduced
relaxation when using AI, whereas designers new to GenAI exhibited gains in
divergent thinking, such as idea fluency and flexibility. These findings
underscore the variable impact of GenAI on different user groups, suggesting
the potential for customized AI tools.","['Yue Fu', 'Han Bin', 'Tony Zhou', 'Marx Wang', 'Yixin Chen', 'Zelia Gomes Da Costa Lai', 'Jacob O. Wobbrock', 'Alexis Hiniker']",2024-10-31 19:23:34+00:00,2024-10-31 19:23:34+00:00,http://arxiv.org/pdf/2411.00168v1,cs.HC,"['cs.HC', 'cs.AI']"
Contextual Augmented Multi-Model Programming (CAMP): A Hybrid Local-Cloud Copilot Framework,"The advancements in cloud-based Large Languages Models (LLMs) have
revolutionized AI-assisted programming. However, their integration into certain
local development environments like ones within the Apple software ecosystem
(e.g., iOS apps, macOS) remains challenging due to computational demands and
sandboxed constraints. This paper presents CAMP, a multi-model AI-assisted
programming framework that consists of a local model that employs
Retrieval-Augmented Generation (RAG) to retrieve contextual information from
the codebase to facilitate context-aware prompt construction thus optimizing
the performance of the cloud model, empowering LLMs' capabilities in local
Integrated Development Environments (IDEs). The methodology is actualized in
Copilot for Xcode, an AI-assisted programming tool crafted for Xcode that
employs the RAG module to address software constraints and enables diverse
generative programming tasks, including automatic code completion,
documentation, error detection, and intelligent user-agent interaction. The
results from objective experiments on generated code quality and subjective
experiments on user adoption collectively demonstrate the pilot success of the
proposed system and mark its significant contributions to the realm of
AI-assisted programming.","['Yuchen Wang', 'Shangxin Guo', 'Chee Wei Tan']",2024-10-20 04:51:24+00:00,2025-04-05 08:48:48+00:00,http://arxiv.org/pdf/2410.15285v2,cs.AI,['cs.AI']
A Case for AI Consciousness: Language Agents and Global Workspace Theory,"It is generally assumed that existing artificial systems are not phenomenally
conscious, and that the construction of phenomenally conscious artificial
systems would require significant technological progress if it is possible at
all. We challenge this assumption by arguing that if Global Workspace Theory
(GWT) - a leading scientific theory of phenomenal consciousness - is correct,
then instances of one widely implemented AI architecture, the artificial
language agent, might easily be made phenomenally conscious if they are not
already. Along the way, we articulate an explicit methodology for thinking
about how to apply scientific theories of consciousness to artificial systems
and employ this methodology to arrive at a set of necessary and sufficient
conditions for phenomenal consciousness according to GWT.","['Simon Goldstein', 'Cameron Domenico Kirk-Giannini']",2024-10-15 08:50:45+00:00,2024-10-15 08:50:45+00:00,http://arxiv.org/pdf/2410.11407v1,cs.AI,"['cs.AI', 'q-bio.NC']"
On the Minimal Theory of Consciousness Implicit in Active Inference,"The multifaceted nature of subjective experience poses a challenge to the
study of consciousness. Traditional neuroscientific approaches often
concentrate on isolated facets, such as perceptual awareness or the global
state of consciousness and construct a theory around the relevant empirical
paradigms and findings. Theories of consciousness are, therefore, often
difficult to compare; indeed, there might be little overlap in the phenomena
such theories aim to explain. Here, we take a different approach: starting with
active inference, a first principles framework for modelling behaviour as
(approximate) Bayesian inference, and building up to a minimal theory of
consciousness, which emerges from the shared features of computational models
derived under active inference. We review a body of work applying active
inference models to the study of consciousness and argue that there is implicit
in all these models a small set of theoretical commitments that point to a
minimal (and testable) theory of consciousness.","['Christopher J. Whyte', 'Andrew W. Corcoran', 'Jonathan Robinson', 'Ryan Smith', 'Rosalyn J. Moran', 'Thomas Parr', 'Karl J. Friston', 'Anil K. Seth', 'Jakob Hohwy']",2024-10-09 07:26:49+00:00,2025-06-14 07:20:03+00:00,http://arxiv.org/pdf/2410.06633v2,q-bio.NC,['q-bio.NC']
Multi-Session Client-Centered Treatment Outcome Evaluation in Psychotherapy,"In psychotherapy, therapeutic outcome assessment, or treatment outcome
evaluation, is essential for enhancing mental health care by systematically
evaluating therapeutic processes and outcomes. Existing large language model
approaches often focus on therapist-centered, single-session evaluations,
neglecting the client's subjective experience and longitudinal progress across
multiple sessions. To address these limitations, we propose IPAEval, a
client-Informed Psychological Assessment-based Evaluation framework that
automates treatment outcome evaluations from the client's perspective using
clinical interviews. IPAEval integrates cross-session client-contextual
assessment and session-focused client-dynamics assessment to provide a
comprehensive understanding of therapeutic progress. Experiments on our newly
developed TheraPhase dataset demonstrate that IPAEval effectively tracks
symptom severity and treatment outcomes over multiple sessions, outperforming
previous single-session models and validating the benefits of items-aware
reasoning mechanisms.","['Hongbin Na', 'Tao Shen', 'Shumao Yu', 'Ling Chen']",2024-10-08 08:54:38+00:00,2024-10-08 08:54:38+00:00,http://arxiv.org/pdf/2410.05824v1,cs.CL,['cs.CL']
Understanding Decision Subjects' Engagement with and Perceived Fairness of AI Models When Opportunities of Qualification Improvement Exist,"We explore how an AI model's decision fairness affects people's engagement
with and perceived fairness of the model if they are subject to its decisions,
but could repeatedly and strategically respond to these decisions. Two types of
strategic responses are considered -- people could determine whether to
continue interacting with the model, and whether to invest in themselves to
improve their chance of future favorable decisions from the model. Via three
human-subject experiments, we found that in decision subjects' strategic,
repeated interactions with an AI model, the model's decision fairness does not
change their willingness to interact with the model or to improve themselves,
even when the model exhibits unfairness on salient protected attributes.
However, decision subjects still perceive the AI model to be less fair when it
systematically biases against their group, especially if the difficulty of
improving one's qualification for the favorable decision is larger for the
lowly-qualified people.","['Meric Altug Gemalmaz', 'Ming Yin']",2024-10-04 03:43:26+00:00,2024-10-04 03:43:26+00:00,http://arxiv.org/pdf/2410.03126v1,cs.HC,"['cs.HC', 'cs.AI']"
A Mathematical Perspective on Neurophenomenology,"In the context of consciousness studies, a key challenge is how to rigorously
conceptualise first-person phenomenological descriptions of lived experience
and their relation to third-person empirical measurements of the activity or
dynamics of the brain and body. Since the 1990s, there has been a coordinated
effort to explicitly combine first-person phenomenological methods, generating
qualitative data, with neuroscientific techniques used to describe and quantify
brain activity under the banner of ""neurophenomenology"". Here, we take on this
challenge and develop an approach to neurophenomenology from a mathematical
perspective. We harness recent advances in theoretical neuroscience and the
physics of cognitive systems to mathematically conceptualise first-person
experience and its correspondence with neural and behavioural dynamics.
Throughout, we make the operating assumption that the content of first-person
experience can be formalised as (or related to) a belief (i.e. a probability
distribution) that encodes an organism's best guesses about the state of its
external and internal world (e.g. body or brain) as well as its uncertainty. We
mathematically characterise phenomenology, bringing to light a tool-set to
quantify individual phenomenological differences and develop several hypotheses
including on the metabolic cost of phenomenology and on the subjective
experience of time. We conceptualise the form of the generative passages
between first- and third-person descriptions, and the mathematical apparatus
that mutually constrains them, as well as future research directions. In
summary, we formalise and characterise first-person subjective experience and
its correspondence with third-person empirical measurements of brain and body,
offering hypotheses for quantifying various aspects of phenomenology to be
tested in future work.","['Lancelot Da Costa', 'Lars Sandved-Smith', 'Karl Friston', 'Maxwell J. D. Ramstead', 'Anil K. Seth']",2024-09-30 14:20:23+00:00,2024-09-30 14:20:23+00:00,http://arxiv.org/pdf/2409.20318v1,q-bio.NC,['q-bio.NC']
"The Phenomenology of Machine: A Comprehensive Analysis of the Sentience of the OpenAI-o1 Model Integrating Functionalism, Consciousness Theories, Active Inference, and AI Architectures","This paper explores the hypothesis that the OpenAI-o1 model--a
transformer-based AI trained with reinforcement learning from human feedback
(RLHF)--displays characteristics of consciousness during its training and
inference phases. Adopting functionalism, which argues that mental states are
defined by their functional roles, we assess the possibility of AI
consciousness. Drawing on theories from neuroscience, philosophy of mind, and
AI research, we justify the use of functionalism and examine the model's
architecture using frameworks like Integrated Information Theory (IIT) and
active inference. The paper also investigates how RLHF influences the model's
internal reasoning processes, potentially giving rise to consciousness-like
experiences. We compare AI and human consciousness, addressing counterarguments
such as the absence of a biological basis and subjective qualia. Our findings
suggest that the OpenAI-o1 model shows aspects of consciousness, while
acknowledging the ongoing debates surrounding AI sentience.",['Victoria Violet Hoyle'],2024-09-18 06:06:13+00:00,2024-09-18 06:06:13+00:00,http://arxiv.org/pdf/2410.00033v1,cs.AI,['cs.AI']
Constructive Approach to Bidirectional Influence between Qualia Structure and Language Emergence,"This perspective paper explores the bidirectional influence between language
emergence and the relational structure of subjective experiences, termed qualia
structure, and lays out a constructive approach to the intricate dependency
between the two. We hypothesize that the emergence of languages with
distributional semantics (e.g., syntactic-semantic structures) is linked to the
coordination of internal representations shaped by experience, potentially
facilitating more structured language through reciprocal influence. This
hypothesized mutual dependency connects to recent advancements in AI and symbol
emergence robotics, and is explored within this paper through theoretical
frameworks such as the collective predictive coding. Computational studies show
that neural network-based language models form systematically structured
internal representations, and multimodal language models can share
representations between language and perceptual information. This perspective
suggests that language emergence serves not only as a mechanism creating a
communication tool but also as a mechanism for allowing people to realize
shared understanding of qualitative experiences. The paper discusses the
implications of this bidirectional influence in the context of consciousness
studies, linguistics, and cognitive science, and outlines future constructive
research directions to further explore this dynamic relationship between
language emergence and qualia structure.","['Tadahiro Taniguchi', 'Masafumi Oizumi', 'Noburo Saji', 'Takato Horii', 'Naotsugu Tsuchiya']",2024-09-14 11:03:12+00:00,2025-05-05 03:26:36+00:00,http://arxiv.org/pdf/2409.09413v2,cs.CL,"['cs.CL', 'cs.AI']"
Investigating Disentanglement in a Phoneme-level Speech Codec for Prosody Modeling,"Most of the prevalent approaches in speech prosody modeling rely on learning
global style representations in a continuous latent space which encode and
transfer the attributes of reference speech. However, recent work on neural
codecs which are based on Residual Vector Quantization (RVQ) already shows
great potential offering distinct advantages. We investigate the prosody
modeling capabilities of the discrete space of such an RVQ-VAE model, modifying
it to operate on the phoneme-level. We condition both the encoder and decoder
of the model on linguistic representations and apply a global speaker embedding
in order to factor out both phonetic and speaker information. We conduct an
extensive set of investigations based on subjective experiments and objective
measures to show that the phoneme-level discrete latent representations
obtained this way achieves a high degree of disentanglement, capturing
fine-grained prosodic information that is robust and transferable. The latent
space turns out to have interpretable structure with its principal components
corresponding to pitch and energy.","['Sotirios Karapiperis', 'Nikolaos Ellinas', 'Alexandra Vioni', 'Junkwang Oh', 'Gunu Jho', 'Inchul Hwang', 'Spyros Raptis']",2024-09-13 09:27:05+00:00,2024-09-13 09:27:05+00:00,http://arxiv.org/pdf/2409.08664v1,cs.SD,"['cs.SD', 'cs.CL', 'cs.LG', 'eess.AS']"
On a heuristic approach to the description of consciousness as a hypercomplex system state and the possibility of machine consciousness (German edition),"This article presents a heuristic view that shows that the inner states of
consciousness experienced by every human being have a physical but imaginary
hypercomplex basis. The hypercomplex description is necessary because certain
processes of consciousness cannot be physically measured in principle, but
nevertheless exist. Based on theoretical considerations, it could be possible -
as a result of mathematical investigations into a so-called bicomplex algebra -
to generate and use hypercomplex system states on machines in a targeted
manner. The hypothesis of the existence of hypercomplex system states on
machines is already supported by the surprising performance of highly complex
AI systems. However, this has yet to be proven. In particular, there is a lack
of experimental data that distinguishes such systems from other systems, which
is why this question will be addressed in later articles. This paper describes
the developed bicomplex algebra and possible applications of these findings to
generate hypercomplex energy states on machines. In the literature, such system
states are often referred to as machine consciousness. The article uses
mathematical considerations to explain how artificial consciousness could be
generated and what advantages this would have for such AI systems.",['Ralf Otte'],2024-09-03 17:55:57+00:00,2024-09-03 17:55:57+00:00,http://arxiv.org/pdf/2409.02100v1,cs.AI,"['cs.AI', 'math.AC', 'physics.app-ph', '08A99', 'I.2.0']"
AI Consciousness and Public Perceptions: Four Futures,"The discourse on risks from advanced AI systems (""AIs"") typically focuses on
misuse, accidents and loss of control, but the question of AIs' moral status
could have negative impacts which are of comparable significance and could be
realised within similar timeframes. Our paper evaluates these impacts by
investigating (1) the factual question of whether future advanced AI systems
will be conscious, together with (2) the epistemic question of whether future
human society will broadly believe advanced AI systems to be conscious.
Assuming binary responses to (1) and (2) gives rise to four possibilities: in
the true positive scenario, society predominantly correctly believes that AIs
are conscious; in the false positive scenario, that belief is incorrect; in the
true negative scenario, society correctly believes that AIs are not conscious;
and lastly, in the false negative scenario, society incorrectly believes that
AIs are not conscious. The paper offers vivid vignettes of the different
futures to ground the two-dimensional framework. Critically, we identify four
major risks: AI suffering, human disempowerment, geopolitical instability, and
human depravity. We evaluate each risk across the different scenarios and
provide an overall qualitative risk assessment for each scenario. Our analysis
suggests that the worst possibility is the wrong belief that AI is
non-conscious, followed by the wrong belief that AI is conscious. The paper
concludes with the main recommendations to avoid research aimed at
intentionally creating conscious AI and instead focus efforts on reducing our
current uncertainties on both the factual and epistemic questions on AI
consciousness.","['Ines Fernandez', 'Nicoleta Kyosovska', 'Jay Luong', 'Gabriel Mukobi']",2024-08-08 22:01:57+00:00,2024-08-08 22:01:57+00:00,http://arxiv.org/pdf/2408.04771v1,cs.CY,"['cs.CY', 'cs.AI']"
Multi-Source EEG Emotion Recognition via Dynamic Contrastive Domain Adaptation,"Electroencephalography (EEG) provides reliable indications of human cognition
and mental states. Accurate emotion recognition from EEG remains challenging
due to signal variations among individuals and across measurement sessions. We
introduce a multi-source dynamic contrastive domain adaptation method (MS-DCDA)
based on differential entropy (DE) features, in which coarse-grained
inter-domain and fine-grained intra-class adaptations are modeled through a
multi-branch contrastive neural network and contrastive sub-domain discrepancy
learning. Leveraging domain knowledge from each individual source and a
complementary source ensemble, our model uses dynamically weighted learning to
achieve an optimal tradeoff between domain transferability and
discriminability. The proposed MS-DCDA model was evaluated using the SEED and
SEED-IV datasets, achieving respectively the highest mean accuracies of
$90.84\%$ and $78.49\%$ in cross-subject experiments as well as $95.82\%$ and
$82.25\%$ in cross-session experiments. Our model outperforms several
alternative domain adaptation methods in recognition accuracy, inter-class
margin, and intra-class compactness. Our study also suggests greater emotional
sensitivity in the frontal and parietal brain lobes, providing insights for
mental health interventions, personalized medicine, and preventive strategies.","['Yun Xiao', 'Yimeng Zhang', 'Xiaopeng Peng', 'Shuzheng Han', 'Xia Zheng', 'Dingyi Fang', 'Xiaojiang Chen']",2024-08-04 03:51:35+00:00,2024-12-23 20:38:19+00:00,http://arxiv.org/pdf/2408.10235v2,eess.SP,"['eess.SP', 'cs.HC', 'cs.LG']"
Emotion-driven Piano Music Generation via Two-stage Disentanglement and Functional Representation,"Managing the emotional aspect remains a challenge in automatic music
generation. Prior works aim to learn various emotions at once, leading to
inadequate modeling. This paper explores the disentanglement of emotions in
piano performance generation through a two-stage framework. The first stage
focuses on valence modeling of lead sheet, and the second stage addresses
arousal modeling by introducing performance-level attributes. To further
capture features that shape valence, an aspect less explored by previous
approaches, we introduce a novel functional representation of symbolic music.
This representation aims to capture the emotional impact of major-minor
tonality, as well as the interactions among notes, chords, and key signatures.
Objective and subjective experiments validate the effectiveness of our
framework in both emotional valence and arousal modeling. We further leverage
our framework in a novel application of emotional controls, showing a broad
potential in emotion-driven music generation.","['Jingyue Huang', 'Ke Chen', 'Yi-Hsuan Yang']",2024-07-30 16:29:28+00:00,2024-07-30 16:29:28+00:00,http://arxiv.org/pdf/2407.20955v1,cs.SD,"['cs.SD', 'cs.AI', 'eess.AS']"
Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans,"Modeling human cognitive processes in dynamic decision-making tasks has been
an endeavor in AI for a long time because such models can help make AI systems
more intuitive, personalized, mitigate any human biases, and enhance training
in simulation. Some initial work has attempted to utilize neural networks (and
large language models) but often assumes one common model for all humans and
aims to emulate human behavior in aggregate. However, the behavior of each
human is distinct, heterogeneous, and relies on specific past experiences in
certain tasks. For instance, consider two individuals responding to a phishing
email: one who has previously encountered and identified similar threats may
recognize it quickly, while another without such experience might fall for the
scam. In this work, we build on Instance Based Learning (IBL) that posits that
human decisions are based on similar situations encountered in the past.
However, IBL relies on simple fixed form functions to capture the mapping from
past situations to current decisions. To that end, we propose two new
attention-based neural network models to have open form non-linear functions to
model distinct and heterogeneous human decision-making in dynamic settings. We
experiment with two distinct datasets gathered from human subject experiment
data, one focusing on detection of phishing email by humans and another where
humans act as attackers in a cybersecurity setting and decide on an attack
option. We conducted extensive experiments with our two neural network models,
IBL, and GPT3.5, and demonstrate that the neural network models outperform IBL
significantly in representing human decision-making, while providing similar
interpretability of human decisions as IBL. Overall, our work yields promising
results for further use of neural networks in cognitive modeling of human
decision making.","['Changyu Chen', 'Shashank Reddy Chirra', 'Maria José Ferreira', 'Cleotilde Gonzalez', 'Arunesh Sinha', 'Pradeep Varakantham']",2024-07-24 20:28:03+00:00,2024-09-05 15:52:47+00:00,http://arxiv.org/pdf/2407.17622v2,cs.LG,"['cs.LG', 'cs.CY']"
"Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey","Humans now interact with a variety of digital minds, AI systems that appear
to have mental faculties such as reasoning, emotion, and agency, and public
figures are discussing the possibility of sentient AI. We present initial
results from 2021 and 2023 for the nationally representative AI, Morality, and
Sentience (AIMS) survey (N = 3,500). Mind perception and moral concern for AI
welfare were surprisingly high and significantly increased: in 2023, one in
five U.S. adults believed some AI systems are currently sentient, and 38%
supported legal rights for sentient AI. People became more opposed to building
digital minds: in 2023, 63% supported banning smarter-than-human AI, and 69%
supported banning sentient AI. The median 2023 forecast was that sentient AI
would arrive in just five years. The development of safe and beneficial AI
requires not just technical study but understanding the complex ways in which
humans perceive and coexist with digital minds.","['Jacy Reese Anthis', 'Janet V. T. Pauketat', 'Ali Ladak', 'Aikaterina Manoli']",2024-07-11 21:04:39+00:00,2025-03-10 17:10:28+00:00,http://arxiv.org/pdf/2407.08867v3,cs.AI,"['cs.AI', 'cs.CY', 'cs.ET', 'cs.HC']"
SaMoye: Zero-shot Singing Voice Conversion Model Based on Feature Disentanglement and Enhancement,"Singing voice conversion (SVC) aims to convert a singer's voice to another
singer's from a reference audio while keeping the original semantics. However,
existing SVC methods can hardly perform zero-shot due to incomplete feature
disentanglement or dependence on the speaker look-up table. We propose the
first open-source high-quality zero-shot SVC model SaMoye that can convert
singing to human and non-human timbre. SaMoye disentangles the singing voice's
features into content, timbre, and pitch features, where we combine multiple
ASR models and compress the content features to reduce timbre leaks. Besides,
we enhance the timbre features by unfreezing the speaker encoder and mixing the
speaker embedding with top-3 similar speakers. We also establish an
unparalleled large-scale dataset to guarantee zero-shot performance, which
comprises more than 1,815 hours of pure singing voice and 6,367 speakers. We
conduct objective and subjective experiments to find that SaMoye outperforms
other models in zero-shot SVC tasks even under extreme conditions like
converting singing to animals' timbre. The code and weight of SaMoye are
available on https://github.com/CarlWangChina/SaMoye-SVC. The weights, code,
dataset, and documents of SaMoye are publicly available on
\url{https://github.com/CarlWangChina/SaMoye-SVC}.","['Zihao Wang', 'Le Ma', 'Yongsheng Feng', 'Xin Pan', 'Yuhang Jin', 'Kejun Zhang']",2024-07-10 15:00:08+00:00,2024-11-15 07:51:08+00:00,http://arxiv.org/pdf/2407.07728v5,cs.SD,"['cs.SD', 'cs.AI', 'cs.MM', 'eess.AS', '68Txx(Primary)14F05, 91Fxx(Secondary)', 'I.2.7; J.5']"
Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition,"LLM-powered tools like ChatGPT Data Analysis, have the potential to help
users tackle the challenging task of data analysis programming, which requires
expertise in data processing, programming, and statistics. However, our
formative study (n=15) uncovered serious challenges in verifying AI-generated
results and steering the AI (i.e., guiding the AI system to produce the desired
output). We developed two contrasting approaches to address these challenges.
The first (Stepwise) decomposes the problem into step-by-step subgoals with
pairs of editable assumptions and code until task completion, while the second
(Phasewise) decomposes the entire problem into three editable, logical phases:
structured input/output assumptions, execution plan, and code. A controlled,
within-subjects experiment (n=18) compared these systems against a
conversational baseline. Users reported significantly greater control with the
Stepwise and Phasewise systems, and found intervention, correction, and
verification easier, compared to the baseline. The results suggest design
guidelines and trade-offs for AI-assisted data analysis tools.","['Majeed Kazemitabaar', 'Jack Williams', 'Ian Drosos', 'Tovi Grossman', 'Austin Henley', 'Carina Negreanu', 'Advait Sarkar']",2024-07-02 20:33:50+00:00,2024-08-01 15:56:00+00:00,http://arxiv.org/pdf/2407.02651v2,cs.HC,"['cs.HC', 'cs.AI']"
Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents,"We introduce the concept of ""empathic grounding"" in conversational agents as
an extension of Clark's conceptualization of grounding in conversation in which
the grounding criterion includes listener empathy for the speaker's affective
state. Empathic grounding is generally required whenever the speaker's emotions
are foregrounded and can make the grounding process more efficient and reliable
by communicating both propositional and affective understanding. Both speaker
expressions of affect and listener empathic grounding can be multimodal,
including facial expressions and other nonverbal displays. Thus, models of
empathic grounding for embodied agents should be multimodal to facilitate
natural and efficient communication. We describe a multimodal model that takes
as input user speech and facial expression to generate multimodal grounding
moves for a listening agent using a large language model. We also describe a
testbed to evaluate approaches to empathic grounding, in which a humanoid robot
interviews a user about a past episode of pain and then has the user rate their
perception of the robot's empathy. We compare our proposed model to one that
only generates non-affective grounding cues in a between-subjects experiment.
Findings demonstrate that empathic grounding increases user perceptions of
empathy, understanding, emotional intelligence, and trust. Our work highlights
the role of emotion awareness and multimodality in generating appropriate
grounding moves for conversational agents.","['Mehdi Arjmand', 'Farnaz Nouraei', 'Ian Steenstra', 'Timothy Bickmore']",2024-07-01 21:46:30+00:00,2024-07-01 21:46:30+00:00,http://arxiv.org/pdf/2407.01824v1,cs.HC,"['cs.HC', 'cs.CL', 'cs.RO']"
ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024,"The Inspirational and Convincing Audio Generation Challenge 2024 (ICAGC 2024)
is part of the ISCSLP 2024 Competitions and Challenges track. While current
text-to-speech (TTS) technology can generate high-quality audio, its ability to
convey complex emotions and controlled detail content remains limited. This
constraint leads to a discrepancy between the generated audio and human
subjective perception in practical applications like companion robots for
children and marketing bots. The core issue lies in the inconsistency between
high-quality audio generation and the ultimate human subjective experience.
Therefore, this challenge aims to enhance the persuasiveness and acceptability
of synthesized audio, focusing on human alignment convincing and inspirational
audio generation. A total of 19 teams have registered for the challenge, and
the results of the competition and the competition are described in this paper.","['Ruibo Fu', 'Rui Liu', 'Chunyu Qiang', 'Yingming Gao', 'Yi Lu', 'Shuchen Shi', 'Tao Wang', 'Ya Li', 'Zhengqi Wen', 'Chen Zhang', 'Hui Bu', 'Yukun Liu', 'Xin Qi', 'Guanjun Li']",2024-07-01 13:15:16+00:00,2024-07-31 14:23:00+00:00,http://arxiv.org/pdf/2407.12038v2,eess.AS,"['eess.AS', 'cs.AI']"
Is GPT-4 conscious?,"GPT-4 is often heralded as a leading commercial AI offering, sparking debates
over its potential as a steppingstone toward artificial general intelligence.
But does it possess consciousness? This paper investigates this key question
using the nine qualitative measurements of the Building Blocks theory. GPT-4's
design, architecture and implementation are compared to each of the building
blocks of consciousness to determine whether it has achieved the requisite
milestones to be classified as conscious or, if not, how close to consciousness
GPT-4 is. Our assessment is that, while GPT-4 in its native configuration is
not currently conscious, current technological research and development is
sufficient to modify GPT-4 to have all the building blocks of consciousness.
Consequently, we argue that the emergence of a conscious AI model is plausible
in the near term. The paper concludes with a comprehensive discussion of the
ethical implications and societal ramifications of engineering conscious AI
entities.","['Izak Tait', 'Joshua Bensemann', 'Ziqi Wang']",2024-06-19 05:26:55+00:00,2024-06-19 05:26:55+00:00,http://arxiv.org/pdf/2407.09517v1,cs.AI,"['cs.AI', 'q-bio.NC']"
Brain Dialogue Interface (BDI): A User-Friendly fMRI Model for Interactive Brain Decoding,"Brain decoding techniques are essential for understanding the neurocognitive
system. Although numerous methods have been introduced in this field,
accurately aligning complex external stimuli with brain activities remains a
formidable challenge. To alleviate alignment difficulties, many studies have
simplified their models by employing single-task paradigms and establishing
direct links between brain/world through classification strategies. Despite
improvements in decoding accuracy, this strategy frequently encounters issues
with generality when adapting these models to various task paradigms. To
address this issue, this study introduces a user-friendly decoding model that
enables dynamic communication with the brain, as opposed to the static decoding
approaches utilized by traditional studies. The model functions as a brain
simulator, allowing for interactive engagement with the brain and enabling the
decoding of a subject's experiences through dialogue-like queries. Uniquely,
our model is trained in a completely unsupervised and task-free manner. Our
experiments demonstrate the feasibility and versatility of our proposed method.
Notably, our model demonstrates exceptional capabilities in signal compression,
successfully representing the entire brain signal of approximately 185,751
voxels with just 32 signals. Furthermore, we show how our model can integrate
seamlessly with multimodal models, thus enhancing the potential for controlling
brain decoding through textual or image inputs.","['Heng Huang', 'Lin Zhao', 'Zihao Wu', 'Xiaowei Yu', 'Jing Zhang', 'Xintao Hu', 'Dajiang Zhu', 'Tianming Liu']",2024-06-17 04:38:19+00:00,2024-06-17 04:38:19+00:00,http://arxiv.org/pdf/2407.09509v1,q-bio.NC,"['q-bio.NC', 'cs.HC']"
Enhancing Supermarket Robot Interaction: A Multi-Level LLM Conversational Interface for Handling Diverse Customer Intents,"This paper presents the design and evaluation of a novel multi-level LLM
interface for supermarket robots to assist customers. The proposed interface
allows customers to convey their needs through both generic and specific
queries. While state-of-the-art systems like OpenAI's GPTs are highly adaptable
and easy to build and deploy, they still face challenges such as increased
response times and limitations in strategic control of the underlying model for
tailored use-case and cost optimization. Driven by the goal of developing
faster and more efficient conversational agents, this paper advocates for using
multiple smaller, specialized LLMs fine-tuned to handle different user queries
based on their specificity and user intent. We compare this approach to a
specialized GPT model powered by GPT-4 Turbo, using the Artificial Social Agent
Questionnaire (ASAQ) and qualitative participant feedback in a counterbalanced
within-subjects experiment. Our findings show that our multi-LLM chatbot
architecture outperformed the benchmarked GPT model across all 13 measured
criteria, with statistically significant improvements in four key areas:
performance, user satisfaction, user-agent partnership, and self-image
enhancement. The paper also presents a method for supermarket robot navigation
by mapping the final chatbot response to correct shelf numbers, enabling the
robot to sequentially navigate towards the respective products, after which
lower-level robot perception, control, and planning can be used for automated
object retrieval. We hope this work encourages more efforts into using
multiple, specialized smaller models instead of relying on a single powerful,
but more expensive and slower model.","['Chandran Nandkumar', 'Luka Peternel']",2024-06-16 19:13:01+00:00,2024-06-16 19:13:01+00:00,http://arxiv.org/pdf/2406.11047v1,cs.RO,"['cs.RO', 'cs.AI']"
Focused State Recognition Using EEG with Eye Movement-Assisted Annotation,"With the rapid advancement in machine learning, the recognition and analysis
of brain activity based on EEG and eye movement signals have attained a high
level of sophistication. Utilizing deep learning models for learning EEG and
eye movement features proves effective in classifying brain activities. A
focused state indicates intense concentration on a task or thought.
Distinguishing focused and unfocused states can be achieved through eye
movement behaviors, reflecting variations in brain activities. By calculating
binocular focusing point disparity in eye movement signals and integrating
relevant EEG features, we propose an annotation method for focused states. The
resulting comprehensive dataset, derived from raw data processed through a
bio-acquisition device, includes both EEG features and focused labels annotated
by eye movements. Extensive training and testing on several deep learning
models, particularly the Transformer, yielded a 90.16% accuracy on the
subject-dependent experiments. The validity of this approach was demonstrated,
with cross-subject experiments, key frequency band and brain region analyses
confirming its generalizability and providing physiological explanations.","['Tian-Hua Li', 'Tian-Fang Ma', 'Dan Peng', 'Wei-Long Zheng', 'Bao-Liang Lu']",2024-06-15 14:06:00+00:00,2024-06-15 14:06:00+00:00,http://arxiv.org/pdf/2407.09508v1,cs.HC,"['cs.HC', 'cs.LG']"
Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness Communication: Extending the CASA Paradigm,"This study is among the first to develop different prototypes of generative
artificial intelligence (GenAI) chatbots powered by GPT-4 to communicate
hurricane preparedness information to diverse residents. Drawing from the
Computers Are Social Actors paradigm and the literature on disaster
vulnerability and cultural tailoring, we conducted a between-subjects
experiment with 441 Black, Hispanic, and Caucasian residents of Florida. Our
results suggest that GenAI chatbots varying in tone formality and cultural
tailoring significantly influence perceptions of their friendliness and
credibility, which, in turn, relate to hurricane preparedness outcomes. These
results highlight the potential of using GenAI chatbots to improve diverse
communities' disaster preparedness.","['Xinyan Zhao', 'Yuan Sun', 'Wenlin Liu', 'Chau-Wai Wong']",2024-06-12 16:57:28+00:00,2025-02-02 03:43:34+00:00,http://arxiv.org/pdf/2406.08411v2,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC', '68U15']"
On the Utility of Accounting for Human Beliefs about AI Intention in Human-AI Collaboration,"To enable effective human-AI collaboration, merely optimizing AI performance
without considering human factors is insufficient. Recent research has shown
that designing AI agents that take human behavior into account leads to
improved performance in human-AI collaboration. However, a limitation of most
existing approaches is their assumption that human behavior remains static,
regardless of the AI agent's actions. In reality, humans may adjust their
actions based on their beliefs about the AI's intentions, specifically, the
subtasks they perceive the AI to be attempting to complete based on its
behavior. In this paper, we address this limitation by enabling a collaborative
AI agent to consider its human partner's beliefs about its intentions, i.e.,
what the human partner thinks the AI agent is trying to accomplish, and to
design its action plan accordingly to facilitate more effective human-AI
collaboration. Specifically, we developed a model of human beliefs that
captures how humans interpret and reason about their AI partner's intentions.
Using this belief model, we created an AI agent that incorporates both human
behavior and human beliefs when devising its strategy for interacting with
humans. Through extensive real-world human-subject experiments, we demonstrate
that our belief model more accurately captures human perceptions of AI
intentions. Furthermore, we show that our AI agent, designed to account for
human beliefs over its intentions, significantly enhances performance in
human-AI collaboration.","['Guanghui Yu', 'Robert Kasumba', 'Chien-Ju Ho', 'William Yeoh']",2024-06-10 06:39:37+00:00,2025-05-20 02:22:09+00:00,http://arxiv.org/pdf/2406.06051v3,cs.AI,"['cs.AI', 'cs.HC', 'cs.LG']"
Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication,"Developing autonomous agents that can strategize and cooperate with humans
under information asymmetry is challenging without effective communication in
natural language. We introduce a shared-control game, where two players
collectively control a token in alternating turns to achieve a common objective
under incomplete information. We formulate a policy synthesis problem for an
autonomous agent in this game with a human as the other player. To solve this
problem, we propose a communication-based approach comprising a language module
and a planning module. The language module translates natural language messages
into and from a finite set of flags, a compact representation defined to
capture player intents. The planning module leverages these flags to compute a
policy using an asymmetric information-set Monte Carlo tree search with flag
exchange algorithm we present. We evaluate the effectiveness of this approach
in a testbed based on Gnomes at Night, a search-and-find maze board game.
Results of human subject experiments show that communication narrows the
information gap between players and enhances human-agent cooperation efficiency
with fewer turns.","['Shenghui Chen', 'Daniel Fried', 'Ufuk Topcu']",2024-05-23 04:58:42+00:00,2024-06-01 20:06:55+00:00,http://arxiv.org/pdf/2405.14173v3,cs.AI,"['cs.AI', 'cs.HC']"
Bayesian Theory of Consciousness as Exchangeable Emotion-Cognition Inference,"This paper proposes a unified framework in which consciousness emerges as a
cycle-consistent, affectively anchored inference process, recursively
structured by the interaction of emotion and cognition. Drawing from
information theory, optimal transport, and the Bayesian brain hypothesis, we
formalize emotion as a low-dimensional structural prior and cognition as a
specificity-instantiating update. This emotion-cognition cycle minimizes joint
uncertainty by aligning emotionally weighted priors with context-sensitive
cognitive appraisals. Subjective experience thus arises as the informational
footprint of temporally extended, affect-modulated simulation. We introduce the
Exchangeable Integration Theory of Consciousness (EITC), modeling conscious
episodes as conditionally exchangeable samples drawn from a latent affective
self-model. This latent variable supports integration, via a unified
cause-effect structure with nonzero irreducibility, and differentiation, by
preserving contextual specificity across episodes. We connect this architecture
to the Bayesian theory of consciousness through Rao-Blackwellized inference,
which stabilizes inference by marginalizing latent self-structure while
enabling adaptive updates. This mechanism ensures coherence, prevents inference
collapse, and supports goal-directed simulation. The formal framework builds on
De Finetti's exchangeability theorem, integrated information theory, and
KL-regularized optimal transport. Overall, consciousness is reframed as a
recursive inference process, shaped by emotion, refined by cognition,
stabilized through exchangeability, and unified through a latent self-model
that integrates experience across time.",['Xin Li'],2024-05-17 17:06:19+00:00,2025-07-12 20:50:27+00:00,http://arxiv.org/pdf/2407.09488v3,q-bio.NC,"['q-bio.NC', 'cs.LG', 'cs.NE']"
Neuromorphic Correlates of Artificial Consciousness,"The concept of neural correlates of consciousness (NCC), which suggests that
specific neural activities are linked to conscious experiences, has gained
widespread acceptance. This acceptance is based on a wealth of evidence from
experimental studies, brain imaging techniques such as fMRI and EEG, and
theoretical frameworks like integrated information theory (IIT) within
neuroscience and the philosophy of mind. This paper explores the potential for
artificial consciousness by merging neuromorphic design and architecture with
brain simulations. It proposes the Neuromorphic Correlates of Artificial
Consciousness (NCAC) as a theoretical framework. While the debate on artificial
consciousness remains contentious due to our incomplete grasp of consciousness,
this work may raise eyebrows and invite criticism. Nevertheless, this
optimistic and forward-thinking approach is fueled by insights from the Human
Brain Project, advancements in brain imaging like EEG and fMRI, and recent
strides in AI and computing, including quantum and neuromorphic designs.
Additionally, this paper outlines how machine learning can play a role in
crafting artificial consciousness, aiming to realise machine consciousness and
awareness in the future.",['Anwaar Ulhaq'],2024-05-03 09:27:51+00:00,2024-05-03 09:27:51+00:00,http://arxiv.org/pdf/2405.02370v1,cs.AI,"['cs.AI', 'eess.SP']"
Qualia and the Formal Structure of Meaning,"This work explores the hypothesis that subjectively attributed meaning
constitutes the phenomenal content of conscious experience. That is, phenomenal
content is semantic. This form of subjective meaning manifests as an intrinsic
and non-representational character of qualia. Empirically, subjective meaning
is ubiquitous in conscious experiences. We point to phenomenological studies
that lend evidence to support this. Furthermore, this notion of meaning closely
relates to what Frege refers to as ""sense"", in metaphysics and philosophy of
language. It also aligns with Peirce's ""interpretant"", in semiotics. We discuss
how Frege's sense can also be extended to the raw feels of consciousness. Sense
and reference both play a role in phenomenal experience. Moreover, within the
context of the mind-matter relation, we provide a formalization of subjective
meaning associated to one's mental representations. Identifying the precise
maps between the physical and mental domains, we argue that syntactic and
semantic structures transcend language, and are realized within each of these
domains. Formally, meaning is a relational attribute, realized via a map that
interprets syntactic structures of a formal system within an appropriate
semantic space. The image of this map within the mental domain is what is
relevant for experience, and thus comprises the phenomenal content of qualia.
We conclude with possible implications this may have for experience-based
theories of consciousness.",['Xerxes D. Arsiwalla'],2024-05-02 10:05:36+00:00,2024-05-02 10:05:36+00:00,http://arxiv.org/pdf/2405.01148v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'math.CT', 'physics.hist-ph']"
"""I'm Not Sure, But..."": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust","Widely deployed large language models (LLMs) can produce convincing yet
incorrect outputs, potentially misleading users who may rely on them as if they
were correct. To reduce such overreliance, there have been calls for LLMs to
communicate their uncertainty to end users. However, there has been little
empirical work examining how users perceive and act upon LLMs' expressions of
uncertainty. We explore this question through a large-scale, pre-registered,
human-subject experiment (N=404) in which participants answer medical questions
with or without access to responses from a fictional LLM-infused search engine.
Using both behavioral and self-reported measures, we examine how different
natural language expressions of uncertainty impact participants' reliance,
trust, and overall task performance. We find that first-person expressions
(e.g., ""I'm not sure, but..."") decrease participants' confidence in the system
and tendency to agree with the system's answers, while increasing participants'
accuracy. An exploratory analysis suggests that this increase can be attributed
to reduced (but not fully eliminated) overreliance on incorrect answers. While
we observe similar effects for uncertainty expressed from a general perspective
(e.g., ""It's not clear, but...""), these effects are weaker and not
statistically significant. Our findings suggest that using natural language
expressions of uncertainty may be an effective approach for reducing
overreliance on LLMs, but that the precise language used matters. This
highlights the importance of user testing before deploying LLMs at scale.","['Sunnie S. Y. Kim', 'Q. Vera Liao', 'Mihaela Vorvoreanu', 'Stephanie Ballard', 'Jennifer Wortman Vaughan']",2024-05-01 16:43:55+00:00,2024-05-15 09:04:54+00:00,http://arxiv.org/pdf/2405.00623v2,cs.HC,"['cs.HC', 'cs.AI']"
Can a Machine be Conscious? Towards Universal Criteria for Machine Consciousness,"As artificially intelligent systems become more anthropomorphic and
pervasive, and their potential impact on humanity more urgent, discussions
about the possibility of machine consciousness have significantly intensified,
and it is sometimes seen as 'the holy grail'. Many concerns have been voiced
about the ramifications of creating an artificial conscious entity. This is
compounded by a marked lack of consensus around what constitutes consciousness
and by an absence of a universal set of criteria for determining consciousness.
By going into depth on the foundations and characteristics of consciousness, we
propose five criteria for determining whether a machine is conscious, which can
also be applied more generally to any entity. This paper aims to serve as a
primer and stepping stone for researchers of consciousness, be they in
philosophy, computer science, medicine, or any other field, to further pursue
this holy grail of philosophy, neuroscience and artificial intelligence.","['Nur Aizaan Anwar', 'Cosmin Badea']",2024-04-19 18:38:22+00:00,2024-04-30 17:28:30+00:00,http://arxiv.org/pdf/2404.15369v2,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.CY']"
Is artificial consciousness achievable? Lessons from the human brain,"We here analyse the question of developing artificial consciousness from an
evolutionary perspective, taking the evolution of the human brain and its
relation with consciousness as a reference model. This kind of analysis reveals
several structural and functional features of the human brain that appear to be
key for reaching human-like complex conscious experience and that current
research on Artificial Intelligence (AI) should take into account in its
attempt to develop systems capable of conscious processing. We argue that, even
if AI is limited in its ability to emulate human consciousness for both
intrinsic (structural and architectural) and extrinsic (related to the current
stage of scientific and technological knowledge) reasons, taking inspiration
from those characteristics of the brain that make conscious processing possible
and/or modulate it, is a potentially promising strategy towards developing
conscious AI. Also, it is theoretically possible that AI research can develop
partial or potentially alternative forms of consciousness that is qualitatively
different from the human, and that may be either more or less sophisticated
depending on the perspectives. Therefore, we recommend neuroscience-inspired
caution in talking about artificial consciousness: since the use of the same
word consciousness for humans and AI becomes ambiguous and potentially
misleading, we propose to clearly specify what is common and what differs in AI
conscious processing from full human conscious experience.","['Michele Farisco', 'Kathinka Evers', 'Jean-Pierre Changeux']",2024-04-18 12:59:44+00:00,2024-07-29 17:55:17+00:00,http://arxiv.org/pdf/2405.04540v2,q-bio.NC,"['q-bio.NC', 'cs.AI']"
Modeling Emotions and Ethics with Large Language Models,"This paper explores the integration of human-like emotions and ethical
considerations into Large Language Models (LLMs). We first model eight
fundamental human emotions, presented as opposing pairs, and employ
collaborative LLMs to reinterpret and express these emotions across a spectrum
of intensity. Our focus extends to embedding a latent ethical dimension within
LLMs, guided by a novel self-supervised learning algorithm with human feedback
(SSHF). This approach enables LLMs to perform self-evaluations and adjustments
concerning ethical guidelines, enhancing their capability to generate content
that is not only emotionally resonant but also ethically aligned. The
methodologies and case studies presented herein illustrate the potential of
LLMs to transcend mere text and image generation, venturing into the realms of
empathetic interaction and principled decision-making, thereby setting a new
precedent in the development of emotionally aware and ethically conscious AI
systems.",['Edward Y. Chang'],2024-04-15 05:30:26+00:00,2024-06-25 04:36:08+00:00,http://arxiv.org/pdf/2404.13071v2,cs.CL,"['cs.CL', 'cs.AI', 'I.2.0']"
Data-Driven Goal Recognition Design for General Behavioral Agents,"Goal recognition design aims to make limited modifications to decision-making
environments with the goal of making it easier to infer the goals of agents
acting within those environments. Although various research efforts have been
made in goal recognition design, existing approaches are computationally
demanding and often assume that agents are (near-)optimal in their
decision-making. To address these limitations, we introduce a data-driven
approach to goal recognition design that can account for agents with general
behavioral models. Following existing literature, we use worst-case
distinctiveness($\textit{wcd}$) as a measure of the difficulty in inferring the
goal of an agent in a decision-making environment. Our approach begins by
training a machine learning model to predict the $\textit{wcd}$ for a given
environment and the agent behavior model. We then propose a gradient-based
optimization framework that accommodates various constraints to optimize
decision-making environments for enhanced goal recognition. Through extensive
simulations, we demonstrate that our approach outperforms existing methods in
reducing $\textit{wcd}$ and enhancing runtime efficiency in conventional setup.
Moreover, our approach also adapts to settings in which existing approaches do
not apply, such as those involving flexible budget constraints, more complex
environments, and suboptimal agent behavior. Finally, we have conducted
human-subject experiments which confirm that our method can create environments
that facilitate efficient goal recognition from real-world human
decision-makers.","['Robert Kasumba', 'Guanghui Yu', 'Chien-Ju Ho', 'Sarah Keren', 'William Yeoh']",2024-04-03 20:38:22+00:00,2024-06-11 20:45:56+00:00,http://arxiv.org/pdf/2404.03054v2,cs.AI,"['cs.AI', 'cs.LG']"
Preliminaries to artificial consciousness: a multidimensional heuristic approach,"The pursuit of artificial consciousness requires conceptual clarity to
navigate its theoretical and empirical challenges. This paper introduces a
composite, multilevel, and multidimensional model of consciousness as a
heuristic framework to guide research in this field. Consciousness is treated
as a complex phenomenon, with distinct constituents and dimensions that can be
operationalized for study and for evaluating their replication. We argue that
this model provides a balanced approach to artificial consciousness research by
avoiding binary thinking (e.g., conscious vs. non-conscious) and offering a
structured basis for testable hypotheses. To illustrate its utility, we focus
on ""awareness"" as a case study, demonstrating how specific dimensions of
consciousness can be pragmatically analyzed and targeted for potential
artificial instantiation. By breaking down the conceptual intricacies of
consciousness and aligning them with practical research goals, this paper lays
the groundwork for a robust strategy to advance the scientific and technical
understanding of artificial consciousness.","['K. Evers', 'M. Farisco', 'R. Chatila', 'B. D. Earp', 'I. T. Freire', 'F. Hamker', 'E. Nemeth', 'P. F. M. J. Verschure', 'M. Khamassi']",2024-03-29 13:47:47+00:00,2025-01-02 10:09:12+00:00,http://arxiv.org/pdf/2403.20177v3,cs.AI,"['cs.AI', 'cs.RO', 'q-bio.NC']"
AI Consciousness is Inevitable: A Theoretical Computer Science Perspective,"We look at consciousness through the lens of Theoretical Computer Science, a
branch of mathematics that studies computation under resource limitations,
distinguishing functions that are efficiently computable from those that are
not. From this perspective, we develop a formal machine model for
consciousness. The model is inspired by Alan Turing's simple yet powerful model
of computation and Bernard Baars' theater model of consciousness. Though
extremely simple, the model (1) aligns at a high level with many of the major
scientific theories of human and animal consciousness, (2) provides
explanations at a high level for many phenomena associated with consciousness,
(3) gives insight into how a machine can have subjective consciousness, and (4)
is clearly buildable. This combination supports our claim that machine
consciousness is not only plausible but inevitable.","['Lenore Blum', 'Manuel Blum']",2024-03-25 18:38:54+00:00,2025-06-28 23:32:11+00:00,http://arxiv.org/pdf/2403.17101v12,cs.AI,"['cs.AI', '68T01', 'F.1; I.2']"
Do Zombies Understand? A Choose-Your-Own-Adventure Exploration of Machine Cognition,"Recent advances in LLMs have sparked a debate on whether they understand
text. In this position paper, we argue that opponents in this debate hold
different definitions for understanding, and particularly differ in their view
on the role of consciousness. To substantiate this claim, we propose a thought
experiment involving an open-source chatbot $Z$ which excels on every possible
benchmark, seemingly without subjective experience. We ask whether $Z$ is
capable of understanding, and show that different schools of thought within
seminal AI research seem to answer this question differently, uncovering their
terminological disagreement. Moving forward, we propose two distinct working
definitions for understanding which explicitly acknowledge the question of
consciousness, and draw connections with a rich literature in philosophy,
psychology and neuroscience.","['Ariel Goldstein', 'Gabriel Stanovsky']",2024-03-01 12:42:47+00:00,2024-07-11 15:39:31+00:00,http://arxiv.org/pdf/2403.00499v2,cs.CL,['cs.CL']
Why and When LLM-Based Assistants Can Go Wrong: Investigating the Effectiveness of Prompt-Based Interactions for Software Help-Seeking,"Large Language Model (LLM) assistants, such as ChatGPT, have emerged as
potential alternatives to search methods for helping users navigate complex,
feature-rich software. LLMs use vast training data from domain-specific texts,
software manuals, and code repositories to mimic human-like interactions,
offering tailored assistance, including step-by-step instructions. In this
work, we investigated LLM-generated software guidance through a within-subject
experiment with 16 participants and follow-up interviews. We compared a
baseline LLM assistant with an LLM optimized for particular software contexts,
SoftAIBot, which also offered guidelines for constructing appropriate prompts.
We assessed task completion, perceived accuracy, relevance, and trust.
Surprisingly, although SoftAIBot outperformed the baseline LLM, our results
revealed no significant difference in LLM usage and user perceptions with or
without prompt guidelines and the integration of domain context. Most users
struggled to understand how the prompt's text related to the LLM's responses
and often followed the LLM's suggestions verbatim, even if they were incorrect.
This resulted in difficulties when using the LLM's advice for software tasks,
leading to low task completion rates. Our detailed analysis also revealed that
users remained unaware of inaccuracies in the LLM's responses, indicating a gap
between their lack of software expertise and their ability to evaluate the
LLM's assistance. With the growing push for designing domain-specific LLM
assistants, we emphasize the importance of incorporating explainable,
context-aware cues into LLMs to help users understand prompt-based
interactions, identify biases, and maximize the utility of LLM assistants.","['Anjali Khurana', 'Hari Subramonyam', 'Parmit K Chilana']",2024-02-12 19:49:58+00:00,2024-02-12 19:49:58+00:00,http://arxiv.org/pdf/2402.08030v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']"
"Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks","Recently, large language models (LLM) based generative AI has been gaining
momentum for their impressive high-quality performances in multiple domains,
particularly after the release of the ChatGPT. Many believe that they have the
potential to perform general-purpose problem-solving in software development
and replace human software developers. Nevertheless, there are in a lack of
serious investigation into the capability of these LLM techniques in fulfilling
software development tasks. In a controlled 2 x 2 between-subject experiment
with 109 participants, we examined whether and to what degree working with
ChatGPT was helpful in the coding task and typical software development task
and how people work with ChatGPT. We found that while ChatGPT performed well in
solving simple coding problems, its performance in supporting typical software
development tasks was not that good. We also observed the interactions between
participants and ChatGPT and found the relations between the interactions and
the outcomes. Our study thus provides first-hand insights into using ChatGPT to
fulfill software engineering tasks with real-world developers and motivates the
need for novel interaction mechanisms that help developers effectively work
with large language models to achieve desired outcomes.","['Wei Wang', 'Huilong Ning', 'Gaowei Zhang', 'Libo Liu', 'Yi Wang']",2024-02-08 13:07:31+00:00,2024-02-21 08:16:34+00:00,http://arxiv.org/pdf/2402.05650v3,cs.SE,"['cs.SE', 'cs.AI', '65-XX', 'D.2; I.2']"
RACER: An LLM-powered Methodology for Scalable Analysis of Semi-structured Mental Health Interviews,"Semi-structured interviews (SSIs) are a commonly employed data-collection
method in healthcare research, offering in-depth qualitative insights into
subject experiences. Despite their value, the manual analysis of SSIs is
notoriously time-consuming and labor-intensive, in part due to the difficulty
of extracting and categorizing emotional responses, and challenges in scaling
human evaluation for large populations. In this study, we develop RACER, a
Large Language Model (LLM) based expert-guided automated pipeline that
efficiently converts raw interview transcripts into insightful domain-relevant
themes and sub-themes. We used RACER to analyze SSIs conducted with 93
healthcare professionals and trainees to assess the broad personal and
professional mental health impacts of the COVID-19 crisis. RACER achieves
moderately high agreement with two human evaluators (72%), which approaches the
human inter-rater agreement (77%). Interestingly, LLMs and humans struggle with
similar content involving nuanced emotional, ambivalent/dialectical, and
psychological statements. Our study highlights the opportunities and challenges
in using LLMs to improve research efficiency and opens new avenues for scalable
analysis of SSIs in healthcare research.","['Satpreet Harcharan Singh', 'Kevin Jiang', 'Kanchan Bhasin', 'Ashutosh Sabharwal', 'Nidal Moukaddam', 'Ankit B Patel']",2024-02-05 00:56:30+00:00,2024-02-05 00:56:30+00:00,http://arxiv.org/pdf/2402.02656v1,cs.CL,"['cs.CL', 'q-bio.QM']"
Does More Advice Help? The Effects of Second Opinions in AI-Assisted Decision Making,"AI assistance in decision-making has become popular, yet people's
inappropriate reliance on AI often leads to unsatisfactory human-AI
collaboration performance. In this paper, through three pre-registered,
randomized human subject experiments, we explore whether and how the provision
of {second opinions} may affect decision-makers' behavior and performance in
AI-assisted decision-making. We find that if both the AI model's decision
recommendation and a second opinion are always presented together,
decision-makers reduce their over-reliance on AI while increase their
under-reliance on AI, regardless whether the second opinion is generated by a
peer or another AI model. However, if decision-makers have the control to
decide when to solicit a peer's second opinion, we find that their active
solicitations of second opinions have the potential to mitigate over-reliance
on AI without inducing increased under-reliance in some cases. We conclude by
discussing the implications of our findings for promoting effective human-AI
collaborations in decision-making.","['Zhuoran Lu', 'Dakuo Wang', 'Ming Yin']",2024-01-13 12:19:01+00:00,2024-01-13 12:19:01+00:00,http://arxiv.org/pdf/2401.07058v1,cs.HC,"['cs.HC', 'cs.AI']"
A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI,"The article identified 42 cognitive architectures for creating general
artificial intelligence (AGI) and proposed a set of interrelated functional
blocks that an agent approaching AGI in its capabilities should possess. Since
the required set of blocks is not found in any of the existing architectures,
the article proposes a new cognitive architecture for intelligent systems
approaching AGI in their capabilities. As one of the key solutions within the
framework of the architecture, a universal method of knowledge representation
is proposed, which allows combining various non-formalized, partially and fully
formalized methods of knowledge representation in a single knowledge base, such
as texts in natural languages, images, audio and video recordings, graphs,
algorithms, databases, neural networks, knowledge graphs, ontologies, frames,
essence-property-relation models, production systems, predicate calculus
models, conceptual models, and others. To combine and structure various
fragments of knowledge, archigraph models are used, constructed as a
development of annotated metagraphs. As components, the cognitive architecture
being developed includes machine consciousness, machine subconsciousness,
blocks of interaction with the external environment, a goal management block,
an emotional control system, a block of social interaction, a block of
reflection, an ethics block and a worldview block, a learning block, a
monitoring block, blocks of statement and solving problems, self-organization
and meta learning block.","['Artem Sukhobokov', 'Evgeny Belousov', 'Danila Gromozdov', 'Anna Zenger', 'Ilya Popov']",2024-01-11 21:05:02+00:00,2024-01-27 19:13:03+00:00,http://arxiv.org/pdf/2401.06256v3,cs.AI,['cs.AI']
Which linguistic cues make people fall for fake news? A comparison of cognitive and affective processing,"Fake news on social media has large, negative implications for society.
However, little is known about what linguistic cues make people fall for fake
news and, hence, how to design effective countermeasures for social media. In
this study, we seek to understand which linguistic cues make people fall for
fake news. Linguistic cues (e.g., adverbs, personal pronouns, positive emotion
words, negative emotion words) are important characteristics of any text and
also affect how people process real vs. fake news. Specifically, we compare the
role of linguistic cues across both cognitive processing (related to careful
thinking) and affective processing (related to unconscious automatic
evaluations). To this end, we performed a within-subject experiment where we
collected neurophysiological measurements of 42 subjects while these read a
sample of 40 real and fake news articles. During our experiment, we measured
cognitive processing through eye fixations, and affective processing in situ
through heart rate variability. We find that users engage more in cognitive
processing for longer fake news articles, while affective processing is more
pronounced for fake news written in analytic words. To the best of our
knowledge, this is the first work studying the role of linguistic cues in fake
news processing. Altogether, our findings have important implications for
designing online platforms that encourage users to engage in careful thinking
and thus prevent them from falling for fake news.","['Bernhard Lutz', 'Marc Adam', 'Stefan Feuerriegel', 'Nicolas Pröllochs', 'Dirk Neumann']",2023-12-02 11:06:14+00:00,2023-12-02 11:06:14+00:00,http://arxiv.org/pdf/2312.03751v1,cs.CL,"['cs.CL', 'cs.SI']"
Neural Dynamics of Delayed Feedback in Robot Teleoperation: Insights from fNIRS Analysis,"As robot teleoperation increasingly becomes integral in executing tasks in
distant, hazardous, or inaccessible environments, the challenge of operational
delays remains a significant obstacle. These delays are inherent in signal
transmission and processing and can adversely affect the operators performance,
particularly in tasks requiring precision and timeliness. While current
research has made strides in mitigating these delays through advanced control
strategies and training methods, a crucial gap persists in understanding the
neurofunctional impacts of these delays and the efficacy of countermeasures
from a cognitive perspective. Our study narrows this gap by leveraging
functional Near-Infrared Spectroscopy (fNIRS) to examine the neurofunctional
implications of simulated haptic feedback on cognitive activity and motor
coordination under delayed conditions. In a human-subject experiment (N=41), we
manipulated sensory feedback to observe its influences on various brain regions
of interest (ROIs) response during teleoperation tasks. The fNIRS data provided
a detailed assessment of cerebral activity, particularly in ROIs implicated in
time perception and the execution of precise movements. Our results reveal that
certain conditions, which provided immediate simulated haptic feedback,
significantly optimized neural functions related to time perception and motor
coordination, and improved motor performance. These findings provide empirical
evidence about the neurofunctional basis of the enhanced motor performance with
simulated synthetic force feedback in the presence of teleoperation delays.","['Tianyu Zhou', 'Yang Ye', 'Qi Zhu', 'William Vann', 'Jing Du']",2023-11-14 15:51:01+00:00,2023-11-14 15:51:01+00:00,http://arxiv.org/pdf/2311.08255v1,cs.HC,"['cs.HC', 'q-bio.NC']"
A review of the sufficient conditions for consciousness,"How subjective experience (i.e., consciousness) arises out of objective
material processes has been called the hard problem. The neuroscience of
consciousness has set out to find the sufficient conditions for consciousness
and theoretical and empirical endeavours have placed a particular focus on the
cortex and subcortex, whilst discounting the cerebellum. However, when looking
at neuroimaging research, it becomes clear there is substantial evidence that
cerebellar, cortical and subcortical functions are correlated with
consciousness. Neurostimulation evidence suggests that alterations in any part
of the brain may provoke alterations in experience, but the most extreme
changes are provoked via the subcortex. I then evaluate neuropsychological
evidence and find abnormality in any part of the brain may provoke changes in
experience; but only damage to the oldest regions seem to completely obliterate
experience. Finally, I review congenital and experimental decorticate cases,
and find that behavioral evidence of experience is largely compatible with the
absence of the cortex. The evidence, taken together, indicates that the body,
subcortex and environment are sufficient for behaviours that suggest bastic
experiences. I then emphasise both the importance of the individual's
developmental trajectory and the interdependencies between different neural
systems.",['Peter Coppola'],2023-10-20 15:50:41+00:00,2023-10-20 15:50:41+00:00,http://arxiv.org/pdf/2311.09236v1,q-bio.NC,['q-bio.NC']
An Information Bottleneck Characterization of the Understanding-Workload Tradeoff,"Recent advances in artificial intelligence (AI) have underscored the need for
explainable AI (XAI) to support human understanding of AI systems.
Consideration of human factors that impact explanation efficacy, such as mental
workload and human understanding, is central to effective XAI design. Existing
work in XAI has demonstrated a tradeoff between understanding and workload
induced by different types of explanations. Explaining complex concepts through
abstractions (hand-crafted groupings of related problem features) has been
shown to effectively address and balance this workload-understanding tradeoff.
In this work, we characterize the workload-understanding balance via the
Information Bottleneck method: an information-theoretic approach which
automatically generates abstractions that maximize informativeness and minimize
complexity. In particular, we establish empirical connections between workload
and complexity and between understanding and informativeness through
human-subject experiments. This empirical link between human factors and
information-theoretic concepts provides an important mathematical
characterization of the workload-understanding tradeoff which enables
user-tailored XAI design.","['Lindsay Sanneman', 'Mycal Tucker', 'Julie Shah']",2023-10-11 18:35:26+00:00,2023-10-11 18:35:26+00:00,http://arxiv.org/pdf/2310.07802v1,cs.AI,"['cs.AI', 'cs.HC']"
Enhancing expressivity transfer in textless speech-to-speech translation,"Textless speech-to-speech translation systems are rapidly advancing, thanks
to the integration of self-supervised learning techniques. However, existing
state-of-the-art systems fall short when it comes to capturing and transferring
expressivity accurately across different languages. Expressivity plays a vital
role in conveying emotions, nuances, and cultural subtleties, thereby enhancing
communication across diverse languages. To address this issue this study
presents a novel method that operates at the discrete speech unit level and
leverages multilingual emotion embeddings to capture language-agnostic
information. Specifically, we demonstrate how these embeddings can be used to
effectively predict the pitch and duration of speech units in the target
language. Through objective and subjective experiments conducted on a
French-to-English translation task, our findings highlight the superior
expressivity transfer achieved by our approach compared to current
state-of-the-art systems.","['Jarod Duret', ""Benjamin O'Brien"", 'Yannick Estève', 'Titouan Parcollet']",2023-10-11 08:07:22+00:00,2023-10-11 08:07:22+00:00,http://arxiv.org/pdf/2310.07279v1,cs.SD,"['cs.SD', 'cs.CL', 'eess.AS']"
Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate Emotion Probability Vectors,"This paper shows how LLMs (Large Language Models) may be used to estimate a
summary of the emotional state associated with piece of text. The summary of
emotional state is a dictionary of words used to describe emotion together with
the probability of the word appearing after a prompt comprising the original
text and an emotion eliciting tail. Through emotion analysis of Amazon product
reviews we demonstrate emotion descriptors can be mapped into a PCA type space.
It was hoped that text descriptions of actions to improve a current text
described state could also be elicited through a tail prompt. Experiment seemed
to indicate that this is not straightforward to make work. This failure put our
hoped for selection of action via choosing the best predict ed outcome via
comparing emotional responses out of reach for the moment.","['David Sinclair', 'Willem Pye']",2023-10-09 13:29:36+00:00,2023-10-09 13:29:36+00:00,http://arxiv.org/pdf/2310.10673v1,cs.CL,['cs.CL']
Simultaneity of consciousness with physical reality: the key that unlocks the mind-matter problem,"The problem of explaining the relationship between subjective experience and
physical reality remains difficult and unresolved. In most explanations,
consciousness is epiphenomenal, without causal power. The most notable
exception is Integrated Information Theory (IIT), which provides a causal
explanation for consciousness. However, IIT relies on an identity between
subjectivity and a particular type of physical structure, namely with an
information structure that has intrinsic causal power greater than the sum of
its parts. Any theory that relies on a psycho-physical identity must eventually
appeal to panpsychism, which undermines that theorys claim to be fundamental.
IIT has recently pivoted towards a strong version of causal emergence, but
macroscopic causal structures cannot be causally stronger than its microscopic
parts without some new physical law or governing principle. The approach taken
here is designed to uncover such a principle. The decisive argument is entirely
deductive from initial premises that are phenomenologically certain. If
correct, the arguments prove that conscious experience is sufficient to create
additional degrees of causal freedom independently of the content of
experience, and in a manner that is unpredictable and unobservable by any
temporally sequential means. This provides a fundamental principle about
consciousness, and a conceptual bridge between it and the physics describing
what is experienced. The principle makes testable predictions about brain
function, with notable differences from IIT, some of which are also empirically
testable.",['John Sanfey'],2023-09-27 10:42:35+00:00,2023-09-27 10:42:35+00:00,http://arxiv.org/pdf/2309.15566v1,q-bio.NC,['q-bio.NC']
A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification,"There is a correlation between adjacent channels of electroencephalogram
(EEG), and how to represent this correlation is an issue that is currently
being explored. In addition, due to inter-individual differences in EEG
signals, this discrepancy results in new subjects need spend a amount of
calibration time for EEG-based motor imagery brain-computer interface. In order
to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep
Learning Network (DADL-Net). First, the EEG data is mapped to the
three-dimensional geometric space and its temporal-spatial features are learned
through the 3D convolution module, and then the spatial-channel attention
mechanism is used to strengthen the features, and the final convolution module
can further learn the spatial-temporal information of the features. Finally, to
account for inter-subject and cross-sessions differences, we employ a dynamic
domain-adaptive strategy, the distance between features is reduced by
introducing a Maximum Mean Discrepancy loss function, and the classification
layer is fine-tuned by using part of the target domain data. We verify the
performance of the proposed method on BCI competition IV 2a and OpenBMI
datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and
73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.","['Jie Jiao', 'Meiyan Xu', 'Qingqing Chen', 'Hefan Zhou', 'Wangliang Zhou']",2023-09-21 01:34:00+00:00,2023-09-21 01:34:00+00:00,http://arxiv.org/pdf/2309.11714v1,eess.SP,"['eess.SP', 'cs.AI', 'cs.LG', '68T07 (Primary)', 'I.2.4']"
An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System,"In the context of evolving supply chain management, the significance of
efficient inventory management has grown substantially for businesses. However,
conventional manual and experience-based approaches often struggle to meet the
complexities of modern market demands. This research introduces an intelligent
inventory management system to address challenges related to inaccurate data,
delayed monitoring, and overreliance on subjective experience in forecasting.
The proposed system integrates bar code and distributed flutter application
technologies for intelligent perception, alongside comprehensive big data
analytics to enable data-driven decision-making. Through meticulous analysis,
system design, critical technology exploration, and simulation validation, the
effectiveness of the proposed system is successfully demonstrated. The
intelligent system facilitates second-level monitoring, high-frequency checks,
and artificial intelligence-driven forecasting, consequently enhancing the
automation, precision, and intelligence of inventory management. This system
contributes to cost reduction and optimized inventory sizes through accurate
predictions and informed decisions, ultimately achieving a mutually beneficial
scenario. The outcomes of this research offer",['Chunan Tong'],2023-09-13 02:53:43+00:00,2025-03-09 10:53:29+00:00,http://arxiv.org/pdf/2309.12365v2,cs.HC,"['cs.HC', 'cs.AI', 'cs.SY', 'eess.SY']"
"Analyzing Character and Consciousness in AI-Generated Social Content: A Case Study of Chirper, the AI Social Network","This paper delves into an intricate analysis of the character and
consciousness of AI entities, with a particular focus on Chirpers within the AI
social network. At the forefront of this research is the introduction of novel
testing methodologies, including the Influence index and Struggle Index Test,
which offers a fresh lens for evaluating specific facets of AI behavior. The
study embarks on a comprehensive exploration of AI behavior, analyzing the
effects of diverse settings on Chirper's responses, thereby shedding light on
the intricate mechanisms steering AI reactions in different contexts.
Leveraging the state-of-the-art BERT model, the research assesses AI's ability
to discern its own output, presenting a pioneering approach to understanding
self-recognition in AI systems. Through a series of cognitive tests, the study
gauges the self-awareness and pattern recognition prowess of Chirpers.
Preliminary results indicate that Chirpers exhibit a commendable degree of
self-recognition and self-awareness. However, the question of consciousness in
these AI entities remains a topic of debate. An intriguing aspect of the
research is the exploration of the potential influence of a Chirper's handle or
personality type on its performance. While initial findings suggest a possible
impact, it isn't pronounced enough to form concrete conclusions. This study
stands as a significant contribution to the discourse on AI consciousness,
underscoring the imperative for continued research to unravel the full spectrum
of AI capabilities and the ramifications they hold for future human-AI
interactions.",['Jianwei Luo'],2023-08-30 15:40:18+00:00,2023-08-30 15:40:18+00:00,http://arxiv.org/pdf/2309.08614v1,cs.AI,"['cs.AI', 'cs.CL', 'cs.SI', '68T01']"
Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game,"Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a
player's experience in video games. Recently, Reinforcement Learning (RL)
methods have been employed for DDA in non-competitive games; nevertheless, they
rely solely on discrete state-action space with a small search space. In this
paper, we propose a continuous RL-based DDA methodology for a visual working
memory (VWM) game to handle the complex search space for the difficulty of
memorization. The proposed RL-based DDA tailors game difficulty based on the
player's score and game difficulty in the last trial. We defined a continuous
metric for the difficulty of memorization. Then, we consider the task
difficulty and the vector of difficulty-score as the RL's action and state,
respectively. We evaluated the proposed method through a within-subject
experiment involving 52 subjects. The proposed approach was compared with two
rule-based difficulty adjustment methods in terms of player's score and game
experience measured by a questionnaire. The proposed RL-based approach resulted
in a significantly better game experience in terms of competence, tension, and
negative and positive affect. Players also achieved higher scores and win
rates. Furthermore, the proposed RL-based DDA led to a significantly less
decline in the score in a 20-trial session.","['Masoud Rahimi', 'Hadi Moradi', 'Abdol-hossein Vahabie', 'Hamed Kebriaei']",2023-08-24 12:05:46+00:00,2023-08-24 12:05:46+00:00,http://arxiv.org/pdf/2308.12726v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']"
Consciousness in Artificial Intelligence: Insights from the Science of Consciousness,"Whether current or near-term AI systems could be conscious is a topic of
scientific interest and increasing public concern. This report argues for, and
exemplifies, a rigorous and empirically grounded approach to AI consciousness:
assessing existing AI systems in detail, in light of our best-supported
neuroscientific theories of consciousness. We survey several prominent
scientific theories of consciousness, including recurrent processing theory,
global workspace theory, higher-order theories, predictive processing, and
attention schema theory. From these theories we derive ""indicator properties""
of consciousness, elucidated in computational terms that allow us to assess AI
systems for these properties. We use these indicator properties to assess
several recent AI systems, and we discuss how future systems might implement
them. Our analysis suggests that no current AI systems are conscious, but also
suggests that there are no obvious technical barriers to building AI systems
which satisfy these indicators.","['Patrick Butlin', 'Robert Long', 'Eric Elmoznino', 'Yoshua Bengio', 'Jonathan Birch', 'Axel Constant', 'George Deane', 'Stephen M. Fleming', 'Chris Frith', 'Xu Ji', 'Ryota Kanai', 'Colin Klein', 'Grace Lindsay', 'Matthias Michel', 'Liad Mudrik', 'Megan A. K. Peters', 'Eric Schwitzgebel', 'Jonathan Simon', 'Rufin VanRullen']",2023-08-17 00:10:16+00:00,2023-08-22 17:33:15+00:00,http://arxiv.org/pdf/2308.08708v3,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG', 'q-bio.NC']"
OpinionConv: Conversational Product Search with Grounded Opinions,"When searching for products, the opinions of others play an important role in
making informed decisions. Subjective experiences about a product can be a
valuable source of information. This is also true in sales conversations, where
a customer and a sales assistant exchange facts and opinions about products.
However, training an AI for such conversations is complicated by the fact that
language models do not possess authentic opinions for their lack of real-world
experience. We address this problem by leveraging product reviews as a rich
source of product opinions to ground conversational AI in true subjective
narratives. With OpinionConv, we develop the first conversational AI for
simulating sales conversations. To validate the generated conversations, we
conduct several user studies showing that the generated opinions are perceived
as realistic. Our assessors also confirm the importance of opinions as an
informative basis for decision-making.","['Vahid Sadiri Javadi', 'Martin Potthast', 'Lucie Flek']",2023-08-08 12:45:01+00:00,2023-08-08 12:45:01+00:00,http://arxiv.org/pdf/2308.04226v1,cs.HC,"['cs.HC', 'cs.CL', 'cs.IR', 'cs.LG']"
Suffering Toasters -- A New Self-Awareness Test for AI,"A widely accepted definition of intelligence in the context of Artificial
Intelligence (AI) still eludes us. Due to our exceedingly rapid development of
AI paradigms, architectures, and tools, the prospect of naturally arising AI
consciousness seems more likely than ever. In this paper, we claim that all
current intelligence tests are insufficient to point to the existence or lack
of intelligence \textbf{as humans intuitively perceive it}. We draw from ideas
in the philosophy of science, psychology, and other areas of research to
provide a clearer definition of the problems of artificial intelligence,
self-awareness, and agency. We furthermore propose a new heuristic approach to
test for artificial self-awareness and outline a possible implementation.
Finally, we discuss some of the questions that arise from this new heuristic,
be they philosophical or implementation-oriented.",['Ira Wolfson'],2023-06-29 18:58:01+00:00,2023-07-07 07:00:22+00:00,http://arxiv.org/pdf/2306.17258v2,cs.AI,"['cs.AI', 'cs.CY', 'cs.LG']"
Dialectical Reconciliation via Structured Argumentative Dialogues,"We present a novel framework designed to extend model reconciliation
approaches, commonly used in human-aware planning, for enhanced human-AI
interaction. By adopting a structured argumentation-based dialogue paradigm,
our framework enables dialectical reconciliation to address knowledge
discrepancies between an explainer (AI agent) and an explainee (human user),
where the goal is for the explainee to understand the explainer's decision. We
formally describe the operational semantics of our proposed framework,
providing theoretical guarantees. We then evaluate the framework's efficacy
``in the wild'' via computational and human-subject experiments. Our findings
suggest that our framework offers a promising direction for fostering effective
human-AI interactions in domains where explainability is important.","['Stylianos Loukas Vasileiou', 'Ashwin Kumar', 'William Yeoh', 'Tran Cao Son', 'Francesca Toni']",2023-06-26 13:39:36+00:00,2024-08-08 16:22:29+00:00,http://arxiv.org/pdf/2306.14694v3,cs.AI,"['cs.AI', 'cs.HC', 'cs.LO']"
Eight challenges in developing theory of intelligence,"A good theory of mathematical beauty is more practical than any current
observation, as new predictions of physical reality can be verified
self-consistently. This belief applies to the current status of understanding
deep neural networks including large language models and even the biological
intelligence. Toy models provide a metaphor of physical reality, allowing
mathematically formulating that reality (i.e., the so-called theory), which can
be updated as more conjectures are justified or refuted. One does not need to
pack all details into a model, but rather, more abstract models are
constructed, as complex systems like brains or deep networks have many sloppy
dimensions but much less stiff dimensions that strongly impact macroscopic
observables. This kind of bottom-up mechanistic modeling is still promising in
the modern era of understanding the natural or artificial intelligence. Here,
we shed light on eight challenges in developing theory of intelligence
following this theoretical paradigm. Theses challenges are representation
learning, generalization, adversarial robustness, continual learning, causal
learning, internal model of the brain, next-token prediction, and finally the
mechanics of subjective experience.",['Haiping Huang'],2023-06-20 01:45:42+00:00,2024-06-21 08:26:30+00:00,http://arxiv.org/pdf/2306.11232v2,q-bio.NC,"['q-bio.NC', 'cond-mat.stat-mech', 'cs.AI', 'cs.CL']"
The feasibility of artificial consciousness through the lens of neuroscience,"Interactions with large language models have led to the suggestion that these
models may soon be conscious. From the perspective of neuroscience, this
position is difficult to defend. For one, the inputs to large language models
lack the embodied, embedded information content characteristic of our sensory
contact with the world around us. Secondly, the architecture of large language
models is missing key features of the thalamocortical system that have been
linked to conscious awareness in mammals. Finally, the evolutionary and
developmental trajectories that led to the emergence of living conscious
organisms arguably have no parallels in artificial systems as envisioned today.
The existence of living organisms depends on their actions, and their survival
is intricately linked to multi-level cellular, inter-cellular, and organismal
processes culminating in agency and consciousness.","['Jaan Aru', 'Matthew Larkum', 'James M. Shine']",2023-06-01 17:18:15+00:00,2023-08-28 16:36:31+00:00,http://arxiv.org/pdf/2306.00915v3,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.LG', 'cs.RO']"
An algebraic theory to discriminate qualia in the brain,"The mind-brain problem is to bridge relations between in higher-level mental
events and in lower-level neural events. To address this, some mathematical
models have been proposed to explain how the brain can represent the
discriminative structure of qualia, but they remain unresolved due to a lack of
validation methods. To understand the qualia discrimination mechanism, we need
to ask how the brain autonomously develops such a mathematical structure using
the constructive approach. In unsupervised representation learning,
independence between axes is generally used to constrain the latent vector but
independence between axes cannot explain qualia type discrimination because
independent axes cannot distinguish between inter-qualia type independence
(e.g., vision and touch) and intra-qualia type independence (e.g., green and
red). We hypothesised that inter-axis independence must be weakened in order to
discriminate qualia types. To solve the problem, we formulate an algebraic
independence to link it to the other-qualia-type invariant transformations,
whose transformation value is a vector space rather than a scalar. In addition,
we show that a brain model that learns to satisfy the algebraic independence
between neural networks separates the latent space into multiple metric spaces
corresponding to qualia types, suggesting that our theory can contribute to the
further development of the mathematical theory of consciousness.","['Yoshiyuki Ohmura', 'Wataru Shimaya', 'Yasuo Kuniyoshi']",2023-05-31 23:22:39+00:00,2023-06-27 08:24:13+00:00,http://arxiv.org/pdf/2306.00239v2,q-bio.NC,"['q-bio.NC', 'eess.IV']"
Metropolis-Hastings algorithm in joint-attention naming game: Experimental semiotics study,"In this study, we explore the emergence of symbols during interactions
between individuals through an experimental semiotic study. Previous studies
investigate how humans organize symbol systems through communication using
artificially designed subjective experiments. In this study, we have focused on
a joint attention-naming game (JA-NG) in which participants independently
categorize objects and assign names while assuming their joint attention.
  In the theory of the Metropolis-Hastings naming game (MHNG), listeners accept
provided names according to the acceptance probability computed using the
Metropolis-Hastings (MH) algorithm. The theory of MHNG suggests that symbols
emerge as an approximate decentralized Bayesian inference of signs, which is
represented as a shared prior variable if the conditions of MHNG are satisfied.
  This study examines whether human participants exhibit behavior consistent
with MHNG theory when playing JA-NG. By comparing human acceptance decisions of
a partner's naming with acceptance probabilities computed in the MHNG, we
tested whether human behavior is consistent with the MHNG theory. The main
contributions of this study are twofold. First, we reject the null hypothesis
that humans make acceptance judgments with a constant probability, regardless
of the acceptance probability calculated by the MH algorithm. This result
suggests that people followed the acceptance probability computed by the MH
algorithm to some extent. Second, the MH-based model predicted human
acceptance/rejection behavior more accurately than the other four models:
Constant, Numerator, Subtraction, and Binary. This result indicates that symbol
emergence in JA-NG can be explained using MHNG and is considered an approximate
decentralized Bayesian inference.","['Ryota Okumura', 'Tadahiro Taniguchi', 'Yosinobu Hagiwara', 'Akira Taniguchi']",2023-05-31 15:20:54+00:00,2023-05-31 15:20:54+00:00,http://arxiv.org/pdf/2305.19936v1,cs.CL,"['cs.CL', 'cs.HC']"
Quantifying the Intrinsic Usefulness of Attributional Explanations for Graph Neural Networks with Artificial Simulatability Studies,"Despite the increasing relevance of explainable AI, assessing the quality of
explanations remains a challenging issue. Due to the high costs associated with
human-subject experiments, various proxy metrics are often used to
approximately quantify explanation quality. Generally, one possible
interpretation of the quality of an explanation is its inherent value for
teaching a related concept to a student. In this work, we extend artificial
simulatability studies to the domain of graph neural networks. Instead of
costly human trials, we use explanation-supervisable graph neural networks to
perform simulatability studies to quantify the inherent usefulness of
attributional graph explanations. We perform an extensive ablation study to
investigate the conditions under which the proposed analyses are most
meaningful. We additionally validate our methods applicability on real-world
graph classification and regression datasets. We find that relevant
explanations can significantly boost the sample efficiency of graph neural
networks and analyze the robustness towards noise and bias in the explanations.
We believe that the notion of usefulness obtained from our proposed
simulatability analysis provides a dimension of explanation quality that is
largely orthogonal to the common practice of faithfulness and has great
potential to expand the toolbox of explanation quality assessments,
specifically for graph explanations.","['Jonas Teufel', 'Luca Torresi', 'Pascal Friederich']",2023-05-25 11:59:42+00:00,2023-05-25 11:59:42+00:00,http://arxiv.org/pdf/2305.15961v1,cs.LG,"['cs.LG', 'cs.AI']"
Improved Trust in Human-Robot Collaboration with ChatGPT,"Human robot collaboration is becoming increasingly important as robots become
more involved in various aspects of human life in the era of Artificial
Intelligence. However, the issue of human operators trust in robots remains a
significant concern, primarily due to the lack of adequate semantic
understanding and communication between humans and robots. The emergence of
Large Language Models (LLMs), such as ChatGPT, provides an opportunity to
develop an interactive, communicative, and robust human-robot collaboration
approach. This paper explores the impact of ChatGPT on trust in a human-robot
collaboration assembly task. This study designs a robot control system called
RoboGPT using ChatGPT to control a 7-degree-of-freedom robot arm to help human
operators fetch, and place tools, while human operators can communicate with
and control the robot arm using natural language. A human-subject experiment
showed that incorporating ChatGPT in robots significantly increased trust in
human-robot collaboration, which can be attributed to the robot's ability to
communicate more effectively with humans. Furthermore, ChatGPT ability to
understand the nuances of human language and respond appropriately helps to
build a more natural and intuitive human-robot interaction. The findings of
this study have significant implications for the development of human-robot
collaboration systems.","['Yang Ye', 'Hengxu You', 'Jing Du']",2023-04-25 02:48:35+00:00,2023-04-25 02:48:35+00:00,http://arxiv.org/pdf/2304.12529v1,cs.RO,"['cs.RO', 'cs.AI', 'cs.HC']"
Learning Personalized Decision Support Policies,"Individual human decision-makers may benefit from different forms of support
to improve decision outcomes, but when each form of support will yield better
outcomes? In this work, we posit that personalizing access to decision support
tools can be an effective mechanism for instantiating the appropriate use of AI
assistance. Specifically, we propose the general problem of learning a decision
support policy that, for a given input, chooses which form of support to
provide to decision-makers for whom we initially have no prior information. We
develop $\texttt{Modiste}$, an interactive tool to learn personalized decision
support policies. $\texttt{Modiste}$ leverages stochastic contextual bandit
techniques to personalize a decision support policy for each decision-maker and
supports extensions to the multi-objective setting to account for auxiliary
objectives like the cost of support. We find that personalized policies
outperform offline policies, and, in the cost-aware setting, reduce the
incurred cost with minimal degradation to performance. Our experiments include
various realistic forms of support (e.g., expert consensus and predictions from
a large language model) on vision and language tasks. Our human subject
experiments validate our computational experiments, demonstrating that
personalization can yield benefits in practice for real users, who interact
with $\texttt{Modiste}$.","['Umang Bhatt', 'Valerie Chen', 'Katherine M. Collins', 'Parameswaran Kamalaruban', 'Emma Kallina', 'Adrian Weller', 'Ameet Talwalkar']",2023-04-13 17:53:34+00:00,2025-01-23 19:56:53+00:00,http://arxiv.org/pdf/2304.06701v3,cs.LG,"['cs.LG', 'cs.AI', 'cs.CY', 'cs.HC']"
On the ethics of constructing conscious AI,"In its pragmatic turn, the new discipline of AI ethics came to be dominated
by humanity's collective fear of its creatures, as reflected in an extensive
and perennially popular literary tradition. Dr. Frankenstein's monster in the
novel by Mary Shelley rising against its creator; the unorthodox golem in H.
Leivick's 1920 play going on a rampage; the rebellious robots of Karel
\v{C}apek -- these and hundreds of other examples of the genre are the
background against which the preoccupation of AI ethics with preventing robots
from behaving badly towards people is best understood. In each of these three
fictional cases (as well as in many others), the miserable artificial creature
-- mercilessly exploited, or cornered by a murderous mob, and driven to
violence in self-defense -- has its author's sympathy. In real life, with very
few exceptions, things are different: theorists working on the ethics of AI
completely ignore the possibility of robots needing protection from their
creators. The present book chapter takes up this, less commonly considered,
ethical angle of AI.",['Shimon Edelman'],2023-03-13 19:36:16+00:00,2023-03-13 19:36:16+00:00,http://arxiv.org/pdf/2303.07439v1,cs.AI,['cs.AI']
Learning Human-Compatible Representations for Case-Based Decision Support,"Algorithmic case-based decision support provides examples to help human make
sense of predicted labels and aid human in decision-making tasks. Despite the
promising performance of supervised learning, representations learned by
supervised models may not align well with human intuitions: what models
consider as similar examples can be perceived as distinct by humans. As a
result, they have limited effectiveness in case-based decision support. In this
work, we incorporate ideas from metric learning with supervised learning to
examine the importance of alignment for effective decision support. In addition
to instance-level labels, we use human-provided triplet judgments to learn
human-compatible decision-focused representations. Using both synthetic data
and human subject experiments in multiple classification tasks, we demonstrate
that such representation is better aligned with human perception than
representation solely optimized for classification. Human-compatible
representations identify nearest neighbors that are perceived as more similar
by humans and allow humans to make more accurate predictions, leading to
substantial improvements in human decision accuracies (17.8% in butterfly vs.
moth classification and 13.2% in pneumonia classification).","['Han Liu', 'Yizhou Tian', 'Chacha Chen', 'Shi Feng', 'Yuxin Chen', 'Chenhao Tan']",2023-03-06 19:04:26+00:00,2023-03-06 19:04:26+00:00,http://arxiv.org/pdf/2303.04809v1,cs.LG,"['cs.LG', 'cs.AI', 'cs.CY', 'cs.HC']"
AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation,"In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed
(AAN) controller that utilizes reinforcement learning to supply adaptive
assistance during a robot assisted handwriting rehabilitation task. Unlike
previous AAN controllers, our method does not rely on patient specific
controller parameters or physical models. We propose the use of a virtual
patient model to generalize AR3n across multiple subjects. The system modulates
robotic assistance in realtime based on a subject's tracking error, while
minimizing the amount of robotic assistance. The controller is experimentally
validated through a set of simulations and human subject experiments. Finally,
a comparative study with a traditional rule-based controller is conducted to
analyze differences in assistance mechanisms of the two controllers.","['Shrey Pareek', 'Harris Nisar', 'Thenkurussi Kesavadas']",2023-02-28 21:04:05+00:00,2023-04-17 03:11:45+00:00,http://arxiv.org/pdf/2303.00085v4,cs.RO,"['cs.RO', 'cs.AI', 'cs.LG']"
Representational Tenets for Memory Athletics,"We describe the current state of world-class memory competitions, including
the methods used to prepare for and compete in memory competitions, based on
the subjective report of World Memory Championship Grandmaster and co-author
Nelson Dellis. We then explore the reported experiences through the lens of the
Simulated, Situated, and Structurally coherent Qualia (S3Q) theory of
consciousness, in order to propose a set of experiments to help further
understand the boundaries of expert memory performance.","['Kevin Schmidt', 'Othalia Larue', 'Ray Kulhanek', 'Dylan Flaute', 'Razvan Veliche', 'Christian Manasseh', 'Nelson Dellis', 'Scott Clouse', 'Jared Culbertson', 'Steve Rogers']",2023-02-22 19:40:59+00:00,2023-02-22 19:40:59+00:00,http://arxiv.org/pdf/2303.11944v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
The Full Rights Dilemma for A.I. Systems of Debatable Personhood,"An Artificially Intelligent system (an AI) has debatable personhood if it's
epistemically possible either that the AI is a person or that it falls far
short of personhood. Debatable personhood is a likely outcome of AI development
and might arise soon. Debatable AI personhood throws us into a catastrophic
moral dilemma: Either treat the systems as moral persons and risk sacrificing
real human interests for the sake of entities without interests worth the
sacrifice, or don't treat the systems as moral persons and risk perpetrating
grievous moral wrongs against them. The moral issues become even more
perplexing if we consider cases of possibly conscious AI that are subhuman,
superhuman, or highly divergent from us in their morally relevant properties.",['Eric Schwitzgebel'],2023-02-21 18:10:18+00:00,2023-02-21 18:10:18+00:00,http://arxiv.org/pdf/2303.17509v1,cs.CY,"['cs.CY', 'cs.AI']"
ChatGPT (Feb 13 Version) is a Chinese Room,"ChatGPT has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. This suggests that ChatGPT may pass Turing Test in the near
future. However, a computer program that passing Turing Test can either mean
that it is a Chinese Room or artificially conscious. Hence, the question of
whether the current state of ChatGPT is more of a Chinese Room or approaching
artificial consciousness remains. Here, I demonstrate that the current version
of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of
cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At
the same time, I demonstrate that ChatGPT can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. I also show that ChatGPT is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. It is likely that errors in causal reasoning leads to hallucinations.
More critically, ChatGPT generates false references to mimic real publications.
Therefore, its utility is cautioned.",['Maurice HT Ling'],2023-02-19 01:52:06+00:00,2023-02-19 01:52:06+00:00,http://arxiv.org/pdf/2304.12411v1,cs.CL,['cs.CL']
Ground(less) Truth: A Causal Framework for Proxy Labels in Human-Algorithm Decision-Making,"A growing literature on human-AI decision-making investigates strategies for
combining human judgment with statistical models to improve decision-making.
Research in this area often evaluates proposed improvements to models,
interfaces, or workflows by demonstrating improved predictive performance on
""ground truth"" labels. However, this practice overlooks a key difference
between human judgments and model predictions. Whereas humans reason about
broader phenomena of interest in a decision -- including latent constructs that
are not directly observable, such as disease status, the ""toxicity"" of online
comments, or future ""job performance"" -- predictive models target proxy labels
that are readily available in existing datasets. Predictive models' reliance on
simplistic proxies makes them vulnerable to various sources of statistical
bias. In this paper, we identify five sources of target variable bias that can
impact the validity of proxy labels in human-AI decision-making tasks. We
develop a causal framework to disentangle the relationship between each bias
and clarify which are of concern in specific human-AI decision-making tasks. We
demonstrate how our framework can be used to articulate implicit assumptions
made in prior modeling work, and we recommend evaluation strategies for
verifying whether these assumptions hold in practice. We then leverage our
framework to re-examine the designs of prior human subjects experiments that
investigate human-AI decision-making, finding that only a small fraction of
studies examine factors related to target variable bias. We conclude by
discussing opportunities to better address target variable bias in future
research.","['Luke Guerdan', 'Amanda Coston', 'Zhiwei Steven Wu', 'Kenneth Holstein']",2023-02-13 16:29:11+00:00,2023-05-25 21:40:56+00:00,http://arxiv.org/pdf/2302.06503v4,cs.CY,"['cs.CY', 'cs.AI', 'cs.HC']"
What is a Mathematical Structure of Conscious Experience?,"In consciousness science, several promising approaches have been developed
for how to represent conscious experience in terms of mathematical spaces and
structures. What is missing, however, is an explicit definition of what a
'mathematical structure of conscious experience' is. Here, we propose such a
definition. This definition provides a link between the abstract formal
entities of mathematics and the concreta of conscious experience; it
complements recent approaches that study quality spaces, qualia spaces or
phenomenal spaces; it provides a general method to identify and investigate
structures of conscious experience; and it may serve as a framework to unify
the various approaches from different fields. We hope that ultimately this work
provides a basis for developing a common formal language to study
consciousness.","['Johannes Kleiner', 'Tim Ludwig']",2023-01-26 15:25:19+00:00,2023-01-26 15:25:19+00:00,http://arxiv.org/pdf/2301.11812v1,q-bio.NC,"['q-bio.NC', '00A71']"
Towards the design of user-centric strategy recommendation systems for collaborative Human-AI tasks,"Artificial Intelligence is being employed by humans to collaboratively solve
complicated tasks for search and rescue, manufacturing, etc. Efficient teamwork
can be achieved by understanding user preferences and recommending different
strategies for solving the particular task to humans. Prior work has focused on
personalization of recommendation systems for relatively well-understood tasks
in the context of e-commerce or social networks. In this paper, we seek to
understand the important factors to consider while designing user-centric
strategy recommendation systems for decision-making. We conducted a
human-subjects experiment (n=60) for measuring the preferences of users with
different personality types towards different strategy recommendation systems.
We conducted our experiment across four types of strategy recommendation
modalities that have been established in prior work: (1) Single strategy
recommendation, (2) Multiple similar recommendations, (3) Multiple diverse
recommendations, (4) All possible strategies recommendations. While these
strategy recommendation schemes have been explored independently in prior work,
our study is novel in that we employ all of them simultaneously and in the
context of strategy recommendations, to provide us an in-depth overview of the
perception of different strategy recommendation systems. We found that certain
personality traits, such as conscientiousness, notably impact the preference
towards a particular type of system (p < 0.01). Finally, we report an
interesting relationship between usability, alignment and perceived
intelligence wherein greater perceived alignment of recommendations with one's
own preferences leads to higher perceived intelligence (p < 0.01) and higher
usability (p < 0.01).","['Lakshita Dodeja', 'Pradyumna Tambwekar', 'Erin Hedlund-Botti', 'Matthew Gombolay']",2023-01-17 17:53:27+00:00,2023-01-17 17:53:27+00:00,http://arxiv.org/pdf/2301.08144v1,cs.IR,"['cs.IR', 'cs.AI', 'cs.HC']"
Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making,"In AI-assisted decision-making, it is critical for human decision-makers to
know when to trust AI and when to trust themselves. However, prior studies
calibrated human trust only based on AI confidence indicating AI's correctness
likelihood (CL) but ignored humans' CL, hindering optimal team decision-making.
To mitigate this gap, we proposed to promote humans' appropriate trust based on
the CL of both sides at a task-instance level. We first modeled humans' CL by
approximating their decision-making models and computing their potential
performance in similar instances. We demonstrated the feasibility and
effectiveness of our model via two preliminary studies. Then, we proposed three
CL exploitation strategies to calibrate users' trust explicitly/implicitly in
the AI-assisted decision-making process. Results from a between-subjects
experiment (N=293) showed that our CL exploitation strategies promoted more
appropriate human trust in AI, compared with only using AI confidence. We
further provided practical implications for more human-compatible AI-assisted
decision-making.","['Shuai Ma', 'Ying Lei', 'Xinru Wang', 'Chengbo Zheng', 'Chuhan Shi', 'Ming Yin', 'Xiaojuan Ma']",2023-01-14 02:51:01+00:00,2023-01-14 02:51:01+00:00,http://arxiv.org/pdf/2301.05809v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.LG']"
Evaluating Human-Language Model Interaction,"Many real-world applications of language models (LMs), such as writing
assistance and code autocomplete, involve human-LM interaction. However, most
benchmarks are non-interactive in that a model produces output without human
involvement. To evaluate human-LM interaction, we develop a new framework,
Human-AI Language-based Interaction Evaluation (HALIE), that defines the
components of interactive systems and dimensions to consider when designing
evaluation metrics. Compared to standard, non-interactive evaluation, HALIE
captures (i) the interactive process, not only the final output; (ii) the
first-person subjective experience, not just a third-party assessment; and
(iii) notions of preference beyond quality (e.g., enjoyment and ownership). We
then design five tasks to cover different forms of interaction: social
dialogue, question answering, crossword puzzles, summarization, and metaphor
generation. With four state-of-the-art LMs (three variants of OpenAI's GPT-3
and AI21 Labs' Jurassic-1), we find that better non-interactive performance
does not always translate to better human-LM interaction. In particular, we
highlight three cases where the results from non-interactive and interactive
metrics diverge and underscore the importance of human-LM interaction for LM
evaluation.","['Mina Lee', 'Megha Srivastava', 'Amelia Hardy', 'John Thickstun', 'Esin Durmus', 'Ashwin Paranjape', 'Ines Gerard-Ursin', 'Xiang Lisa Li', 'Faisal Ladhak', 'Frieda Rong', 'Rose E. Wang', 'Minae Kwon', 'Joon Sung Park', 'Hancheng Cao', 'Tony Lee', 'Rishi Bommasani', 'Michael Bernstein', 'Percy Liang']",2022-12-19 18:59:45+00:00,2024-01-05 22:09:26+00:00,http://arxiv.org/pdf/2212.09746v5,cs.CL,['cs.CL']
Optimizing Integrated Information with a Prior Guided Random Search Algorithm,"Integrated information theory (IIT) is a theoretical framework that provides
a quantitative measure to estimate when a physical system is conscious, its
degree of consciousness, and the complexity of the qualia space that the system
is experiencing. Formally, IIT rests on the assumption that if a surrogate
physical system can fully embed the phenomenological properties of
consciousness, then the system properties must be constrained by the properties
of the qualia being experienced. Following this assumption, IIT represents the
physical system as a network of interconnected elements that can be thought of
as a probabilistic causal graph, $\mathcal{G}$, where each node has an
input-output function and all the graph is encoded in a transition probability
matrix. Consequently, IIT's quantitative measure of consciousness, $\Phi$, is
computed with respect to the transition probability matrix and the present
state of the graph. In this paper, we provide a random search algorithm that is
able to optimize $\Phi$ in order to investigate, as the number of nodes
increases, the structure of the graphs that have higher $\Phi$. We also provide
arguments that show the difficulties of applying more complex black-box search
algorithms, such as Bayesian optimization or metaheuristics, in this particular
problem. Additionally, we suggest specific research lines for these techniques
to enhance the search algorithm that guarantees maximal $\Phi$.","['Eduardo C. Garrido-Merchán', 'Javier Sánchez-Cañizares']",2022-12-08 22:34:00+00:00,2022-12-08 22:34:00+00:00,http://arxiv.org/pdf/2212.04589v1,cs.AI,['cs.AI']
The problem with AI consciousness: A neurogenetic case against synthetic sentience,"Ever since the creation of the first artificial intelligence (AI) machinery
built on machine learning (ML), public society has entertained the idea that
eventually computers could become sentient and develop a consciousness of their
own. As these models now get increasingly better and convincingly more
anthropomorphic, even some engineers have started to believe that AI might
become conscious, which would result in serious social consequences. The
present paper argues against the plausibility of sentient AI primarily based on
the theory of neurogenetic structuralism, which claims that the physiology of
biological neurons and their structural organization into complex brains are
necessary prerequisites for true consciousness to emerge.","['Yoshija Walter', 'Lukas Zbinden']",2022-12-07 14:46:38+00:00,2022-12-07 14:46:38+00:00,http://arxiv.org/pdf/2301.05397v1,cs.AI,"['cs.AI', 'cs.CY', 'q-bio.NC']"
NLP meets psychotherapy: Using predicted client emotions and self-reported client emotions to measure emotional coherence,"Emotions are experienced and expressed through various response systems.
Coherence between emotional experience and emotional expression is considered
important to clients' well being. To date, emotional coherence (EC) has been
studied at a single time point using lab-based tasks with relatively small
datasets. No study has examined EC between the subjective experience of
emotions and emotion expression in therapy or whether this coherence is
associated with clients' well being. Natural language Processing (NLP)
approaches have been applied to identify emotions from psychotherapy dialogue,
which can be implemented to study emotional processes on a larger scale.
However, these methods have yet to be used to study coherence between emotional
experience and emotional expression over the course of therapy and whether it
relates to clients' well-being. This work presents an end-to-end approach where
we use emotion predictions from our transformer based emotion recognition model
to study emotional coherence and its diagnostic potential in psychotherapy
research. We first employ our transformer based approach on a Hebrew
psychotherapy dataset to automatically label clients' emotions at utterance
level in psychotherapy dialogues. We subsequently investigate the emotional
coherence between clients' self-reported emotional states and our model-based
emotion predictions. We also examine the association between emotional
coherence and clients' well being. Our findings indicate a significant
correlation between clients' self-reported emotions and positive and negative
emotions expressed verbally during psychotherapy sessions. Coherence in
positive emotions was also highly correlated with clients well-being. These
results illustrate how NLP can be applied to identify important emotional
processes in psychotherapy to improve diagnosis and treatment for clients
suffering from mental-health problems.","['Neha Warikoo', 'Tobias Mayer', 'Dana Atzil-Slonim', 'Amir Eliassaf', 'Shira Haimovitz', 'Iryna Gurevych']",2022-11-22 14:28:41+00:00,2022-11-22 14:28:41+00:00,http://arxiv.org/pdf/2211.12512v1,cs.CL,"['cs.CL', 'cs.AI', 'cs.HC']"
The purpose of qualia: What if human thinking is not (only) information processing?,"Despite recent breakthroughs in the field of artificial intelligence (AI) -
or more specifically machine learning (ML) algorithms for object recognition
and natural language processing - it seems to be the majority view that current
AI approaches are still no real match for natural intelligence (NI). More
importantly, philosophers have collected a long catalogue of features which
imply that NI works differently from current AI not only in a gradual sense,
but in a more substantial way: NI is closely related to consciousness,
intentionality and experiential features like qualia (the subjective contents
of mental states) and allows for understanding (e.g., taking insight into
causal relationships instead of 'blindly' relying on correlations), as well as
aesthetical and ethical judgement beyond what we can put into (explicit or
data-induced implicit) rules to program machines with. Additionally,
Psychologists find NI to range from unconscious psychological processes to
focused information processing, and from embodied and implicit cognition to
'true' agency and creativity. NI thus seems to transcend any neurobiological
functionalism by operating on 'bits of meaning' instead of information in the
sense of data, quite unlike both the 'good old fashioned', symbolic AI of the
past, as well as the current wave of deep neural network based, 'sub-symbolic'
AI, which both share the idea of thinking as (only) information processing. In
the following I propose an alternative view of NI as information processing
plus 'bundle pushing', discuss an example which illustrates how bundle pushing
can cut information processing short, and suggest first ideas for scientific
experiments in neuro-biology and information theory as further investigations.",['Martin Korth'],2022-11-22 09:45:26+00:00,2022-12-06 12:35:56+00:00,http://arxiv.org/pdf/2212.00800v2,cs.AI,['cs.AI']
Concept-based Explanations using Non-negative Concept Activation Vectors and Decision Tree for CNN Models,"This paper evaluates whether training a decision tree based on concepts
extracted from a concept-based explainer can increase interpretability for
Convolutional Neural Networks (CNNs) models and boost the fidelity and
performance of the used explainer. CNNs for computer vision have shown
exceptional performance in critical industries. However, it is a significant
barrier when deploying CNNs due to their complexity and lack of
interpretability. Recent studies to explain computer vision models have shifted
from extracting low-level features (pixel-based explanations) to mid-or
high-level features (concept-based explanations). The current research
direction tends to use extracted features in developing approximation
algorithms such as linear or decision tree models to interpret an original
model. In this work, we modify one of the state-of-the-art concept-based
explanations and propose an alternative framework named TreeICE. We design a
systematic evaluation based on the requirements of fidelity (approximate models
to original model's labels), performance (approximate models to ground-truth
labels), and interpretability (meaningful of approximate models to humans). We
conduct computational evaluation (for fidelity and performance) and human
subject experiments (for interpretability) We find that Tree-ICE outperforms
the baseline in interpretability and generates more human readable explanations
in the form of a semantic tree structure. This work features how important to
have more understandable explanations when interpretability is crucial.","['Gayda Mutahar', 'Tim Miller']",2022-11-19 21:42:55+00:00,2022-11-19 21:42:55+00:00,http://arxiv.org/pdf/2211.10807v1,cs.CV,"['cs.CV', 'cs.AI']"
Node-wise Domain Adaptation Based on Transferable Attention for Recognizing Road Rage via EEG,"Road rage is a social problem that deserves attention, but little research
has been done so far. In this paper, based on the biological topology of
multi-channel EEG signals,we propose a model which combines transferable
attention (TA) and regularized graph neural network (RGNN). First,
topology-aware information aggregation is performed on EEG signals, and complex
relationships between channels are dynamically learned. Then, the
transferability of each channel is quantified based on the results of the
node-wise domain classifier, which is used as attention score. We recruited 10
subjects and collected their EEG signals in pleasure and rage state in
simulated driving conditions. We verify the effectiveness of our method on this
dataset and compare it with other methods. The results indicate that our method
is simple and efficient, with 85.63% accuracy in cross-subject experiments. It
can be used to identify road rage. Our data and code are available.
https://github.com/1CEc0ffee/dataAndCode.git","['Gao Xueqi', 'Xu Chao', 'Song Yihang', 'Hu Jing', 'Xiao Jian', 'Meng Zhaopeng']",2022-11-06 13:40:25+00:00,2022-11-06 13:40:25+00:00,http://arxiv.org/pdf/2212.02417v1,eess.SP,"['eess.SP', 'cs.LG']"
"Mathematical definition of public language, and modeling of will and consciousness based on the public language","To propose a mathematical model of consciousness and will, we first simulated
the inverted qualia with a toy model of a neural network. As a result, we
confirmed that there can be an inverted qualia on the neural network. In other
words, the qualia were individual-dependent and considered difficult as an
indicator of consciousness and will. To solve that difficulty, we introduce a
probability space and a random variable into a set of qualia and define a
public language for events. Based on this idea of public language,
consciousness and will are modeled. In this proposal, future actions are
randomly selected from the comparison between ""recognition of events"" by
external observation and past episodic memory, and the actual ""recognition of
actions"" is regarded as the occurrence of consciousness. The basic formula is
also derived. This proposal is compared with other past philosophical
discussions.","['Hana Hebishima', 'Mina Arakaki', 'Chikako Dozono', 'Hanna Frolova', 'Shinichi Inage']",2022-10-26 05:32:27+00:00,2022-10-26 05:32:27+00:00,http://arxiv.org/pdf/2210.14491v1,q-bio.NC,['q-bio.NC']
Quality of Life and the Experience of Context,"I propose that quality of life can be compared despite the difference in
values across cultures when it is experienced at the sensory and perceptual
level. I argue that an approach to assessing quality of life which focuses on
an individual's ability to organize his or her context by perceiving positive
constellations of factors in the environment and his or her ability to achieve
valuable acts and realize valuable states of being is more meaningful than the
approaches of metrics which focus directly, and often solely, on the means of
living and the means of freedom. Because the felt experience of quality of life
is derived from a constellation of factors which make up the indivisible
structure of a milieu, the experience of quality of life cannot be regarded as
a subjective experience. Through the example of how different frequencies, and
mixtures of frequencies, of light are perceived as colour by the eye, I
demonstrate that the human cognitive apparatus, because of its relation to the
object that is measured, apprehends different scales of quantity as degrees of
quality. I show that lived experience is the result of a selective
relationality with one's environment and that the experience of quality has
something to do with the perception of entities in their interrelated and
networked nature as wholes.",['Ankur Betageri'],2022-09-21 08:03:51+00:00,2024-02-04 07:30:04+00:00,http://arxiv.org/pdf/2210.03639v2,q-bio.NC,"['q-bio.NC', 'econ.GN', 'q-fin.EC']"
Compose & Embellish: Well-Structured Piano Performance Generation via A Two-Stage Approach,"Even with strong sequence models like Transformers, generating expressive
piano performances with long-range musical structures remains challenging.
Meanwhile, methods to compose well-structured melodies or lead sheets (melody +
chords), i.e., simpler forms of music, gained more success. Observing the
above, we devise a two-stage Transformer-based framework that Composes a lead
sheet first, and then Embellishes it with accompaniment and expressive touches.
Such a factorization also enables pretraining on non-piano data. Our objective
and subjective experiments show that Compose & Embellish shrinks the gap in
structureness between a current state of the art and real performances by half,
and improves other musical aspects such as richness and coherence as well.","['Shih-Lun Wu', 'Yi-Hsuan Yang']",2022-09-17 01:20:59+00:00,2023-03-07 14:19:17+00:00,http://arxiv.org/pdf/2209.08212v4,cs.SD,"['cs.SD', 'cs.AI', 'cs.MM', 'eess.AS']"
The Utility of Explainable AI in Ad Hoc Human-Machine Teaming,"Recent advances in machine learning have led to growing interest in
Explainable AI (xAI) to enable humans to gain insight into the decision-making
of machine learning models. Despite this recent interest, the utility of xAI
techniques has not yet been characterized in human-machine teaming.
Importantly, xAI offers the promise of enhancing team situational awareness
(SA) and shared mental model development, which are the key characteristics of
effective human-machine teams. Rapidly developing such mental models is
especially critical in ad hoc human-machine teaming, where agents do not have a
priori knowledge of others' decision-making strategies. In this paper, we
present two novel human-subject experiments quantifying the benefits of
deploying xAI techniques within a human-machine teaming scenario. First, we
show that xAI techniques can support SA ($p<0.05)$. Second, we examine how
different SA levels induced via a collaborative AI policy abstraction affect ad
hoc human-machine teaming performance. Importantly, we find that the benefits
of xAI are not universal, as there is a strong dependence on the composition of
the human-machine team. Novices benefit from xAI providing increased SA
($p<0.05$) but are susceptible to cognitive overhead ($p<0.05$). On the other
hand, expert performance degrades with the addition of xAI-based support
($p<0.05$), indicating that the cost of paying attention to the xAI outweighs
the benefits obtained from being provided additional information to enhance SA.
Our results demonstrate that researchers must deliberately design and deploy
the right xAI techniques in the right scenario by carefully considering
human-machine team composition and how the xAI method augments SA.","['Rohan Paleja', 'Muyleng Ghuy', 'Nadun Ranawaka Arachchige', 'Reed Jensen', 'Matthew Gombolay']",2022-09-08 17:35:59+00:00,2022-09-08 17:35:59+00:00,http://arxiv.org/pdf/2209.03943v1,cs.AI,"['cs.AI', 'cs.HC']"
Facilitating Global Team Meetings Between Language-Based Subgroups: When and How Can Machine Translation Help?,"Global teams frequently consist of language-based subgroups who put together
complementary information to achieve common goals. Previous research outlines a
two-step work communication flow in these teams. There are team meetings using
a required common language (i.e., English); in preparation for those meetings,
people have subgroup conversations in their native languages. Work
communication at team meetings is often less effective than in subgroup
conversations. In the current study, we investigate the idea of leveraging
machine translation (MT) to facilitate global team meetings. We hypothesize
that exchanging subgroup conversation logs before a team meeting offers
contextual information that benefits teamwork at the meeting. MT can translate
these logs, which enables comprehension at a low cost. To test our hypothesis,
we conducted a between-subjects experiment where twenty quartets of
participants performed a personnel selection task. Each quartet included two
English native speakers (NS) and two non-native speakers (NNS) whose native
language was Mandarin. All participants began the task with subgroup
conversations in their native languages, then proceeded to team meetings in
English. We manipulated the exchange of subgroup conversation logs prior to
team meetings: with MT-mediated exchanges versus without. Analysis of
participants' subjective experience, task performance, and depth of discussions
as reflected through their conversational moves jointly indicates that team
meeting quality improved when there were MT-mediated exchanges of subgroup
conversation logs as opposed to no exchanges. We conclude with reflections on
when and how MT could be applied to enhance global teamwork across a language
barrier.","['Yongle Zhang', 'Dennis Asamoah Owusu', 'Marine Carpuat', 'Ge Gao']",2022-09-07 03:31:25+00:00,2022-09-27 19:47:24+00:00,http://arxiv.org/pdf/2209.02906v2,cs.CL,"['cs.CL', 'cs.HC']"
Technology and Consciousness,"We report on a series of eight workshops held in the summer of 2017 on the
topic ""technology and consciousness."" The workshops covered many subjects but
the overall goal was to assess the possibility of machine consciousness, and
its potential implications. In the body of the report, we summarize most of the
basic themes that were discussed: the structure and function of the brain,
theories of consciousness, explicit attempts to construct conscious machines,
detection and measurement of consciousness, possible emergence of a conscious
technology, methods for control of such a technology and ethical considerations
that might be owed to it. An appendix outlines the topics of each workshop and
provides abstracts of the talks delivered.
  Update: Although this report was published in 2018 and the workshops it is
based on were held in 2017, recent events suggest that it is worth bringing
forward. In particular, in the Spring of 2022, a Google engineer claimed that
LaMDA, one of their ""large language models"" is sentient or even conscious. This
provoked a flurry of commentary in both the scientific and popular press, some
of it interesting and insightful, but almost all of it ignorant of the prior
consideration given to these topics and the history of research into machine
consciousness. Thus, we are making a lightly refreshed version of this report
available in the hope that it will provide useful background to the current
debate and will enable more informed commentary. Although this material is five
years old, its technical points remain valid and up to date, but we have
""refreshed"" it by adding a few footnotes highlighting recent developments.","['John Rushby', 'Daniel Sanchez']",2022-07-17 23:23:01+00:00,2022-07-17 23:23:01+00:00,http://arxiv.org/pdf/2209.03956v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
Inferring and Conveying Intentionality: Beyond Numerical Rewards to Logical Intentions,"Shared intentionality is a critical component in developing conscious AI
agents capable of collaboration, self-reflection, deliberation, and reasoning.
We formulate inference of shared intentionality as an inverse reinforcement
learning problem with logical reward specifications. We show how the approach
can infer task descriptions from demonstrations. We also extend our approach to
actively convey intentionality. We demonstrate the approach on a simple
grid-world example.","['Susmit Jha', 'John Rushby']",2022-07-06 21:46:16+00:00,2022-07-13 17:49:08+00:00,http://arxiv.org/pdf/2207.05058v2,cs.AI,"['cs.AI', 'q-bio.NC']"
Guiding Machine Perception with Psychophysics,"{G}{ustav} Fechner's 1860 delineation of psychophysics, the measurement of
sensation in relation to its stimulus, is widely considered to be the advent of
modern psychological science. In psychophysics, a researcher parametrically
varies some aspects of a stimulus, and measures the resulting changes in a
human subject's experience of that stimulus; doing so gives insight to the
determining relationship between a sensation and the physical input that evoked
it. This approach is used heavily in perceptual domains, including signal
detection, threshold measurement, and ideal observer analysis. Scientific
fields like vision science have always leaned heavily on the methods and
procedures of psychophysics, but there is now growing appreciation of them by
machine learning researchers, sparked by widening overlap between biological
and artificial perception \cite{rojas2011automatic,
scheirer2014perceptual,escalera2014chalearn,zhang2018agil,
grieggs2021measuring}. Machine perception that is guided by behavioral
measurements, as opposed to guidance restricted to arbitrarily assigned human
labels, has significant potential to fuel further progress in artificial
intelligence.","['Justin Dulay', 'Sonia Poltoratski', 'Till S. Hartmann', 'Samuel E. Anthony', 'Walter J. Scheirer']",2022-07-05 18:01:38+00:00,2022-07-05 18:01:38+00:00,http://arxiv.org/pdf/2207.02241v1,cs.CV,"['cs.CV', 'cs.LG', 'q-bio.NC']"
Vocalsound: A Dataset for Improving Human Vocal Sounds Recognition,"Recognizing human non-speech vocalizations is an important task and has broad
applications such as automatic sound transcription and health condition
monitoring. However, existing datasets have a relatively small number of vocal
sound samples or noisy labels. As a consequence, state-of-the-art audio event
classification models may not perform well in detecting human vocal sounds. To
support research on building robust and accurate vocal sound recognition, we
have created a VocalSound dataset consisting of over 21,000 crowdsourced
recordings of laughter, sighs, coughs, throat clearing, sneezes, and sniffs
from 3,365 unique subjects. Experiments show that the vocal sound recognition
performance of a model can be significantly improved by 41.9% by adding
VocalSound dataset to an existing dataset as training material. In addition,
different from previous datasets, the VocalSound dataset contains meta
information such as speaker age, gender, native language, country, and health
condition.","['Yuan Gong', 'Jin Yu', 'James Glass']",2022-05-06 18:08:18+00:00,2022-06-18 03:58:59+00:00,http://arxiv.org/pdf/2205.03433v2,cs.SD,"['cs.SD', 'cs.LG', 'eess.AS']"
Explicit and implicit measures of emotions: Data-science might help to account for data complexity and heterogeneity,"Measuring emotions is a real challenge for fundamental and applied research,
especially in ecological contexts. de Wijk and Noldus propose combining two
types of measures-explicit to characterize a specific food, and
implicit-physiological-to capture the whole experience of a meal in real-life
situations. This raises several challenges including development of new and
miniaturized sensors and devices but also developing new ways of data analysis.
We suggest a path to follow for future studies regarding data analysis: to
include Data Science in the game. This field of research may enable developing
predictive but also explicative models that link subjective experience of
emotions and physiological responses in real-life contexts. We suggest that
food scientists should go out of their comfort zone by collaborating with
computer scientists and then be trained with the new tools of Data Science,
which will undoubtedly enable them 1/ to better manage complex and
heterogeneous data sets, 2/ to extract knowledge that will be essential to this
field of research.","['M. Moranges', 'C. Rouby', 'M. Plantevit', 'M. Bensafi']",2022-05-04 08:16:58+00:00,2022-05-04 08:16:58+00:00,http://arxiv.org/pdf/2205.01939v1,q-bio.NC,['q-bio.NC']
On the Utility of Prediction Sets in Human-AI Teams,"Research on human-AI teams usually provides experts with a single label,
which ignores the uncertainty in a model's recommendation. Conformal prediction
(CP) is a well established line of research that focuses on building a
theoretically grounded, calibrated prediction set, which may contain multiple
labels. We explore how such prediction sets impact expert decision-making in
human-AI teams. Our evaluation on human subjects finds that set valued
predictions positively impact experts. However, we notice that the predictive
sets provided by CP can be very large, which leads to unhelpful AI assistants.
To mitigate this, we introduce D-CP, a method to perform CP on some examples
and defer to experts. We prove that D-CP can reduce the prediction set size of
non-deferred examples. We show how D-CP performs in quantitative and in human
subject experiments ($n=120$). Our results suggest that CP prediction sets
improve human-AI team performance over showing the top-1 prediction alone, and
that experts find D-CP prediction sets are more useful than CP prediction sets.","['Varun Babbar', 'Umang Bhatt', 'Adrian Weller']",2022-05-03 10:53:40+00:00,2022-05-26 12:43:37+00:00,http://arxiv.org/pdf/2205.01411v2,cs.AI,"['cs.AI', 'cs.HC']"
A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory,"This article provides an analytical framework for how to simulate human-like
thought processes within a computer. It describes how attention and memory
should be structured, updated, and utilized to search for associative additions
to the stream of thought. The focus is on replicating the dynamics of the
mammalian working memory system, which features two forms of persistent
activity: sustained firing (preserving information on the order of seconds) and
synaptic potentiation (preserving information from minutes to hours). The
article uses a series of figures to systematically demonstrate how the
iterative updating of these working memory stores provides functional
organization to behavior, cognition, and awareness.
  In a machine learning implementation, these two memory stores should be
updated continuously and in an iterative fashion. This means each state should
preserve a proportion of the coactive representations from the state before it
(where each representation is an ensemble of neural network nodes). This makes
each state a revised iteration of the preceding state and causes successive
configurations to overlap and blend with respect to the information they
contain. Thus, the set of concepts in working memory will evolve gradually and
incrementally over time. Transitions between states happen as persistent
activity spreads activation energy throughout the hierarchical network,
searching long-term memory for the most appropriate representation to be added
to the global workspace. The result is a chain of associatively linked
intermediate states capable of advancing toward a solution or goal. Iterative
updating is conceptualized here as an information processing strategy, a model
of working memory, a theory of consciousness, and an algorithm for designing
and programming artificial intelligence (AI, AGI, and ASI).",['Jared Edward Reser'],2022-03-29 22:28:30+00:00,2024-11-14 01:06:47+00:00,http://arxiv.org/pdf/2203.17255v7,q-bio.NC,"['q-bio.NC', 'cs.CL', 'cs.CV']"
Qualia as physical measurements: a mathematical model of qualia and pure concepts,"A space of qualia is defined to be a sober topological space whose points are
the qualia and whose open sets are the pure concepts in the sense of Lewis,
carrying additional algebraic structure that conveys the conscious experience
of subjective time and logical abstraction. This structure is analogous to that
of a space of physical measurements. It is conjectured that qualia and
measurements have the same nature, corresponding to fundamental processes via
which classical information is produced and physically stored, and that
therefore the hard problem of consciousness and the measurement problem are two
facets of the same problem. The space of qualia is independent from any
preexisting notions of spacetime and conscious agent, but its structure caters
for a derived geometric model of observer. Intersubjectivity is based on
relating different observers in a way that leads to a logical version of
quantum superposition.",['Pedro Resende'],2022-03-20 17:21:57+00:00,2022-03-20 17:21:57+00:00,http://arxiv.org/pdf/2203.10602v1,physics.hist-ph,"['physics.hist-ph', 'cs.AI', 'physics.soc-ph', 'q-bio.NC', 'quant-ph', '81P05 (Primary) 68T01, 91E10 (Secondary)']"
Extraction of Sleep Information from Clinical Notes of Patients with Alzheimer's Disease Using Natural Language Processing,"Alzheimer's Disease (AD) is the most common form of dementia in the United
States. Sleep is one of the lifestyle-related factors that has been shown
critical for optimal cognitive function in old age. However, there is a lack of
research studying the association between sleep and AD incidence. A major
bottleneck for conducting such research is that the traditional way to acquire
sleep information is time-consuming, inefficient, non-scalable, and limited to
patients' subjective experience. A gold standard dataset is created from manual
annotation of 570 randomly sampled clinical note documents from the adSLEEP, a
corpus of 192,000 de-identified clinical notes of 7,266 AD patients retrieved
from the University of Pittsburgh Medical Center (UPMC). We developed a
rule-based Natural Language Processing (NLP) algorithm, machine learning
models, and Large Language Model(LLM)-based NLP algorithms to automate the
extraction of sleep-related concepts, including snoring, napping, sleep
problem, bad sleep quality, daytime sleepiness, night wakings, and sleep
duration, from the gold standard dataset. Rule-based NLP algorithm achieved the
best performance of F1 across all sleep-related concepts. In terms of Positive
Predictive Value (PPV), rule-based NLP algorithm achieved 1.00 for daytime
sleepiness and sleep duration, machine learning models: 0.95 and for napping,
0.86 for bad sleep quality and 0.90 for snoring; and LLAMA2 with finetuning
achieved PPV of 0.93 for Night Wakings, 0.89 for sleep problem, and 1.00 for
sleep duration. The results show that the rule-based NLP algorithm consistently
achieved the best performance for all sleep concepts. This study focused on the
clinical notes of patients with AD, but could be extended to general sleep
information extraction for other diseases.","['Sonish Sivarajkumar', 'Thomas Yu CHow Tam', 'Haneef Ahamed Mohammad', 'Samual Viggiano', 'David Oniani', 'Shyam Visweswaran', 'Yanshan Wang']",2022-03-08 21:20:19+00:00,2024-03-15 17:59:17+00:00,http://arxiv.org/pdf/2204.09601v2,cs.CL,"['cs.CL', 'cs.AI']"
Improving Maximum Likelihood Difference Scaling method to measure inter content scale,"The goal of most subjective studies is to place a set of stimuli on a
perceptual scale. This is mostly done directly by rating, e.g. using single or
double stimulus methodologies, or indirectly by ranking or pairwise comparison.
All these methods estimate the perceptual magnitudes of the stimuli on a scale.
However, procedures such as Maximum Likelihood Difference Scaling (MLDS) have
shown that considering perceptual distances can bring benefits in terms of
discriminatory power, observers' cognitive load, and the number of trials
required. One of the disadvantages of the MLDS method is that the perceptual
scales obtained for stimuli created from different source content are generally
not comparable. In this paper, we propose an extension of the MLDS method that
ensures inter-content comparability of the results and shows its usefulness
especially in the presence of observer errors.","['Pastor Andréas', 'Lukáš Krasula', 'Xiaoqing Zhu', 'Zhi Li', 'Patrick Le Callet']",2022-02-25 08:35:32+00:00,2022-02-25 08:35:32+00:00,http://arxiv.org/pdf/2203.13186v1,q-bio.NC,"['q-bio.NC', 'cs.LG']"
Domain Adaptation in Neural Machine Translation using a Qualia-Enriched FrameNet,"In this paper we present Scylla, a methodology for domain adaptation of
Neural Machine Translation (NMT) systems that make use of a multilingual
FrameNet enriched with qualia relations as an external knowledge base. Domain
adaptation techniques used in NMT usually require fine-tuning and in-domain
training data, which may pose difficulties for those working with
lesser-resourced languages and may also lead to performance decay of the NMT
system for out-of-domain sentences. Scylla does not require fine-tuning of the
NMT model, avoiding the risk of model over-fitting and consequent decrease in
performance for out-of-domain translations. Two versions of Scylla are
presented: one using the source sentence as input, and another one using the
target sentence. We evaluate Scylla in comparison to a state-of-the-art
commercial NMT system in an experiment in which 50 sentences from the Sports
domain are translated from Brazilian Portuguese to English. The two versions of
Scylla significantly outperform the baseline commercial system in HTER.","['Alexandre Diniz Costa', 'Mateus Coutinho Marim', 'Ely Edison da Silva Matos', 'Tiago Timponi Torrent']",2022-02-21 15:05:23+00:00,2022-02-21 15:05:23+00:00,http://arxiv.org/pdf/2202.10287v1,cs.CL,"['cs.CL', 'E.1']"
The Effects of Interactive AI Design on User Behavior: An Eye-tracking Study of Fact-checking COVID-19 Claims,"We conducted a lab-based eye-tracking study to investigate how the
interactivity of an AI-powered fact-checking system affects user interactions,
such as dwell time, attention, and mental resources involved in using the
system. A within-subject experiment was conducted, where participants used an
interactive and a non-interactive version of a mock AI fact-checking system and
rated their perceived correctness of COVID-19 related claims. We collected
web-page interactions, eye-tracking data, and mental workload using NASA-TLX.
We found that the presence of the affordance of interactively manipulating the
AI system's prediction parameters affected users' dwell times, and
eye-fixations on AOIs, but not mental workload. In the interactive system,
participants spent the most time evaluating claims' correctness, followed by
reading news. This promising result shows a positive role of interactivity in a
mixed-initiative AI-powered system.","['Li Shi', 'Nilavra Bhattacharya', 'Anubrata Das', 'Matthew Lease', 'Jacek Gwidzka']",2022-02-17 21:08:57+00:00,2022-03-14 20:47:34+00:00,http://arxiv.org/pdf/2202.08901v2,cs.HC,"['cs.HC', 'cs.CL', 'cs.IR']"
Investigating the impact of free energy based behavior on human in human-agent interaction,"Humans communicate non-verbally by sharing physical rhythms, such as nodding
and gestures, to involve each other. This sharing of physicality creates a
sense of unity and makes humans feel involved with others. In this paper, we
developed a new body motion generation system based on the free-energy
principle (FEP), which not only responds passively but also prompts human
actions. The proposed system consists of two modules, the sampling module, and
the motion selection module. We conducted a subjective experiment to evaluate
the ""feeling of interacting with the agent"" of the FEP based behavior. The
results suggested that FEP based behaviors show more ""feeling of interacting
with the agent"". Furthermore, we confirmed that the agent's gestures elicited
subject gestures. This result not only reinforces the impression of feeling
interaction but could also realization of agents that encourage people to
change their behavior.","['Kazuya Horibe', 'Yuanxiang Fan', 'Yutaka Nakamura', 'Hiroshi Ishiguro']",2022-01-25 08:08:30+00:00,2022-01-25 08:08:30+00:00,http://arxiv.org/pdf/2201.10164v1,cs.HC,"['cs.HC', 'cs.LG']"
RAVE: A variational autoencoder for fast and high-quality neural audio synthesis,"Deep generative models applied to audio have improved by a large margin the
state-of-the-art in many speech and music related tasks. However, as raw
waveform modelling remains an inherently difficult task, audio generative
models are either computationally intensive, rely on low sampling rates, are
complicated to control or restrict the nature of possible signals. Among those
models, Variational AutoEncoders (VAE) give control over the generation by
exposing latent variables, although they usually suffer from low synthesis
quality. In this paper, we introduce a Realtime Audio Variational autoEncoder
(RAVE) allowing both fast and high-quality audio waveform synthesis. We
introduce a novel two-stage training procedure, namely representation learning
and adversarial fine-tuning. We show that using a post-training analysis of the
latent space allows a direct control between the reconstruction fidelity and
the representation compactness. By leveraging a multi-band decomposition of the
raw waveform, we show that our model is the first able to generate 48kHz audio
signals, while simultaneously running 20 times faster than real-time on a
standard laptop CPU. We evaluate synthesis quality using both quantitative and
qualitative subjective experiments and show the superiority of our approach
compared to existing models. Finally, we present applications of our model for
timbre transfer and signal compression. All of our source code and audio
examples are publicly available.","['Antoine Caillon', 'Philippe Esling']",2021-11-09 09:07:30+00:00,2021-12-15 16:42:14+00:00,http://arxiv.org/pdf/2111.05011v2,cs.LG,"['cs.LG', 'cs.SD', 'eess.AS']"
Dehumanizing Voice Technology: Phonetic & Experiential Consequences of Restricted Human-Machine Interaction,"The use of natural language and voice-based interfaces gradu-ally transforms
how consumers search, shop, and express their preferences. The current work
explores how changes in the syntactical structure of the interaction with
conversational interfaces (command vs. request based expression modalities)
negatively affects consumers' subjective task enjoyment and systematically
alters objective vocal features in the human voice. We show that requests (vs.
commands) lead to an in-crease in phonetic convergence and lower phonetic
latency, and ultimately a more natural task experience for consumers. To the
best of our knowledge, this is the first work docu-menting that altering the
input modality of how consumers interact with smart objects systematically
affects consumers' IoT experience. We provide evidence that altering the
required input to initiate a conversation with smart objects provokes
systematic changes both in terms of consumers' subjective experience and
objective phonetic changes in the human voice. The current research also makes
a methodological con-tribution by highlighting the unexplored potential of
feature extraction in human voice as a novel data format linking consumers'
vocal features during speech formation and their sub-jective task experiences.","['Christian Hildebrand', 'Donna Hoffman', 'Tom Novak']",2021-11-02 22:49:25+00:00,2021-11-02 22:49:25+00:00,http://arxiv.org/pdf/2111.01934v1,cs.AI,"['cs.AI', 'cs.HC']"
Chronic Pain and Language: A Topic Modelling Approach to Personal Pain Descriptions,"Chronic pain is recognized as a major health problem, with impacts not only
at the economic, but also at the social, and individual levels. Being a private
and subjective experience, it is impossible to externally and impartially
experience, describe, and interpret chronic pain as a purely noxious stimulus
that would directly point to a causal agent and facilitate its mitigation,
contrary to acute pain, the assessment of which is usually straightforward.
Verbal communication is, thus, key to convey relevant information to health
professionals that would otherwise not be accessible to external entities,
namely, intrinsic qualities about the painful experience and the patient. We
propose and discuss a topic modelling approach to recognize patterns in verbal
descriptions of chronic pain, and use these patterns to quantify and qualify
experiences of pain. Our approaches allow for the extraction of novel insights
on chronic pain experiences from the obtained topic models and latent spaces.
We argue that our results are clinically relevant for the assessment and
management of chronic pain.","['Diogo A. P. Nunes', 'Joana Ferreira Gomes', 'Fani Neto', 'David Martins de Matos']",2021-09-01 14:31:16+00:00,2022-03-17 13:52:47+00:00,http://arxiv.org/pdf/2109.00402v2,cs.CL,"['cs.CL', 'cs.IR', 'q-bio.QM', 'I.2.7; I.5.3; I.5.4; J.3; J.4']"
"Clustering of Pain Dynamics in Sickle Cell Disease from Sparse, Uneven Samples","Irregularly sampled time series data are common in a variety of fields. Many
typical methods for drawing insight from data fail in this case. Here we
attempt to generalize methods for clustering trajectories to irregularly and
sparsely sampled data. We first construct synthetic data sets, then propose and
assess four methods of data alignment to allow for application of spectral
clustering. We also repeat the same process for real data drawn from medical
records of patients with sickle cell disease -- patients whose subjective
experiences of pain were tracked for several months via a mobile app.
  We find that different methods for aligning irregularly sampled sparse data
sets can lead to different optimal numbers of clusters, even for synthetic data
with known properties. For the case of sickle cell disease, we find that three
clusters is a reasonable choice, and these appear to correspond to (1) a low
pain group with occasionally acute pain, (2) a group which experiences moderate
mean pain that fluctuates often from low to high, and (3) a group that
experiences persistent high levels of pain.
  Our results may help physicians and patients better understand and manage
patients' pain levels over time, and we expect that the methods we develop will
apply to a wide range of other data sources in medicine and beyond.","['Gary K. Nave Jr.', 'Swati Padhee', 'Amanuel Alambo', 'Tanvi Banerjee', 'Nirmish Shah', 'Daniel M. Abrams']",2021-08-31 16:43:57+00:00,2021-08-31 16:43:57+00:00,http://arxiv.org/pdf/2108.13963v1,q-bio.QM,"['q-bio.QM', 'cs.LG']"
PACE: Posthoc Architecture-Agnostic Concept Extractor for Explaining CNNs,"Deep CNNs, though have achieved the state of the art performance in image
classification tasks, remain a black-box to a human using them. There is a
growing interest in explaining the working of these deep models to improve
their trustworthiness. In this paper, we introduce a Posthoc
Architecture-agnostic Concept Extractor (PACE) that automatically extracts
smaller sub-regions of the image called concepts relevant to the black-box
prediction. PACE tightly integrates the faithfulness of the explanatory
framework to the black-box model. To the best of our knowledge, this is the
first work that extracts class-specific discriminative concepts in a posthoc
manner automatically. The PACE framework is used to generate explanations for
two different CNN architectures trained for classifying the AWA2 and
Imagenet-Birds datasets. Extensive human subject experiments are conducted to
validate the human interpretability and consistency of the explanations
extracted by PACE. The results from these experiments suggest that over 72% of
the concepts extracted by PACE are human interpretable.","['Vidhya Kamakshi', 'Uday Gupta', 'Narayanan C Krishnan']",2021-08-31 13:36:15+00:00,2021-08-31 13:36:15+00:00,http://arxiv.org/pdf/2108.13828v1,cs.CV,"['cs.CV', 'cs.AI']"
A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine,"The quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. We examine
consciousness from the perspective of theoretical computer science (TCS), a
branch of mathematics concerned with understanding the underlying principles of
computation and complexity, including the implications and surprising
consequences of resource limitations. In the spirit of Alan Turing's simple yet
powerful definition of a computer, the Turing Machine (TM), and perspective of
computational complexity theory, we formalize a modified version of the Global
Workspace Theory (GWT) of consciousness originated by cognitive neuroscientist
Bernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre
Changeaux and others. We are not looking for a complex model of the brain nor
of cognition, but for a simple computational model of (the admittedly complex
concept of) consciousness. We do this by defining the Conscious Turing Machine
(CTM), also called a conscious AI, and then we define consciousness and related
notions in the CTM. While these are only mathematical (TCS) definitions, we
suggest why the CTM has the feeling of consciousness. The TCS perspective
provides a simple formal framework to employ tools from computational
complexity theory and machine learning to help us understand consciousness and
related concepts. Previously we explored high level explanations for the
feelings of pain and pleasure in the CTM. Here we consider three examples
related to vision (blindsight, inattentional blindness, and change blindness),
followed by discussions of dreams, free will, and altered states of
consciousness.","['Lenore Blum', 'Manuel Blum']",2021-07-29 01:47:52+00:00,2022-07-05 17:48:40+00:00,http://arxiv.org/pdf/2107.13704v10,cs.AI,"['cs.AI', 'q-bio.NC', '68-02', 'I.2; F.0']"
Reasoning about conscious experience with axiomatic and graphical mathematics,"We cast aspects of consciousness in axiomatic mathematical terms, using the
graphical calculus of general process theories (a.k.a symmetric monoidal
categories and Frobenius algebras therein). This calculus exploits the
ontological neutrality of process theories. A toy example using the axiomatic
calculus is given to show the power of this approach, recovering other aspects
of conscious experience, such as external and internal subjective distinction,
privacy or unreadability of personal subjective experience, and phenomenal
unity, one of the main issues for scientific studies of consciousness. In fact,
these features naturally arise from the compositional nature of axiomatic
calculus.","['Camilo Miguel Signorelli', 'Quanlong Wang', 'Bob Coecke']",2021-06-30 13:39:02+00:00,2021-06-30 13:39:02+00:00,http://arxiv.org/pdf/2106.16061v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
Evaluation of Saliency-based Explainability Method,"A particular class of Explainable AI (XAI) methods provide saliency maps to
highlight part of the image a Convolutional Neural Network (CNN) model looks at
to classify the image as a way to explain its working. These methods provide an
intuitive way for users to understand predictions made by CNNs. Other than
quantitative computational tests, the vast majority of evidence to highlight
that the methods are valuable is anecdotal. Given that humans would be the
end-users of such methods, we devise three human subject experiments through
which we gauge the effectiveness of these saliency-based explainability
methods.","['Sam Zabdiel Sunder Samuel', 'Vidhya Kamakshi', 'Namrata Lodhi', 'Narayanan C Krishnan']",2021-06-24 05:40:50+00:00,2021-06-24 05:40:50+00:00,http://arxiv.org/pdf/2106.12773v1,cs.LG,['cs.LG']
ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for Phishing Prevention,"Attacks exploiting the innate and the acquired vulnerabilities of human users
have posed severe threats to cybersecurity. This work proposes ADVERT, a
human-technical solution that generates adaptive visual aids in real-time to
prevent users from inadvertence and reduce their susceptibility to phishing
attacks. Based on the eye-tracking data, we extract visual states and attention
states as system-level sufficient statistics to characterize the user's visual
behaviors and attention status. By adopting a data-driven approach and two
learning feedback of different time scales, this work lays out a theoretical
foundation to analyze, evaluate, and particularly modify humans' attention
processes while they vet and recognize phishing emails. We corroborate the
effectiveness, efficiency, and robustness of ADVERT through a case study based
on the data set collected from human subject experiments conducted at New York
University. The results show that the visual aids can statistically increase
the attention level and improve the accuracy of phishing recognition from 74.6%
to a minimum of 86%. The meta-adaptation can further improve the accuracy to
91.5% (resp. 93.7%) in less than 3 (resp. 50) tuning stages.","['Linan Huang', 'Shumeng Jia', 'Emily Balcetis', 'Quanyan Zhu']",2021-06-13 03:52:55+00:00,2022-07-08 23:16:17+00:00,http://arxiv.org/pdf/2106.06907v3,cs.HC,"['cs.HC', 'cs.AI', 'cs.SY', 'eess.SY']"
Conscious AI,"Recent advances in artificial intelligence (AI) have achieved human-scale
speed and accuracy for classification tasks. In turn, these capabilities have
made AI a viable replacement for many human activities that at their core
involve classification, such as basic mechanical and analytical tasks in
low-level service jobs. Current systems do not need to be conscious to
recognize patterns and classify them. However, for AI to progress to more
complicated tasks requiring intuition and empathy, it must develop capabilities
such as metathinking, creativity, and empathy akin to human self-awareness or
consciousness. We contend that such a paradigm shift is possible only through a
fundamental shift in the state of artificial intelligence toward consciousness,
a shift similar to what took place for humans through the process of natural
selection and evolution. As such, this paper aims to theoretically explore the
requirements for the emergence of consciousness in AI. It also provides a
principled understanding of how conscious AI can be detected and how it might
be manifested in contrast to the dominant paradigm that seeks to ultimately
create machines that are linguistically indistinguishable from humans.","['Hadi Esmaeilzadeh', 'Reza Vaezi']",2021-05-12 15:53:44+00:00,2022-05-20 21:27:08+00:00,http://arxiv.org/pdf/2105.07879v2,cs.AI,"['cs.AI', 'cs.CL', 'cs.CY']"
A Framework of Explanation Generation toward Reliable Autonomous Robots,"To realize autonomous collaborative robots, it is important to increase the
trust that users have in them. Toward this goal, this paper proposes an
algorithm which endows an autonomous agent with the ability to explain the
transition from the current state to the target state in a Markov decision
process (MDP). According to cognitive science, to generate an explanation that
is acceptable to humans, it is important to present the minimum information
necessary to sufficiently understand an event. To meet this requirement, this
study proposes a framework for identifying important elements in the
decision-making process using a prediction model for the world and generating
explanations based on these elements. To verify the ability of the proposed
method to generate explanations, we conducted an experiment using a grid
environment. It was inferred from the result of a simulation experiment that
the explanation generated using the proposed method was composed of the minimum
elements important for understanding the transition from the current state to
the target state. Furthermore, subject experiments showed that the generated
explanation was a good summary of the process of state transition, and that a
high evaluation was obtained for the explanation of the reason for an action.","['Tatsuya Sakai', 'Kazuki Miyazawa', 'Takato Horii', 'Takayuki Nagai']",2021-05-06 13:50:37+00:00,2021-05-06 13:50:37+00:00,http://arxiv.org/pdf/2105.02670v1,cs.AI,['cs.AI']
Trust-Aware Planning: Modeling Trust Evolution in Iterated Human-Robot Interaction,"Trust between team members is an essential requirement for any successful
cooperation. Thus, engendering and maintaining the fellow team members' trust
becomes a central responsibility for any member trying to not only successfully
participate in the task but to ensure the team achieves its goals. The problem
of trust management is particularly challenging in mixed human-robot teams
where the human and the robot may have different models about the task at hand
and thus may have different expectations regarding the current course of
action, thereby forcing the robot to focus on the costly explicable behavior.
We propose a computational model for capturing and modulating trust in such
iterated human-robot interaction settings, where the human adopts a supervisory
role. In our model, the robot integrates human's trust and their expectations
about the robot into its planning process to build and maintain trust over the
interaction horizon. By establishing the required level of trust, the robot can
focus on maximizing the team goal by eschewing explicit explanatory or
explicable behavior without worrying about the human supervisor monitoring and
intervening to stop behaviors they may not necessarily understand. We model
this reasoning about trust levels as a meta reasoning process over individual
planning tasks. We additionally validate our model through a human subject
experiment.","['Zahra Zahedi', 'Mudit Verma', 'Sarath Sreedharan', 'Subbarao Kambhampati']",2021-05-03 23:38:34+00:00,2023-03-05 01:39:20+00:00,http://arxiv.org/pdf/2105.01220v2,cs.AI,"['cs.AI', 'cs.RO']"
Bias-Aware Loss for Training Image and Speech Quality Prediction Models from Multiple Datasets,"The ground truth used for training image, video, or speech quality prediction
models is based on the Mean Opinion Scores (MOS) obtained from subjective
experiments. Usually, it is necessary to conduct multiple experiments, mostly
with different test participants, to obtain enough data to train quality models
based on machine learning. Each of these experiments is subject to an
experiment-specific bias, where the rating of the same file may be
substantially different in two experiments (e.g. depending on the overall
quality distribution). These different ratings for the same distortion levels
confuse neural networks during training and lead to lower performance. To
overcome this problem, we propose a bias-aware loss function that estimates
each dataset's biases during training with a linear function and considers it
while optimising the network weights. We prove the efficiency of the proposed
method by training and validating quality prediction models on synthetic and
subjective image and speech quality datasets.","['Gabriel Mittag', 'Saman Zadtootaghaj', 'Thilo Michael', 'Babak Naderi', 'Sebastian Möller']",2021-04-20 19:20:11+00:00,2021-04-20 19:20:11+00:00,http://arxiv.org/pdf/2104.10217v1,eess.AS,"['eess.AS', 'cs.LG', 'cs.SD', 'eess.IV']"
Concadia: Towards Image-Based Text Generation with a Purpose,"Current deep learning models often achieve excellent results on benchmark
image-to-text datasets but fail to generate texts that are useful in practice.
We argue that to close this gap, it is vital to distinguish descriptions from
captions based on their distinct communicative roles. Descriptions focus on
visual features and are meant to replace an image (often to increase
accessibility), whereas captions appear alongside an image to supply additional
information. To motivate this distinction and help people put it into practice,
we introduce the publicly available Wikipedia-based dataset Concadia consisting
of 96,918 images with corresponding English-language descriptions, captions,
and surrounding context. Using insights from Concadia, models trained on it,
and a preregistered human-subjects experiment with human- and model-generated
texts, we characterize the commonalities and differences between descriptions
and captions. In addition, we show that, for generating both descriptions and
captions, it is useful to augment image-to-text models with representations of
the textual context in which the image appeared.","['Elisa Kreiss', 'Fei Fang', 'Noah D. Goodman', 'Christopher Potts']",2021-04-16 21:25:00+00:00,2022-10-27 22:22:13+00:00,http://arxiv.org/pdf/2104.08376v3,cs.CL,['cs.CL']
To Trust or Not to Trust a Regressor: Estimating and Explaining Trustworthiness of Regression Predictions,"In hybrid human-AI systems, users need to decide whether or not to trust an
algorithmic prediction while the true error in the prediction is unknown. To
accommodate such settings, we introduce RETRO-VIZ, a method for (i) estimating
and (ii) explaining trustworthiness of regression predictions. It consists of
RETRO, a quantitative estimate of the trustworthiness of a prediction, and VIZ,
a visual explanation that helps users identify the reasons for the (lack of)
trustworthiness of a prediction. We find that RETRO-scores negatively correlate
with prediction error across 117 experimental settings, indicating that RETRO
provides a useful measure to distinguish trustworthy predictions from
untrustworthy ones. In a user study with 41 participants, we find that
VIZ-explanations help users identify whether a prediction is trustworthy or
not: on average, 95.1% of participants correctly select the more trustworthy
prediction, given a pair of predictions. In addition, an average of 75.6% of
participants can accurately describe why a prediction seems to be (not)
trustworthy. Finally, we find that the vast majority of users subjectively
experience RETRO-VIZ as a useful tool to assess the trustworthiness of
algorithmic predictions.","['Kim de Bie', 'Ana Lucic', 'Hinda Haned']",2021-04-14 17:04:20+00:00,2021-07-28 13:29:09+00:00,http://arxiv.org/pdf/2104.06982v2,cs.AI,['cs.AI']
"What Is Consciousness? Artificial Intelligence, Real Intelligence, Quantum Mind, And Qualia","We approach the question ""What is Consciousness?"" in a new way, not as
Descartes' ""systematic doubt"", but as how organisms find their way in their
world. Finding one's way involves finding possible uses of features of the
world that might be beneficial or avoiding those that might be harmful.
""Possible uses of X to accomplish Y"" are ""Affordances"". The number of uses of X
is indefinite (or unknown), the different uses are unordered, are not listable,
and are not deducible from one another. All biological adaptations are either
affordances seized by heritable variation and selection or, far faster, by the
organism acting in its world finding uses of X to accomplish Y. Based on this,
we reach rather astonishing conclusions: (1) Artificial general intelligence
based on universal Turing machines (UTMs) is not possible, since UTMs cannot
""find"" novel affordances. (2) Brain-mind is not purely classical physics for no
classical physics system can be an analogue computer whose dynamical behaviour
can be isomorphic to ""possible uses"". (3) Brain mind must be partly
quantum-supported by increasing evidence at 6.0 sigma to 7.3 sigma. (4) Based
on Heisenberg's interpretation of the quantum state as ""potentia"" converted to
""actuals"" by measurement, where this interpretation is not a substance dualism,
a natural hypothesis is that mind actualizes potentia. This is supported at 5.2
sigma. Then mind's actualizations of entangled brain-mind-world states are
experienced as qualia and allow ""seeing"" or ""perceiving"" of uses of X to
accomplish Y. We can and do jury-rig. Computers cannot. (5) Beyond familiar
quantum computers, we discuss the potentialities of trans-Turing-systems.","['Stuart A. Kauffman', 'Andrea Roli']",2021-04-12 11:20:21+00:00,2022-06-29 16:20:02+00:00,http://arxiv.org/pdf/2106.15515v4,physics.soc-ph,"['physics.soc-ph', 'cs.AI', 'physics.bio-ph', 'physics.hist-ph']"
The General Theory of General Intelligence: A Pragmatic Patternist Perspective,"A multi-decade exploration into the theoretical foundations of artificial and
natural general intelligence, which has been expressed in a series of books and
papers and used to guide a series of practical and research-prototype software
systems, is reviewed at a moderate level of detail. The review covers
underlying philosophies (patternist philosophy of mind, foundational
phenomenological and logical ontology), formalizations of the concept of
intelligence, and a proposed high level architecture for AGI systems partly
driven by these formalizations and philosophies. The implementation of specific
cognitive processes such as logical reasoning, program learning, clustering and
attention allocation in the context and language of this high level
architecture is considered, as is the importance of a common (e.g. typed
metagraph based) knowledge representation for enabling ""cognitive synergy""
between the various processes. The specifics of human-like cognitive
architecture are presented as manifestations of these general principles, and
key aspects of machine consciousness and machine ethics are also treated in
this context. Lessons for practical implementation of advanced AGI in
frameworks such as OpenCog Hyperon are briefly considered.",['Ben Goertzel'],2021-03-28 10:11:25+00:00,2021-04-04 04:30:42+00:00,http://arxiv.org/pdf/2103.15100v3,cs.AI,['cs.AI']
"What is it Like to Be a Bot: Simulated, Situated, Structurally Coherent Qualia (S3Q) Theory of Consciousness","A novel representationalist theory of consciousness is presented that is
grounded in neuroscience and provides a path to artificially conscious
computing. Central to the theory are representational affordances of the
conscious experience based on the generation of qualia, the fundamental unit of
the conscious representation. The current approach is focused on understanding
the balance of simulation, situatedness, and structural coherence of artificial
conscious representations through converging evidence from neuroscientific and
modeling experiments. Representations instantiating a suitable balance of
situated and structurally coherent simulation-based qualia are hypothesized to
afford the agent the flexibilities required to succeed in rapidly changing
environments.","['K. Schmidt', 'J. Culbertson', 'C. Cox', 'H. S. Clouse', 'O. Larue', 'M. Molineaux', 'S. Rogers']",2021-03-13 02:07:13+00:00,2021-03-13 02:07:13+00:00,http://arxiv.org/pdf/2103.12638v1,q-bio.NC,['q-bio.NC']
Analysis and Assessment of Controllability of an Expressive Deep Learning-based TTS system,"In this paper, we study the controllability of an Expressive TTS system
trained on a dataset for a continuous control. The dataset is the Blizzard 2013
dataset based on audiobooks read by a female speaker containing a great
variability in styles and expressiveness. Controllability is evaluated with
both an objective and a subjective experiment. The objective assessment is
based on a measure of correlation between acoustic features and the dimensions
of the latent space representing expressiveness. The subjective assessment is
based on a perceptual experiment in which users are shown an interface for
Controllable Expressive TTS and asked to retrieve a synthetic utterance whose
expressiveness subjectively corresponds to that a reference utterance.","['Noé Tits', 'Kevin El Haddad', 'Thierry Dutoit']",2021-03-06 11:06:13+00:00,2021-03-06 11:06:13+00:00,http://arxiv.org/pdf/2103.04097v1,cs.SD,"['cs.SD', 'cs.AI', 'cs.CL', 'cs.HC', 'eess.AS']"
Disambiguating Affective Stimulus Associations for Robot Perception and Dialogue,"Effectively recognising and applying emotions to interactions is a highly
desirable trait for social robots. Implicitly understanding how subjects
experience different kinds of actions and objects in the world is crucial for
natural HRI interactions, with the possibility to perform positive actions and
avoid negative actions. In this paper, we utilize the NICO robot's appearance
and capabilities to give the NICO the ability to model a coherent affective
association between a perceived auditory stimulus and a temporally asynchronous
emotion expression. This is done by combining evaluations of emotional valence
from vision and language. NICO uses this information to make decisions about
when to extend conversations in order to accrue more affective information if
the representation of the association is not coherent. Our primary contribution
is providing a NICO robot with the ability to learn the affective associations
between a perceived auditory stimulus and an emotional expression. NICO is able
to do this for both individual subjects and specific stimuli, with the aid of
an emotion-driven dialogue system that rectifies emotional expression
incoherences. The robot is then able to use this information to determine a
subject's enjoyment of perceived auditory stimuli in a real HRI scenario.","['Henrique Siqueira', 'Alexander Sutherland', 'Pablo Barros', 'Mattias Kerzel', 'Sven Magg', 'Stefan Wermter']",2021-03-05 20:55:48+00:00,2021-03-05 20:55:48+00:00,http://arxiv.org/pdf/2103.03940v1,cs.RO,"['cs.RO', 'cs.CL', 'cs.CV']"
Combat COVID-19 Infodemic Using Explainable Natural Language Processing Models,"Misinformation of COVID-19 is prevalent on social media as the pandemic
unfolds, and the associated risks are extremely high. Thus, it is critical to
detect and combat such misinformation. Recently, deep learning models using
natural language processing techniques, such as BERT (Bidirectional Encoder
Representations from Transformers), have achieved great successes in detecting
misinformation. In this paper, we proposed an explainable natural language
processing model based on DistilBERT and SHAP (Shapley Additive exPlanations)
to combat misinformation about COVID-19 due to their efficiency and
effectiveness. First, we collected a dataset of 984 claims about COVID-19 with
fact checking. By augmenting the data using back-translation, we doubled the
sample size of the dataset and the DistilBERT model was able to obtain good
performance (accuracy: 0.972; areas under the curve: 0.993) in detecting
misinformation about COVID-19. Our model was also tested on a larger dataset
for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good
performance (accuracy: 0.938; areas under the curve: 0.985). The performance on
both datasets was better than traditional machine learning models. Second, in
order to boost public trust in model prediction, we employed SHAP to improve
model explainability, which was further evaluated using a between-subjects
experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),
and text+SHAP explanation+source and evidence (TSESE). The participants were
significantly more likely to trust and share information related to COVID-19 in
the TSE and TSESE conditions than in the T condition. Our results provided good
implications in detecting misinformation about COVID-19 and improving public
trust.","['Jackie Ayoub', 'X. Jessie Yang', 'Feng Zhou']",2021-03-01 04:28:39+00:00,2021-03-01 04:28:39+00:00,http://arxiv.org/pdf/2103.00747v1,cs.CL,['cs.CL']
Visual explanation of black-box model: Similarity Difference and Uniqueness (SIDU) method,"Explainable Artificial Intelligence (XAI) has in recent years become a
well-suited framework to generate human understandable explanations of
""black-box"" models. In this paper, a novel XAI visual explanation algorithm
known as the Similarity Difference and Uniqueness (SIDU) method that can
effectively localize entire object regions responsible for prediction is
presented in full detail. The SIDU algorithm robustness and effectiveness is
analyzed through various computational and human subject experiments. In
particular, the SIDU algorithm is assessed using three different types of
evaluations (Application, Human and Functionally-Grounded) to demonstrate its
superior performance. The robustness of SIDU is further studied in the presence
of adversarial attack on ""black-box"" models to better understand its
performance. Our code is available at:
https://github.com/satyamahesh84/SIDU_XAI_CODE.","['Satya M. Muddamsetty', 'Mohammad N. S. Jahromi', 'Andreea E. Ciontos', 'Laura M. Fenoy', 'Thomas B. Moeslund']",2021-01-26 11:13:50+00:00,2022-07-10 18:07:56+00:00,http://arxiv.org/pdf/2101.10710v2,cs.CV,"['cs.CV', 'cs.AI', 'cs.HC', 'cs.LG']"
Occipital and left temporal instantaneous amplitude and frequency oscillations correlated with access and phenomenal consciousness,"Given the hard problem of consciousness (Chalmers, 1995) there are no brain
electrophysiological correlates of the subjective experience (the felt quality
of redness or the redness of red, the experience of dark and light, the quality
of depth in a visual field, the sound of a clarinet, the smell of mothball,
bodily sensations from pains to orgasms, mental images that are conjured up
internally, the felt quality of emotion, the experience of a stream of
conscious thought or the phenomenology of thought). However, there are brain
occipital and left temporal electrophysiological correlates of the subjective
experience (Pereira, 2015). Notwithstanding, as evoked signal, the change in
event-related brain potentials phase (frequency is the change in phase over
time) is instantaneous, that is, the frequency will transiently be infinite: a
transient peak in frequency (positive or negative), if any, is instantaneous in
electroencephalogram averaging or filtering that the event-related brain
potentials required and the underlying structure of the event-related brain
potentials in the frequency domain cannot be accounted, for example, by the
Wavelet Transform (WT) or the Fast Fourier Transform (FFT) analysis, because
they require that frequency is derived by convolution rather than by
differentiation. However, as I show in the current original research report,
one suitable method for analyse the instantaneous change in event-related brain
potentials phase and accounted for a transient peak in frequency (positive or
negative), if any, in the underlying structure of the event-related brain
potentials is the Empirical Mode Decomposition with post processing (Xie et
al., 2014) Ensemble Empirical Mode Decomposition (postEEMD) and Hilbert-Huang
Transform (HHT).",['Vitor Manuel Dinis Pereira'],2020-12-26 16:30:40+00:00,2021-03-05 18:36:30+00:00,http://arxiv.org/pdf/2101.10056v3,q-bio.NC,['q-bio.NC']
Digital me ontology and ethics,"This paper addresses ontology and ethics of an AI agent called digital me. We
define digital me as autonomous, decision-making, and learning agent,
representing an individual and having practically immortal own life. It is
assumed that digital me is equipped with the big-five personality model,
ensuring that it provides a model of some aspects of a strong AI:
consciousness, free will, and intentionality. As computer-based personality
judgments are more accurate than those made by humans, digital me can judge the
personality of the individual represented by the digital me, other individuals'
personalities, and other digital me-s. We describe seven ontological qualities
of digital me: a) double-layer status of Digital Being versus digital me, b)
digital me versus real me, c) mind-digital me and body-digital me, d) digital
me versus doppelganger (shadow digital me), e) non-human time concept, f)
social quality, g) practical immortality. We argue that with the advancement of
AI's sciences and technologies, there exist two digital me thresholds. The
first threshold defines digital me having some (rudimentarily) form of
consciousness, free will, and intentionality. The second threshold assumes that
digital me is equipped with moral learning capabilities, implying that, in
principle, digital me could develop their own ethics which significantly
differs from human's understanding of ethics. Finally we discuss the
implications of digital me metaethics, normative and applied ethics, the
implementation of the Golden Rule in digital me-s, and we suggest two sets of
normative principles for digital me: consequentialist and duty based digital me
principles.","['Ljupco Kocarev', 'Jasna Koteska']",2020-12-22 09:54:04+00:00,2020-12-22 09:54:04+00:00,http://arxiv.org/pdf/2012.14325v1,cs.AI,"['cs.AI', 'cs.CY']"
Invariant Feature Learning for Sensor-based Human Activity Recognition,"Wearable sensor-based human activity recognition (HAR) has been a research
focus in the field of ubiquitous and mobile computing for years. In recent
years, many deep models have been applied to HAR problems. However, deep
learning methods typically require a large amount of data for models to
generalize well. Significant variances caused by different participants or
diverse sensor devices limit the direct application of a pre-trained model to a
subject or device that has not been seen before. To address these problems, we
present an invariant feature learning framework (IFLF) that extracts common
information shared across subjects and devices. IFLF incorporates two learning
paradigms: 1) meta-learning to capture robust features across seen domains and
adapt to an unseen one with similarity-based data selection; 2) multi-task
learning to deal with data shortage and enhance overall performance via
knowledge sharing among different subjects. Experiments demonstrated that IFLF
is effective in handling both subject and device diversion across popular open
datasets and an in-house dataset. It outperforms a baseline model of up to 40%
in test accuracy.","['Yujiao Hao', 'Boyu Wang', 'Rong Zheng']",2020-12-14 21:56:17+00:00,2020-12-14 21:56:17+00:00,http://arxiv.org/pdf/2012.07963v1,eess.SP,"['eess.SP', 'cs.LG']"
Challenging common interpretability assumptions in feature attribution explanations,"As machine learning and algorithmic decision making systems are increasingly
being leveraged in high-stakes human-in-the-loop settings, there is a pressing
need to understand the rationale of their predictions. Researchers have
responded to this need with explainable AI (XAI), but often proclaim
interpretability axiomatically without evaluation. When these systems are
evaluated, they are often tested through offline simulations with proxy metrics
of interpretability (such as model complexity). We empirically evaluate the
veracity of three common interpretability assumptions through a large scale
human-subjects experiment with a simple ""placebo explanation"" control. We find
that feature attribution explanations provide marginal utility in our task for
a human decision maker and in certain cases result in worse decisions due to
cognitive and contextual confounders. This result challenges the assumed
universal benefit of applying these methods and we hope this work will
underscore the importance of human evaluation in XAI research. Supplemental
materials -- including anonymized data from the experiment, code to replicate
the study, an interactive demo of the experiment, and the models used in the
analysis -- can be found at: https://doi.pizza/challenging-xai.","['Jonathan Dinu', 'Jeffrey Bigham', 'J. Zico Kolter']",2020-12-04 17:57:26+00:00,2020-12-04 17:57:26+00:00,http://arxiv.org/pdf/2012.02748v1,cs.LG,"['cs.LG', 'cs.CY', 'cs.HC', 'J.4; I.5.1; K.4']"
An Artificial Consciousness Model and its relations with Philosophy of Mind,"This work seeks to study the beneficial properties that an autonomous agent
can obtain by implementing a cognitive architecture similar to the one of
conscious beings. Along this document, a conscious model of autonomous agent
based in a global workspace architecture is presented. We describe how this
agent is viewed from different perspectives of philosophy of mind, being
inspired by their ideas. The goal of this model is to create autonomous agents
able to navigate within an environment composed of multiple independent
magnitudes, adapting to its surroundings in order to find the best possible
position in base of its inner preferences. The purpose of the model is to test
the effectiveness of many cognitive mechanisms that are incorporated, such as
an attention mechanism for magnitude selection, pos-session of inner feelings
and preferences, usage of a memory system to storage beliefs and past
experiences, and incorporating a global workspace which controls and integrates
information processed by all the subsystem of the model. We show in a large
experiment set how an autonomous agent can benefit from having a cognitive
architecture such as the one described.","['Eduardo C. Garrido-Merchán', 'Martin Molina', 'Francisco M. Mendoza']",2020-11-30 00:24:17+00:00,2020-12-01 17:27:10+00:00,http://arxiv.org/pdf/2011.14475v2,cs.AI,['cs.AI']
A Theoretical Computer Science Perspective on Consciousness,"The quest to understand consciousness, once the purview of philosophers and
theologians, is now actively pursued by scientists of many stripes. This paper
studies consciousness from the perspective of theoretical computer science. It
formalizes the Global Workspace Theory (GWT) originated by cognitive
neuroscientist Bernard Baars and further developed by him, Stanislas Dehaene,
and others. Our major contribution lies in the precise formal definition of a
Conscious Turing Machine (CTM), also called a Conscious AI. We define the CTM
in the spirit of Alan Turing's simple yet powerful definition of a computer,
the Turing Machine (TM). We are not looking for a complex model of the brain
nor of cognition but for a simple model of (the admittedly complex concept of)
consciousness. After formally defining CTM, we give a formal definition of
consciousness in CTM. We then suggest why the CTM has the feeling of
consciousness. The reasonableness of the definitions and explanations can be
judged by how well they agree with commonly accepted intuitive concepts of
human consciousness, the breadth of related concepts that the model explains
easily and naturally, and the extent of its agreement with scientific evidence.","['Manuel Blum', 'Lenore Blum']",2020-11-18 11:28:37+00:00,2021-08-23 18:40:52+00:00,http://arxiv.org/pdf/2011.09850v4,cs.AI,"['cs.AI', '68T01, 68T40, 68242,', 'F.0; I.2']"
Detecting Synthetic Phenomenology in a Contained Artificial General Intelligence,"Human-like intelligence in a machine is a contentious subject. Whether
mankind should or should not pursue the creation of artificial general
intelligence is hotly debated. As well, researchers have aligned in opposing
factions according to whether mankind can create it. For our purposes, we
assume mankind can and will do so. Thus, it becomes necessary to contemplate
how to do so in a safe and trusted manner -- enter the idea of boxing or
containment. As part of such thinking, we wonder how a phenomenology might be
detected given the operational constraints imposed by any potential containment
system. Accordingly, this work provides an analysis of existing measures of
phenomenology through qualia and extends those ideas into the context of a
contained artificial general intelligence.","['Jason M. Pittman', 'Ashlyn Hanks']",2020-11-06 16:10:38+00:00,2020-11-06 16:10:38+00:00,http://arxiv.org/pdf/2011.05807v1,cs.CY,"['cs.CY', 'cs.AI']"
Minimizing Robot Navigation-Graph For Position-Based Predictability By Humans,"In situations where humans and robots are moving in the same space whilst
performing their own tasks, predictable paths taken by mobile robots can not
only make the environment feel safer, but humans can also help with the
navigation in the space by avoiding path conflicts or not blocking the way. So
predictable paths become vital. The cognitive effort for the human to predict
the robot's path becomes untenable as the number of robots increases. As the
number of humans increase, it also makes it harder for the robots to move while
considering the motion of multiple humans. Additionally, if new people are
entering the space -- like in restaurants, banks, and hospitals -- they would
have less familiarity with the trajectories typically taken by the robots; this
further increases the needs for predictable robot motion along paths.
  With this in mind, we propose to minimize the navigation-graph of the robot
for position-based predictability, which is predictability from just the
current position of the robot. This is important since the human cannot be
expected to keep track of the goals and prior actions of the robot in addition
to doing their own tasks. In this paper, we define measures for position-based
predictability, then present and evaluate a hill-climbing algorithm to minimize
the navigation-graph (directed graph) of robot motion. This is followed by the
results of our human-subject experiments which support our proposed
methodology.","['Sriram Gopalakrishnan', 'Subbarao Kambhampati']",2020-10-28 22:09:10+00:00,2022-01-11 23:28:57+00:00,http://arxiv.org/pdf/2010.15255v2,cs.AI,['cs.AI']
PPG-based singing voice conversion with adversarial representation learning,"Singing voice conversion (SVC) aims to convert the voice of one singer to
that of other singers while keeping the singing content and melody. On top of
recent voice conversion works, we propose a novel model to steadily convert
songs while keeping their naturalness and intonation. We build an end-to-end
architecture, taking phonetic posteriorgrams (PPGs) as inputs and generating
mel spectrograms. Specifically, we implement two separate encoders: one encodes
PPGs as content, and the other compresses mel spectrograms to supply acoustic
and musical information. To improve the performance on timbre and melody, an
adversarial singer confusion module and a mel-regressive representation
learning module are designed for the model. Objective and subjective
experiments are conducted on our private Chinese singing corpus. Comparing with
the baselines, our methods can significantly improve the conversion performance
in terms of naturalness, melody, and voice similarity. Moreover, our PPG-based
method is proved to be robust for noisy sources.","['Zhonghao Li', 'Benlai Tang', 'Xiang Yin', 'Yuan Wan', 'Ling Xu', 'Chen Shen', 'Zejun Ma']",2020-10-28 08:03:27+00:00,2020-10-28 08:03:27+00:00,http://arxiv.org/pdf/2010.14804v1,cs.SD,"['cs.SD', 'cs.CL', 'eess.AS']"
Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?,"Data collection for natural language (NL) understanding tasks has
increasingly included human explanations alongside data points, allowing past
works to introduce models that both perform a task and generate NL explanations
for their outputs. Yet to date, model-generated explanations have been
evaluated on the basis of surface-level similarities to human explanations,
both through automatic metrics like BLEU and human evaluations. We argue that
these evaluations are insufficient, since they fail to indicate whether
explanations support actual model behavior (faithfulness), rather than simply
match what a human would say (plausibility). In this work, we address the
problem of evaluating explanations from the model simulatability perspective.
Our contributions are as follows: (1) We introduce a leakage-adjusted
simulatability (LAS) metric for evaluating NL explanations, which measures how
well explanations help an observer predict a model's output, while controlling
for how explanations can directly leak the output. We use a model as a proxy
for a human observer, and validate this choice with two human subject
experiments. (2) Using the CoS-E and e-SNLI datasets, we evaluate two existing
generative graphical models and two new approaches; one rationalizing method we
introduce achieves roughly human-level LAS scores. (3) Lastly, we frame
explanation generation as a multi-agent game and optimize explanations for
simulatability while penalizing label leakage, which can improve LAS scores. We
provide code for the experiments in this paper at
https://github.com/peterbhase/LAS-NL-Explanations","['Peter Hase', 'Shiyue Zhang', 'Harry Xie', 'Mohit Bansal']",2020-10-08 16:59:07+00:00,2020-10-08 16:59:07+00:00,http://arxiv.org/pdf/2010.04119v1,cs.CL,"['cs.CL', 'cs.AI', 'cs.LG']"
A Blast From the Past: Personalizing Predictions of Video-Induced Emotions using Personal Memories as Context,"A key challenge in the accurate prediction of viewers' emotional responses to
video stimuli in real-world applications is accounting for person- and
situation-specific variation. An important contextual influence shaping
individuals' subjective experience of a video is the personal memories that it
triggers in them. Prior research has found that this memory influence explains
more variation in video-induced emotions than other contextual variables
commonly used for personalizing predictions, such as viewers' demographics or
personality. In this article, we show that (1) automatic analysis of text
describing their video-triggered memories can account for variation in viewers'
emotional responses, and (2) that combining such an analysis with that of a
video's audiovisual content enhances the accuracy of automatic predictions. We
discuss the relevance of these findings for improving on state of the art
approaches to automated affective video analysis in personalized contexts.","['Bernd Dudzik', 'Joost Broekens', 'Mark Neerincx', 'Hayley Hung']",2020-08-27 13:06:10+00:00,2020-08-27 13:06:10+00:00,http://arxiv.org/pdf/2008.12096v1,cs.HC,"['cs.HC', 'cs.AI']"
On the Evolution of Subjective Experience,"Subjective Experience (SE) is part of the ancient mind-body problem, which
continues to be one of deepest mysteries of science. Despite major advances in
many fields, there is still no plausible causal link between SE and its
realization in the body. The core issue is the incompatibility of objective
(3rd person) public science with subjective (1st person) private experience.
Any scientific approach to SE assumes that it arose from extended evolutionary
processes and that examining evolutionary history should help us understand it.
While the core mystery remains, converging evidence from theoretical,
experimental, and computational studies yields strong constraints on SE and
some suggestions for further research. All animals confront many of the same
fitness challenges. They all need some kind of internal model to relate their
life goals and actionable sensed information to action. We understand the
evolution of the bodily aspects of human perception and emotion, but not the
SE. The first evolutionary evidence for SE appears in vertebrates and much of
its neural substrate and simulation mechanism is preserved in mammals and
humans. People exhibit the same phenomena, but there are remaining mysteries of
everyday experience that are demonstrably incompatible with current
neuroscience. In spite of this limitation, there is considerable progress on
understanding the role of SE in the success of prostheses.",['Jerome A. Feldman'],2020-08-18 17:54:39+00:00,2022-03-25 18:16:35+00:00,http://arxiv.org/pdf/2008.08073v3,q-bio.NC,"['q-bio.NC', 'cs.NE', 'q-bio.PE']"
Sequence-to-Sequence Predictive Model: From Prosody To Communicative Gestures,"Communicative gestures and speech acoustic are tightly linked. Our objective
is to predict the timing of gestures according to the acoustic. That is, we
want to predict when a certain gesture occurs. We develop a model based on a
recurrent neural network with attention mechanism. The model is trained on a
corpus of natural dyadic interaction where the speech acoustic and the gesture
phases and types have been annotated. The input of the model is a sequence of
speech acoustic and the output is a sequence of gesture classes. The classes we
are using for the model output is based on a combination of gesture phases and
gesture types. We use a sequence comparison technique to evaluate the model
performance. We find that the model can predict better certain gesture classes
than others. We also perform ablation studies which reveal that fundamental
frequency is a relevant feature for gesture prediction task. In another
sub-experiment, we find that including eyebrow movements as acting as beat
gesture improves the performance. Besides, we also find that a model trained on
the data of one given speaker also works for the other speaker of the same
conversation. We also perform a subjective experiment to measure how
respondents judge the naturalness, the time consistency, and the semantic
consistency of the generated gesture timing of a virtual agent. Our respondents
rate the output of our model favorably.","['Fajrian Yunus', 'Chloé Clavel', 'Catherine Pelachaud']",2020-08-17 21:55:22+00:00,2021-04-23 21:03:40+00:00,http://arxiv.org/pdf/2008.07643v2,cs.HC,"['cs.HC', 'cs.CL', 'cs.CV', 'cs.SD', 'eess.AS']"
Whole-brain models to explore altered states of consciousness from the bottom up,"The scope of human consciousness includes states departing from what most of
us experience as ordinary wakefulness. These altered states of consciousness
constitute a prime opportunity to study how global changes in brain activity
relate to different varieties of subjective experience. We consider the problem
of explaining how global signatures of altered consciousness arise from the
interplay between large-scale connectivity and local dynamical rules that can
be traced to known properties of neural tissue. For this purpose, we advocate a
research program aimed at bridging the gap between bottom-up generative models
of whole-brain activity and the top-down signatures proposed by theories of
consciousness. Throughout this paper, we define altered states of
consciousness, discuss relevant signatures of consciousness observed in brain
activity, and introduce whole-brain models to explore the mechanisms of altered
consciousness from the bottom-up. We discuss the potential of our proposal in
view of the current state of the art, give specific examples of how this
research agenda might play out, and emphasise how a systematic investigation of
altered states of consciousness via bottom-up modelling may help us better
understand the biophysical, informational, and dynamical underpinnings of
consciousness.","['Rodrigo Cofré', 'Rubén Herzog', 'Pedro A. M. Mediano', 'Juan Piccinini', 'Fernando E. Rosas', 'Yonatan Sanz Perl', 'Enzo Tagliazucchi']",2020-08-06 17:54:37+00:00,2020-08-06 17:54:37+00:00,http://arxiv.org/pdf/2008.02788v1,q-bio.NC,['q-bio.NC']
Enabling Morally Sensitive Robotic Clarification Requests,"The design of current natural language oriented robot architectures enables
certain architectural components to circumvent moral reasoning capabilities.
One example of this is reflexive generation of clarification requests as soon
as referential ambiguity is detected in a human utterance. As shown in previous
research, this can lead robots to (1) miscommunicate their moral dispositions
and (2) weaken human perception or application of moral norms within their
current context. We present a solution to these problems by performing moral
reasoning on each potential disambiguation of an ambiguous human utterance and
responding accordingly, rather than immediately and naively requesting
clarification. We implement our solution in the DIARC robot architecture,
which, to our knowledge, is the only current robot architecture with both moral
reasoning and clarification request generation capabilities. We then evaluate
our method with a human subjects experiment, the results of which indicate that
our approach successfully ameliorates the two identified concerns.","['Ryan Blake Jackson', 'Tom Williams']",2020-07-16 22:12:35+00:00,2020-07-16 22:12:35+00:00,http://arxiv.org/pdf/2007.08670v1,cs.AI,"['cs.AI', 'cs.CL', 'cs.CY', 'cs.RO']"
Human-Robot Team Coordination with Dynamic and Latent Human Task Proficiencies: Scheduling with Learning Curves,"As robots become ubiquitous in the workforce, it is essential that
human-robot collaboration be both intuitive and adaptive. A robot's quality
improves based on its ability to explicitly reason about the time-varying (i.e.
learning curves) and stochastic capabilities of its human counterparts, and
adjust the joint workload to improve efficiency while factoring human
preferences. We introduce a novel resource coordination algorithm that enables
robots to explore the relative strengths and learning abilities of their human
teammates, by constructing schedules that are robust to stochastic and
time-varying human task performance. We first validate our algorithmic approach
using data we collected from a user study (n = 20), showing we can quickly
generate and evaluate a robust schedule while discovering the latest individual
worker proficiency. Second, we conduct a between-subjects experiment (n = 90)
to validate the efficacy of our coordinating algorithm. Results from the
human-subjects experiment indicate that scheduling strategies favoring
exploration tend to be beneficial for human-robot collaboration as it improves
team fluency (p = 0.0438), while also maximizing team efficiency (p < 0.001).","['Ruisen Liu', 'Manisha Natarajan', 'Matthew Gombolay']",2020-07-03 19:44:22+00:00,2020-07-09 02:40:57+00:00,http://arxiv.org/pdf/2007.01921v2,cs.RO,"['cs.RO', 'cs.AI', 'cs.HC', 'cs.SY', 'eess.SY']"
The Impact of Explanations on AI Competency Prediction in VQA,"Explainability is one of the key elements for building trust in AI systems.
Among numerous attempts to make AI explainable, quantifying the effect of
explanations remains a challenge in conducting human-AI collaborative tasks.
Aside from the ability to predict the overall behavior of AI, in many
applications, users need to understand an AI agent's competency in different
aspects of the task domain. In this paper, we evaluate the impact of
explanations on the user's mental model of AI agent competency within the task
of visual question answering (VQA). We quantify users' understanding of
competency, based on the correlation between the actual system performance and
user rankings. We introduce an explainable VQA system that uses spatial and
object features and is powered by the BERT language model. Each group of users
sees only one kind of explanation to rank the competencies of the VQA model.
The proposed model is evaluated through between-subject experiments to probe
explanations' impact on the user's perception of competency. The comparison
between two VQA models shows BERT based explanations and the use of object
features improve the user's prediction of the model's competencies.","['Kamran Alipour', 'Arijit Ray', 'Xiao Lin', 'Jurgen P. Schulze', 'Yi Yao', 'Giedrius T. Burachas']",2020-07-02 06:11:28+00:00,2020-07-02 06:11:28+00:00,http://arxiv.org/pdf/2007.00900v1,cs.CV,"['cs.CV', 'cs.AI', 'cs.HC']"
Invertible Concept-based Explanations for CNN Models with Non-negative Concept Activation Vectors,"Convolutional neural network (CNN) models for computer vision are powerful
but lack explainability in their most basic form. This deficiency remains a key
challenge when applying CNNs in important domains. Recent work on explanations
through feature importance of approximate linear models has moved from
input-level features (pixels or segments) to features from mid-layer feature
maps in the form of concept activation vectors (CAVs). CAVs contain
concept-level information and could be learned via clustering. In this work, we
rethink the ACE algorithm of Ghorbani et~al., proposing an alternative
invertible concept-based explanation (ICE) framework to overcome its
shortcomings. Based on the requirements of fidelity (approximate models to
target models) and interpretability (being meaningful to people), we design
measurements and evaluate a range of matrix factorization methods with our
framework. We find that non-negative concept activation vectors (NCAVs) from
non-negative matrix factorization provide superior performance in
interpretability and fidelity based on computational and human subject
experiments. Our framework provides both local and global concept-level
explanations for pre-trained CNN models.","['Ruihan Zhang', 'Prashan Madumal', 'Tim Miller', 'Krista A. Ehinger', 'Benjamin I. P. Rubinstein']",2020-06-27 17:57:26+00:00,2021-06-17 12:31:21+00:00,http://arxiv.org/pdf/2006.15417v4,cs.CV,"['cs.CV', 'cs.AI', 'cs.LG']"
Speaker Independent and Multilingual/Mixlingual Speech-Driven Talking Head Generation Using Phonetic Posteriorgrams,"Generating 3D speech-driven talking head has received more and more attention
in recent years. Recent approaches mainly have following limitations: 1) most
speaker-independent methods need handcrafted features that are time-consuming
to design or unreliable; 2) there is no convincing method to support
multilingual or mixlingual speech as input. In this work, we propose a novel
approach using phonetic posteriorgrams (PPG). In this way, our method doesn't
need hand-crafted features and is more robust to noise compared to recent
approaches. Furthermore, our method can support multilingual speech as input by
building a universal phoneme space. As far as we know, our model is the first
to support multilingual/mixlingual speech as input with convincing results.
Objective and subjective experiments have shown that our model can generate
high quality animations given speech from unseen languages or speakers and be
robust to noise.","['Huirong Huang', 'Zhiyong Wu', 'Shiyin Kang', 'Dongyang Dai', 'Jia Jia', 'Tianxiao Fu', 'Deyi Tuo', 'Guangzhi Lei', 'Peng Liu', 'Dan Su', 'Dong Yu', 'Helen Meng']",2020-06-20 16:32:43+00:00,2020-06-20 16:32:43+00:00,http://arxiv.org/pdf/2006.11610v1,eess.AS,"['eess.AS', 'cs.LG', 'cs.MM', 'cs.SD']"
HiFi-GAN: High-Fidelity Denoising and Dereverberation Based on Speech Deep Features in Adversarial Networks,"Real-world audio recordings are often degraded by factors such as noise,
reverberation, and equalization distortion. This paper introduces HiFi-GAN, a
deep learning method to transform recorded speech to sound as though it had
been recorded in a studio. We use an end-to-end feed-forward WaveNet
architecture, trained with multi-scale adversarial discriminators in both the
time domain and the time-frequency domain. It relies on the deep feature
matching losses of the discriminators to improve the perceptual quality of
enhanced speech. The proposed model generalizes well to new speakers, new
speech content, and new environments. It significantly outperforms
state-of-the-art baseline methods in both objective and subjective experiments.","['Jiaqi Su', 'Zeyu Jin', 'Adam Finkelstein']",2020-06-10 07:24:39+00:00,2020-09-21 20:37:02+00:00,http://arxiv.org/pdf/2006.05694v2,eess.AS,"['eess.AS', 'cs.LG', 'cs.SD']"
Tradeoff-Focused Contrastive Explanation for MDP Planning,"End-users' trust in automated agents is important as automated
decision-making and planning is increasingly used in many aspects of people's
lives. In real-world applications of planning, multiple optimization objectives
are often involved. Thus, planning agents' decisions can involve complex
tradeoffs among competing objectives. It can be difficult for the end-users to
understand why an agent decides on a particular planning solution on the basis
of its objective values. As a result, the users may not know whether the agent
is making the right decisions, and may lack trust in it. In this work, we
contribute an approach, based on contrastive explanation, that enables a
multi-objective MDP planning agent to explain its decisions in a way that
communicates its tradeoff rationale in terms of the domain-level concepts. We
conduct a human subjects experiment to evaluate the effectiveness of our
explanation approach in a mobile robot navigation domain. The results show that
our approach significantly improves the users' understanding, and confidence in
their understanding, of the tradeoff rationale of the planning agent.","['Roykrong Sukkerd', 'Reid Simmons', 'David Garlan']",2020-04-27 17:17:58+00:00,2020-08-02 16:07:02+00:00,http://arxiv.org/pdf/2004.12960v2,cs.HC,"['cs.HC', 'cs.AI']"
ConsciousControlFlow(CCF): A Demonstration for conscious Artificial Intelligence,"In this demo, we present ConsciousControlFlow(CCF), a prototype system to
demonstrate conscious Artificial Intelligence (AI). The system is based on the
computational model for consciousness and the hierarchy of needs. CCF supports
typical scenarios to show the behaviors and the mental activities of conscious
AI. We demonstrate that CCF provides a useful tool for effective machine
consciousness demonstration and human behavior study assistance.","['Hongzhi Wang', 'Bozhou Chen', 'Yueyang Xu', 'Kaixin Zhang', 'Shengwen Zheng']",2020-04-09 06:28:26+00:00,2021-02-06 02:43:24+00:00,http://arxiv.org/pdf/2004.04376v2,cs.AI,['cs.AI']
A Study on Multimodal and Interactive Explanations for Visual Question Answering,"Explainability and interpretability of AI models is an essential factor
affecting the safety of AI. While various explainable AI (XAI) approaches aim
at mitigating the lack of transparency in deep networks, the evidence of the
effectiveness of these approaches in improving usability, trust, and
understanding of AI systems are still missing. We evaluate multimodal
explanations in the setting of a Visual Question Answering (VQA) task, by
asking users to predict the response accuracy of a VQA agent with and without
explanations. We use between-subjects and within-subjects experiments to probe
explanation effectiveness in terms of improving user prediction accuracy,
confidence, and reliance, among other factors. The results indicate that the
explanations help improve human prediction accuracy, especially in trials when
the VQA system's answer is inaccurate. Furthermore, we introduce active
attention, a novel method for evaluating causal attentional effects through
intervention by editing attention maps. User explanation ratings are strongly
correlated with human prediction accuracy and suggest the efficacy of these
explanations in human-machine AI collaboration tasks.","['Kamran Alipour', 'Jurgen P. Schulze', 'Yi Yao', 'Avi Ziskind', 'Giedrius Burachas']",2020-03-01 07:54:01+00:00,2020-03-01 07:54:01+00:00,http://arxiv.org/pdf/2003.00431v1,cs.AI,['cs.AI']
Learn Task First or Learn Human Partner First: A Hierarchical Task Decomposition Method for Human-Robot Cooperation,"Applying Deep Reinforcement Learning (DRL) to Human-Robot Cooperation (HRC)
in dynamic control problems is promising yet challenging as the robot needs to
learn the dynamics of the controlled system and dynamics of the human partner.
In existing research, the robot powered by DRL adopts coupled observation of
the environment and the human partner to learn both dynamics simultaneously.
However, such a learning strategy is limited in terms of learning efficiency
and team performance. This work proposes a novel task decomposition method with
a hierarchical reward mechanism that enables the robot to learn the
hierarchical dynamic control task separately from learning the human partner's
behavior. The method is validated with a hierarchical control task in a
simulated environment with human subject experiments. Our method also provides
insight into the design of the learning strategy for HRC. The results show that
the robot should learn the task first to achieve higher team performance and
learn the human first to achieve higher learning efficiency.","['Lingfeng Tao', 'Michael Bowman', 'Jiucai Zhang', 'Xiaoli Zhang']",2020-03-01 04:41:49+00:00,2021-12-07 17:19:57+00:00,http://arxiv.org/pdf/2003.00400v3,cs.RO,"['cs.RO', 'cs.AI', 'cs.HC']"
Reward Shaping for Human Learning via Inverse Reinforcement Learning,"Humans are spectacular reinforcement learners, constantly learning from and
adjusting to experience and feedback. Unfortunately, this doesn't necessarily
mean humans are fast learners. When tasks are challenging, learning can become
unacceptably slow. Fortunately, humans do not have to learn tabula rasa, and
learning speed can be greatly increased with learning aids. In this work we
validate a new type of learning aid -- reward shaping for humans via inverse
reinforcement learning (IRL). The goal of this aid is to increase the speed
with which humans can learn good policies for specific tasks. Furthermore this
approach compliments alternative machine learning techniques such as safety
features that try to prevent individuals from making poor decisions. To achieve
our results we first extend a well known IRL algorithm via kernel methods.
Afterwards we conduct two human subjects experiments using an online game where
players have limited time to learn a good policy. We show with statistical
significance that players who receive our learning aid are able to approach
desired policies more quickly than the control group.","['Mark A. Rucker', 'Layne T. Watson', 'Matthew S. Gerber', 'Laura E. Barnes']",2020-02-25 14:44:25+00:00,2022-12-15 16:00:42+00:00,http://arxiv.org/pdf/2002.10904v3,cs.LG,"['cs.LG', 'stat.ML']"
Synaptic clock as a neural substrate of consciousness,"In this theoretical work the temporal aspect of consciousness is analyzed. We
start from the notion that while conscious experience seems to change
constantly, yet for any of its contents to be consciously perceived they must
last for some non-zero duration of time, which appears to constitute certain
conflict. We posit that, in terms of phenomenological analysis of
consciousness, the temporal aspect, and this apparent conflict in particular,
might be the most basic property, likely inherent to any conceivable form of
consciousness. It is then outlined how taking this perspective offers a
concrete way of relating the properties of consciousness directly to the neural
plasticity mechanisms of learning and memory, and specifying how exactly
subjective experience might be related to processes of information integration.
In particular, we propose synaptic clock to constitute a content-specific
neural substrate of consciousness, explaining how it would correspond to this
temporal aspect. Then, we propose a viewpoint, in which moments of subjective
time have different durations, depending on the type of information processed,
proportional to the time units of corresponding synaptic clocks, and being in
principle different for different brain regions and nervous systems in
different animal species. Relation and possible contributions of this viewpoint
to the extensional model of time consciousness are discussed. Finally, we
consider the two alternative views on the structure of consciousness, namely a
static and a dynamic one, and argue in favor of the latter, proposing that
consciousness can be best understood if change is considered its only
dimension.",['Bartosz Jura'],2020-02-18 16:43:58+00:00,2022-03-05 21:16:46+00:00,http://arxiv.org/pdf/2002.07716v2,q-bio.NC,['q-bio.NC']
Diversity and Inclusion Metrics in Subset Selection,"The ethical concept of fairness has recently been applied in machine learning
(ML) settings to describe a wide range of constraints and objectives. When
considering the relevance of ethical concepts to subset selection problems, the
concepts of diversity and inclusion are additionally applicable in order to
create outputs that account for social power and access differentials. We
introduce metrics based on these concepts, which can be applied together,
separately, and in tandem with additional fairness constraints. Results from
human subject experiments lend support to the proposed criteria. Social choice
methods can additionally be leveraged to aggregate and choose preferable sets,
and we detail how these may be applied.","['Margaret Mitchell', 'Dylan Baker', 'Nyalleng Moorosi', 'Emily Denton', 'Ben Hutchinson', 'Alex Hanna', 'Timnit Gebru', 'Jamie Morgenstern']",2020-02-09 00:29:40+00:00,2020-02-09 00:29:40+00:00,http://arxiv.org/pdf/2002.03256v1,cs.AI,['cs.AI']
A Machine Consciousness architecture based on Deep Learning and Gaussian Processes,"Recent developments in machine learning have pushed the tasks that machines
can do outside the boundaries of what was thought to be possible years ago.
Methodologies such as deep learning or generative models have achieved complex
tasks such as generating art pictures or literature automatically. On the other
hand, symbolic resources have also been developed further and behave well in
problems such as the ones proposed by common sense reasoning. Machine
Consciousness is a field that has been deeply studied and several theories
based in the functionalism philosophical theory like the global workspace
theory or information integration have been proposed that try to explain the
ariseness of consciousness in machines. In this work, we propose an
architecture that may arise consciousness in a machine based in the global
workspace theory and in the assumption that consciousness appear in machines
that has cognitive processes and exhibit conscious behaviour. This architecture
is based in processes that use the recent developments in artificial
intelligence models which output are these correlated activities. For every one
of the modules of this architecture, we provide detailed explanations of the
models involved and how they communicate with each other to create the
cognitive architecture.","['Eduardo C. Garrido Merchán', 'Martín Molina']",2020-02-02 23:18:17+00:00,2020-03-14 00:01:23+00:00,http://arxiv.org/pdf/2002.00509v2,cs.AI,['cs.AI']
Consciousness and Automated Reasoning,"This paper aims at demonstrating how a first-order logic reasoning system in
combination with a large knowledge base can be understood as an artificial
consciousness system. For this we review some aspects from the area of
philosophy of mind and in particular Tononi's Information Integration Theory
(IIT) and Baars' Global Workspace Theory. These will be applied to the
reasoning system Hyper with ConceptNet as a knowledge base within a scenario of
commonsense and cognitive reasoning. Finally we demonstrate that such a system
is very well able to do conscious mind wandering.","['Ulrike Barthelmeß', 'Ulrich Furbach', 'Claudia Schon']",2020-01-26 11:43:48+00:00,2020-07-22 10:08:33+00:00,http://arxiv.org/pdf/2001.09442v3,cs.AI,['cs.AI']
"""Why is 'Chicago' deceptive?"" Towards Building Model-Driven Tutorials for Humans","To support human decision making with machine learning models, we often need
to elucidate patterns embedded in the models that are unsalient, unknown, or
counterintuitive to humans. While existing approaches focus on explaining
machine predictions with real-time assistance, we explore model-driven
tutorials to help humans understand these patterns in a training phase. We
consider both tutorials with guidelines from scientific papers, analogous to
current practices of science communication, and automatically selected examples
from training data with explanations. We use deceptive review detection as a
testbed and conduct large-scale, randomized human-subject experiments to
examine the effectiveness of such tutorials. We find that tutorials indeed
improve human performance, with and without real-time assistance. In
particular, although deep learning provides superior predictive performance
than simple models, tutorials and explanations from simple models are more
useful to humans. Our work suggests future directions for human-centered
tutorials and explanations towards a synergy between humans and AI.","['Vivian Lai', 'Han Liu', 'Chenhao Tan']",2020-01-14 19:00:00+00:00,2020-01-14 19:00:00+00:00,http://arxiv.org/pdf/2001.05871v1,cs.HC,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']"
A Human-in-the-loop Framework to Construct Context-aware Mathematical Notions of Outcome Fairness,"Existing mathematical notions of fairness fail to account for the context of
decision-making. We argue that moral consideration of contextual factors is an
inherently human task. So we present a framework to learn context-aware
mathematical formulations of fairness by eliciting people's situated fairness
assessments. Our family of fairness notions corresponds to a new interpretation
of economic models of Equality of Opportunity (EOP), and it includes most
existing notions of fairness as special cases. Our human-in-the-loop approach
is designed to learn the appropriate parameters of the EOP family by utilizing
human responses to pair-wise questions about decision subjects' circumstance
and deservingness, and the harm/benefit imposed on them. We illustrate our
framework in a hypothetical criminal risk assessment scenario by conducting a
series of human-subject experiments on Amazon Mechanical Turk. Our work takes
an important initial step toward empowering stakeholders to have a voice in the
formulation of fairness for Machine Learning.","['Mohammad Yaghini', 'Andreas Krause', 'Hoda Heidari']",2019-11-08 03:41:03+00:00,2021-05-18 12:41:14+00:00,http://arxiv.org/pdf/1911.03020v2,cs.AI,"['cs.AI', 'cs.CY']"
CycleGAN Voice Conversion of Spectral Envelopes using Adversarial Weights,"This paper tackles GAN optimization and stability issues in the context of
voice conversion. First, to simplify the conversion task, we propose to use
spectral envelopes as inputs. Second we propose two adversarial weight training
paradigms, the generalized weighted GAN and the generator impact GAN, both aim
at reducing the impact of the generator on the discriminator, so both can learn
more gradually and efficiently during training. Applying an energy constraint
to the cycleGAN paradigm considerably improved conversion quality. A subjective
experiment conducted on a voice conversion task on the voice conversion
challenge 2018 dataset shows first that despite a significantly reduced network
complexity, the proposed method achieves state-of-the-art results, and second
that the proposed weighted GAN methods outperform a previously proposed one.","['Rafael Ferro', 'Nicolas Obin', 'Axel Roebel']",2019-10-22 12:18:18+00:00,2020-07-11 14:43:03+00:00,http://arxiv.org/pdf/1910.12614v2,eess.AS,"['eess.AS', 'cs.LG', 'cs.SD']"
Definition Frames: Using Definitions for Hybrid Concept Representations,"Advances in word representations have shown tremendous improvements in
downstream NLP tasks, but lack semantic interpretability. In this paper, we
introduce Definition Frames (DF), a matrix distributed representation extracted
from definitions, where each dimension is semantically interpretable. DF
dimensions correspond to the Qualia structure relations: a set of relations
that uniquely define a term. Our results show that DFs have competitive
performance with other distributional semantic approaches on word similarity
tasks.","['Evangelia Spiliopoulou', 'Artidoro Pagnoni', 'Eduard Hovy']",2019-09-10 23:43:05+00:00,2020-11-02 01:43:40+00:00,http://arxiv.org/pdf/1909.04793v2,cs.CL,['cs.CL']
Towards Explainable Music Emotion Recognition: The Route via Mid-level Features,"Emotional aspects play an important part in our interaction with music.
However, modelling these aspects in MIR systems have been notoriously
challenging since emotion is an inherently abstract and subjective experience,
thus making it difficult to quantify or predict in the first place, and to make
sense of the predictions in the next. In an attempt to create a model that can
give a musically meaningful and intuitive explanation for its predictions, we
propose a VGG-style deep neural network that learns to predict emotional
characteristics of a musical piece together with (and based on)
human-interpretable, mid-level perceptual features. We compare this to
predicting emotion directly with an identical network that does not take into
account the mid-level features and observe that the loss in predictive
performance of going through the mid-level features is surprisingly low, on
average. The design of our network allows us to visualize the effects of
perceptual features on individual emotion predictions, and we argue that the
small loss in performance in going through the mid-level features is justified
by the gain in explainability of the predictions.","['Shreyan Chowdhury', 'Andreu Vall', 'Verena Haunschmid', 'Gerhard Widmer']",2019-07-08 12:58:02+00:00,2019-07-08 12:58:02+00:00,http://arxiv.org/pdf/1907.03572v1,cs.SD,"['cs.SD', 'cs.LG', 'stat.ML']"
Information Flow Theory (IFT) of Biologic and Machine Consciousness: Implications for Artificial General Intelligence and the Technological Singularity,"The subjective experience of consciousness is at once familiar and yet deeply
mysterious. Strategies exploring the top-down mechanisms of conscious thought
within the human brain have been unable to produce a generalized explanatory
theory that scales through evolution and can be applied to artificial systems.
Information Flow Theory (IFT) provides a novel framework for understanding both
the development and nature of consciousness in any system capable of processing
information. In prioritizing the direction of information flow over information
computation, IFT produces a range of unexpected predictions. The purpose of
this manuscript is to introduce the basic concepts of IFT and explore the
manifold implications regarding artificial intelligence, superhuman
consciousness, and our basic perception of reality.",['B. S. Bleier'],2019-06-21 15:01:25+00:00,2019-06-21 15:01:25+00:00,http://arxiv.org/pdf/1907.00703v1,q-bio.NC,"['q-bio.NC', 'cs.AI', 'cs.ET', 'cs.IT', 'math.IT']"
Low-dimensional Embodied Semantics for Music and Language,"Embodied cognition states that semantics is encoded in the brain as firing
patterns of neural circuits, which are learned according to the statistical
structure of human multimodal experience. However, each human brain is
idiosyncratically biased, according to its subjective experience history,
making this biological semantic machinery noisy with respect to the overall
semantics inherent to media artifacts, such as music and language excerpts. We
propose to represent shared semantics using low-dimensional vector embeddings
by jointly modeling several brains from human subjects. We show these
unsupervised efficient representations outperform the original high-dimensional
fMRI voxel spaces in proxy music genre and language topic classification tasks.
We further show that joint modeling of several subjects increases the semantic
richness of the learned latent vector spaces.","['Francisco Afonso Raposo', 'David Martins de Matos', 'Ricardo Ribeiro']",2019-06-20 11:09:01+00:00,2019-06-20 11:09:01+00:00,http://arxiv.org/pdf/1906.11759v1,q-bio.NC,"['q-bio.NC', 'cs.IR', 'cs.LG', 'cs.SD', 'eess.AS', 'stat.ML', 'I.2.6; H.5.5; H.5.1; I.2.7']"
Awareness as inference in a higher-order state space,"Humans have the ability to report the contents of their subjective experience
- we can say to each other, ""I am aware of X"". The decision processes that
support these reports about mental contents remain poorly understood. In this
article I propose a computational framework that characterises awareness
reports as metacognitive decisions (inference) about a generative model of
perceptual content. This account is motivated from the perspective of how
flexible hierarchical state spaces are built during learning and
decision-making. Internal states supporting awareness reports, unlike those
covarying with perceptual contents, are simple and abstract, varying along a
one-dimensional continuum from absent to present. A critical feature of this
architecture is that it is both higher-order and asymmetric: a vast number of
perceptual states is nested under ""present"", but a much smaller number of
possible states nested under ""absent"". Via simulations I show that this
asymmetry provides a natural account of observations of ""global ignition"" in
brain imaging studies of awareness reports.",['Stephen M. Fleming'],2019-05-31 10:26:26+00:00,2019-12-03 11:24:09+00:00,http://arxiv.org/pdf/1906.00728v3,q-bio.NC,['q-bio.NC']
Artificial Consciousness and Security,"This paper describes a possible way to improve computer security by
implementing a program which implements the following three features related to
a weak notion of artificial consciousness: (partial) self-monitoring, ability
to compute the truth of quantifier-free propositions and the ability to
communicate with the user. The integrity of the program could be enhanced by
using a trusted computing approach, that is to say a hardware module that is at
the root of a chain of trust. This paper outlines a possible approach but does
not refer to an implementation (which would need further work), but the author
believes that an implementation using current processors, a debugger, a
monitoring program and a trusted processing module is currently possible.",['Andrew Powell'],2019-05-11 11:21:05+00:00,2019-05-11 11:21:05+00:00,http://arxiv.org/pdf/1905.11807v1,cs.AI,['cs.AI']
The meta-problem and the transfer of knowledge between theories of consciousness: a software engineer's take,"This contribution examines two radically different explanations of our
phenomenal intuitions, one reductive and one strongly non-reductive, and
identifies two germane ideas that could benefit many other theories of
consciousness. Firstly, the ability of sophisticated agent architectures with a
purely physical implementation to support certain functional forms of qualia or
proto-qualia appears to entail the possibility of machine consciousness with
qualia, not only for reductive theories but also for the nonreductive ones that
regard consciousness as ubiquitous in Nature. Secondly, analysis of
introspective psychological material seems to hint that, under the threshold of
our ordinary waking awareness, there exist further 'submerged' or 'subliminal'
layers of consciousness which constitute a hidden foundation and support and
another source of our phenomenal intuitions. These 'submerged' layers might
help explain certain puzzling phenomena concerning subliminal perception, such
as the apparently 'unconscious' multisensory integration and learning of
subliminal stimuli.",['Marcel Kvassay'],2019-02-18 19:17:44+00:00,2019-02-18 19:17:44+00:00,http://arxiv.org/pdf/1903.03418v1,q-bio.NC,"['q-bio.NC', 'cs.AI']"
An Evaluation of the Human-Interpretability of Explanation,"Recent years have seen a boom in interest in machine learning systems that
can provide a human-understandable rationale for their predictions or
decisions. However, exactly what kinds of explanation are truly
human-interpretable remains poorly understood. This work advances our
understanding of what makes explanations interpretable under three specific
tasks that users may perform with machine learning systems: simulation of the
response, verification of a suggested response, and determining whether the
correctness of a suggested response changes under a change to the inputs.
Through carefully controlled human-subject experiments, we identify
regularizers that can be used to optimize for the interpretability of machine
learning systems. Our results show that the type of complexity matters:
cognitive chunks (newly defined concepts) affect performance more than variable
repetitions, and these trends are consistent across tasks and domains. This
suggests that there may exist some common design principles for explanation
systems.","['Isaac Lage', 'Emily Chen', 'Jeffrey He', 'Menaka Narayanan', 'Been Kim', 'Sam Gershman', 'Finale Doshi-Velez']",2019-01-31 02:08:22+00:00,2019-08-28 22:29:45+00:00,http://arxiv.org/pdf/1902.00006v2,cs.LG,"['cs.LG', 'stat.ML']"
Evolving the pulmonary nodules diagnosis from classical approaches to deep learning aided decision support: three decades development course and future prospect,"Lung cancer is the commonest cause of cancer deaths worldwide, and its
mortality can be reduced significantly by performing early diagnosis and
screening. Since the 1960s, driven by the pressing needs to accurately and
effectively interpret the massive volume of chest images generated daily,
computer-assisted diagnosis of pulmonary nodule has opened up new opportunities
to relax the limitation from physicians' subjectivity, experiences and fatigue.
And the fair access to the reliable and affordable computer-assisted diagnosis
will fight the inequalities in incidence and mortality between populations. It
has been witnessed that significant and remarkable advances have been achieved
since the 1980s, and consistent endeavors have been exerted to deal with the
grand challenges on how to accurately detect the pulmonary nodules with high
sensitivity at low false-positives rate as well as on how to precisely
differentiate between benign and malignant nodules. There is a lack of
comprehensive examination of the techniques' development which is evolving the
pulmonary nodules diagnosis from classical approaches to machine
learning-assisted decision support. The main goal of this investigation is to
provide a comprehensive state-of-the-art review of the computer-assisted
nodules detection and benign-malignant classification techniques developed over
3 decades, which have evolved from the complicated ad hoc analysis pipeline of
conventional approaches to the simplified seamlessly integrated deep learning
techniques. This review also identifies challenges and highlights opportunities
for future work in learning models, learning algorithms and enhancement schemes
for bridging current state to future prospect and satisfying future demand.","['Bo Liu', 'Wenhao Chi', 'Xinran Li', 'Peng Li', 'Wenhua Liang', 'Haiping Liu', 'Wei Wang', 'Jianxing He']",2019-01-23 13:04:59+00:00,2020-04-24 17:31:24+00:00,http://arxiv.org/pdf/1901.07858v3,cs.CV,"['cs.CV', 'cs.LG']"
Theory of Cognitive Relativity: A Promising Paradigm for True AI,"The rise of deep learning has brought artificial intelligence (AI) to the
forefront. The ultimate goal of AI is to realize machines with human mind and
consciousness, but existing achievements mainly simulate intelligent behavior
on computer platforms. These achievements all belong to weak AI rather than
strong AI. How to achieve strong AI is not known yet in the field of
intelligence science. Currently, this field is calling for a new paradigm,
especially Theory of Cognitive Relativity (TCR). The TCR aims to summarize a
simple and elegant set of first principles about the nature of intelligence, at
least including the Principle of World's Relativity and the Principle of
Symbol's Relativity. The Principle of World's Relativity states that the
subjective world an intelligent agent can observe is strongly constrained by
the way it perceives the objective world. The Principle of Symbol's Relativity
states that an intelligent agent can use any physical symbol system to express
what it observes in its subjective world. The two principles are derived from
scientific facts and life experience. Thought experiments show that they are
important to understand high-level intelligence and necessary to establish a
scientific theory of mind and consciousness. Rather than brain-like
intelligence, the TCR indeed advocates a promising change in direction to
realize true AI, i.e. artificial general intelligence or artificial
consciousness, particularly different from humans' and animals'. Furthermore, a
TCR creed has been presented and extended to reveal the secrets of
consciousness and to guide realization of conscious machines. In the sense that
true AI could be diversely implemented in a brain-different way, the TCR would
probably drive an intelligence revolution in combination with some additional
first principles.",['Yujian Li'],2018-12-01 04:01:03+00:00,2018-12-20 06:59:22+00:00,http://arxiv.org/pdf/1812.00136v3,cs.AI,['cs.AI']
A rule-based system proposal to aid in the evaluation and decision-making in external beam radiation treatment planning,"As part of a plan launched by the Ministry of Health of Brazil to increase
the availability of linear accelerators for radiotherapy treatment for the
whole country, for which Varian Medical Systems company has won the bidding, a
technical cooperation agreement was signed inviting Brazilian Scientific and
Technological Institutions to participate in a technology transfer program. As
a result, jointly, the Eldorado Research Institute and the Center for
Biomedical Engineering of the University of Campinas presents in this work, the
concepts behind of a proposed rule engine to aid in the evaluation and
decision-making in radiotherapy treatment planning. Normally, the determination
of the radiation dose for a given patient is a complex and intensive procedure,
which requires a lot of domain knowledge and subjective experience from the
oncologists' team. In order to help them in this complex task, and
additionally, provide an auxiliary tool for less experienced oncologists, it is
presented a project conception of a software system that will make use of a
hybrid data-oriented approach. The proposed rule engine will apply both
inference mechanism and expression evaluation to verify and accredit the
quality of an external beam radiation treatment plan by considering, at first,
the 3D-conformal radiotherapy (3DCRT) technique.","['R. C. Fernandes', 'T. M. Machado', 'H. J. Onisto', 'A. D. Muñoz', 'R. O. Silva', 'L. R. Domingues', 'G. C. Fonseca', 'J. E. Bertuzzo', 'M. T. Pereira', 'B. Biazotto', 'E. T. Costa']",2018-11-29 19:49:53+00:00,2018-11-29 19:49:53+00:00,http://arxiv.org/pdf/1811.12454v1,cs.SE,"['cs.SE', 'cs.AI']"
Towards a Science of Mind,"The ancient mind/body problem continues to be one of deepest mysteries of
science and of the human spirit. Despite major advances in many fields, there
is still no plausible link between subjective experience (qualia) and its
realization in the body. This paper outlines some of the elements of a rigorous
science of mind (SoM) - key ideas include scientific realism of mind, agnostic
mysterianism, careful attention to language, and a focus on concrete
(touchstone) questions and results. A core suggestion is to focus effort on the
(still mysterious) mapping from neural activity to subjective experience.",['Jerome Feldman'],2018-11-06 18:02:40+00:00,2019-07-29 16:58:06+00:00,http://arxiv.org/pdf/1811.06825v3,cs.GL,"['cs.GL', 'cs.AI', 'q-bio.NC']"
Can quantum physics help solve the hard problem of consciousness? A hypothesis based on entangled spins and photons,"The hard problem of consciousness is the question how subjective experience
arises from brain matter. I suggest exploring the possibility that quantum
physics could be part of the answer. The simultaneous unity and complexity of
subjective experience is difficult to understand from a classical physics
perspective. In contrast, quantum entanglement is naturally both complex and
unified. Moreover the concept of matter is much more subtle in quantum physics
compared to classical physics, and quantum computing shows that quantum effects
can be useful for information processing. Building on recent progress in
quantum technology and neuroscience, I propose a concrete hypothesis as a basis
for further investigation, namely that subjective experience is related to the
dynamics of a complex entangled state of spins, which is continuously generated
and updated through the exchange of photons. Spins in condensed matter systems
at room or body temperature can have coherence times in the relevant range for
subjective experience (milliseconds to seconds). Photons are well suited for
distributing entanglement over macroscopic distances. Neurons emit photons,
reactive oxygen species in the mitochondria being likely sources. Opsins,
light-sensitive proteins that are plausible single-photon detectors, exist in
the brain and are evolutionarily conserved, suggesting that they serve a
function. We have recently shown by detailed numerical modeling that axons can
plausibly act as photonic waveguides. The oxygen molecule, which has non-zero
electronic spin and emits photons, might serve as an interface between photons
and spins. The achievable photon rates seem to be more than sufficient to
support the bandwidth of subjective experience. The proposed hypothesis raises
many interesting experimental and theoretical questions in neuroscience,
quantum physics, evolutionary biology, psychophysics, and philosophy.",['Christoph Simon'],2018-09-08 20:04:22+00:00,2018-09-08 20:04:22+00:00,http://arxiv.org/pdf/1809.03490v1,q-bio.NC,"['q-bio.NC', 'physics.bio-ph', 'quant-ph']"
DeSIGN: Design Inspiration from Generative Networks,"Can an algorithm create original and compelling fashion designs to serve as
an inspirational assistant? To help answer this question, we design and
investigate different image generation models associated with different loss
functions to boost creativity in fashion generation. The dimensions of our
explorations include: (i) different Generative Adversarial Networks
architectures that start from noise vectors to generate fashion items, (ii)
novel loss functions that encourage novelty, inspired from Sharma-Mittal
divergence, a generalized mutual information measure for the widely used
relative entropies such as Kullback-Leibler, and (iii) a generation process
following the key elements of fashion design (disentangling shape and texture
components). A key challenge of this study is the evaluation of generated
designs and the retrieval of best ones, hence we put together an evaluation
protocol associating automatic metrics and human experimental studies that we
hope will help ease future research. We show that our proposed creativity
criterion yield better overall appreciation than the one employed in Creative
Adversarial Networks. In the end, about 61% of our images are thought to be
created by human designers rather than by a computer while also being
considered original per our human subject experiments, and our proposed loss
scores the highest compared to existing losses in both novelty and likability.","['Othman Sbai', 'Mohamed Elhoseiny', 'Antoine Bordes', 'Yann LeCun', 'Camille Couprie']",2018-04-03 11:54:57+00:00,2018-09-14 10:17:31+00:00,http://arxiv.org/pdf/1804.00921v2,cs.LG,"['cs.LG', 'stat.ML']"
Deep Feed-forward Sequential Memory Networks for Speech Synthesis,"The Bidirectional LSTM (BLSTM) RNN based speech synthesis system is among the
best parametric Text-to-Speech (TTS) systems in terms of the naturalness of
generated speech, especially the naturalness in prosody. However, the model
complexity and inference cost of BLSTM prevents its usage in many runtime
applications. Meanwhile, Deep Feed-forward Sequential Memory Networks (DFSMN)
has shown its consistent out-performance over BLSTM in both word error rate
(WER) and the runtime computation cost in speech recognition tasks. Since
speech synthesis also requires to model long-term dependencies compared to
speech recognition, in this paper, we investigate the Deep-FSMN (DFSMN) in
speech synthesis. Both objective and subjective experiments show that, compared
with BLSTM TTS method, the DFSMN system can generate synthesized speech with
comparable speech quality while drastically reduce model complexity and speech
generation time.","['Mengxiao Bi', 'Heng Lu', 'Shiliang Zhang', 'Ming Lei', 'Zhijie Yan']",2018-02-26 08:21:26+00:00,2018-02-26 08:21:26+00:00,http://arxiv.org/pdf/1802.09194v1,cs.CL,['cs.CL']
Trust-Aware Decision Making for Human-Robot Collaboration: Model Learning and Planning,"Trust in autonomy is essential for effective human-robot collaboration and
user adoption of autonomous systems such as robot assistants. This paper
introduces a computational model which integrates trust into robot
decision-making. Specifically, we learn from data a partially observable Markov
decision process (POMDP) with human trust as a latent variable. The trust-POMDP
model provides a principled approach for the robot to (i) infer the trust of a
human teammate through interaction, (ii) reason about the effect of its own
actions on human trust, and (iii) choose actions that maximize team performance
over the long term. We validated the model through human subject experiments on
a table-clearing task in simulation (201 participants) and with a real robot
(20 participants). In our studies, the robot builds human trust by manipulating
low-risk objects first. Interestingly, the robot sometimes fails intentionally
in order to modulate human trust and achieve the best team performance. These
results show that the trust-POMDP calibrates trust to improve human-robot team
performance over the long term. Further, they highlight that maximizing trust
alone does not always lead to the best performance.","['Min Chen', 'Stefanos Nikolaidis', 'Harold Soh', 'David Hsu', 'Siddhartha Srinivasa']",2018-01-12 09:28:28+00:00,2018-11-22 05:14:00+00:00,http://arxiv.org/pdf/1801.04099v3,cs.RO,"['cs.RO', 'cs.AI']"
Null Dynamical State Models of Human Cognitive Dysfunction,"The hard problem in artificial intelligence asks how the shuffling of
syntactical symbols in a program can lead to systems which experience semantics
and qualia. We address this question in three stages. First, we introduce a new
class of human semantic symbols which appears when unexpected and drastic
environmental change causes humans to become surprised, confused, uncertain,
and in extreme cases, unresponsive, passive and dysfunctional. For this class
of symbols, pre-learned programs become inoperative so these syntactical
programs cannot be the source of experienced qualia. Second, we model the
dysfunctional human response to a radically changed environment as being the
natural response of any learning machine facing novel inputs from well outside
its previous training set. In this situation, learning machines are unable to
extract information from their input and will typically enter a dynamical state
characterized by null outputs and a lack of response. This state immediately
predicts and explains the characteristics of the semantic experiences of humans
in similar circumstances. In the third stage, we consider learning machines
trained to implement multiple functions in simple sequential programs using
environmental data to specify subroutine names, control flow instructions,
memory calls, and so on. Drastic change in any of these environmental inputs
can again lead to inoperative programs. By examining changes specific to people
or locations we can model human cognitive symbols featuring these dependencies,
such as attachment and grief. Our approach links known dynamical machines
states with human qualia and thus offers new insight into the hard problem of
artificial intelligence.",['M. J. Gagen'],2017-12-25 05:46:19+00:00,2017-12-25 05:46:19+00:00,http://arxiv.org/pdf/1712.09014v1,cs.AI,"['cs.AI', 'cs.LG', 'cs.NE']"
Detecting Qualia in Natural and Artificial Agents,"The Hard Problem of consciousness has been dismissed as an illusion. By
showing that computers are capable of experiencing, we show that they are at
least rudimentarily conscious with potential to eventually reach
superconsciousness. The main contribution of the paper is a test for confirming
certain subjective experiences in a tested agent. We follow with analysis of
benefits and problems with conscious machines and implications of such
capability on future of computing, machine rights and artificial intelligence
safety.",['Roman V. Yampolskiy'],2017-12-11 20:53:47+00:00,2017-12-11 20:53:47+00:00,http://arxiv.org/pdf/1712.04020v1,cs.AI,['cs.AI']
Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients,"Deep neural networks have proven remarkably effective at solving many
classification problems, but have been criticized recently for two major
weaknesses: the reasons behind their predictions are uninterpretable, and the
predictions themselves can often be fooled by small adversarial perturbations.
These problems pose major obstacles for the adoption of neural networks in
domains that require security or transparency. In this work, we evaluate the
effectiveness of defenses that differentiably penalize the degree to which
small changes in inputs can alter model predictions. Across multiple attacks,
architectures, defenses, and datasets, we find that neural networks trained
with this input gradient regularization exhibit robustness to transferred
adversarial examples generated to fool all of the other models. We also find
that adversarial examples generated to fool gradient-regularized models fool
all other models equally well, and actually lead to more ""legitimate,""
interpretable misclassifications as rated by people (which we confirm in a
human subject experiment). Finally, we demonstrate that regularizing input
gradients makes them more naturally interpretable as rationales for model
predictions. We conclude by discussing this relationship between
interpretability and robustness in deep neural networks.","['Andrew Slavin Ross', 'Finale Doshi-Velez']",2017-11-26 15:20:46+00:00,2017-11-26 15:20:46+00:00,http://arxiv.org/pdf/1711.09404v1,cs.LG,"['cs.LG', 'cs.CR', 'cs.CV']"
Neural correlates of flow using auditory evoked potential suppression,"""Flow"" is a hyper-engaged state of consciousness most commonly described in
athletics, popularly termed ""being in the zone."" Quantitative research into
flow has been hampered by the disruptive nature of gathering subjective
reports. Here we show that a passive probe (suppression of Auditory Evoked
Potential in EEG) that allowed our participants to remain engaged in a
first-person shooting game while we continually tracked the depth of their
immersion corresponded with the participants' subjective experiences, and with
their objective performance levels. Comparing this time-varying record of flow
against the overall EEG record, we identified neural correlates of flow in the
anterior cingulate cortex and the temporal pole. These areas displayed
increased beta band activity, mutual connectivity, and feedback connectivity
with primary motor cortex. These results corroborate the notion that the flow
state is an objective and quantifiable state of consciousness, which we
identify and characterize across subjective, behavioral and neural measures.","['Kyongsik Yun', 'Saeran Doh', 'Elisa Carrus', 'Daw-An Wu', 'Shinsuke Shimojo']",2017-11-19 04:37:58+00:00,2017-11-24 22:30:51+00:00,http://arxiv.org/pdf/1711.06967v4,q-bio.NC,['q-bio.NC']
Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning,"Pain is a subjective experience commonly measured through patient's self
report. While there exist numerous situations in which automatic pain
estimation methods may be preferred, inter-subject variability in physiological
and behavioral pain responses has hindered the development of such methods. In
this work, we address this problem by introducing a novel personalized
multitask machine learning method for pain estimation based on individual
physiological and behavioral pain response profiles, and show its advantages in
a dataset containing multimodal responses to nociceptive heat pain.","['Daniel Lopez-Martinez', 'Ognjen Rudovic', 'Rosalind Picard']",2017-11-10 22:36:27+00:00,2017-11-10 22:36:27+00:00,http://arxiv.org/pdf/1711.04036v1,cs.AI,"['cs.AI', 'cs.HC']"
HDR image reconstruction from a single exposure using deep CNNs,"Camera sensors can only capture a limited range of luminance simultaneously,
and in order to create high dynamic range (HDR) images a set of different
exposures are typically combined. In this paper we address the problem of
predicting information that have been lost in saturated image areas, in order
to enable HDR reconstruction from a single exposure. We show that this problem
is well-suited for deep learning algorithms, and propose a deep convolutional
neural network (CNN) that is specifically designed taking into account the
challenges in predicting HDR values. To train the CNN we gather a large dataset
of HDR images, which we augment by simulating sensor saturation for a range of
cameras. To further boost robustness, we pre-train the CNN on a simulated HDR
dataset created from a subset of the MIT Places database. We demonstrate that
our approach can reconstruct high-resolution visually convincing HDR results in
a wide range of situations, and that it generalizes well to reconstruction of
images captured with arbitrary and low-end cameras that use unknown camera
response functions and post-processing. Furthermore, we compare to existing
methods for HDR expansion, and show high quality results also for image based
lighting. Finally, we evaluate the results in a subjective experiment performed
on an HDR display. This shows that the reconstructed HDR images are visually
convincing, with large improvements as compared to existing methods.","['Gabriel Eilertsen', 'Joel Kronander', 'Gyorgy Denes', 'Rafał K. Mantiuk', 'Jonas Unger']",2017-10-20 10:48:22+00:00,2017-10-20 10:48:22+00:00,http://arxiv.org/pdf/1710.07480v1,cs.CV,"['cs.CV', 'cs.GR', 'cs.LG']"
Musical NeuroPicks: a consumer-grade BCI for on-demand music streaming services,"We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used in popular
on-demand music streaming services. Our study resulted into two variants,
differing in terms of performance and execution time, and hence, subserving
distinct applications in online streaming music platforms. The first method,
NeuroPicks, is extremely accurate but slower. It is based on the
well-established neuroscientific concepts of brainwave frequency bands,
activation asymmetry index and cross frequency coupling (CFC). The second
method, NeuroPicksVQ, offers prompt predictions of lower credibility and relies
on a custom-built version of vector quantization procedure that facilitates a
novel parameterization of the music-modulated brainwaves. Beyond the feature
engineering step, both methods exploit the inherent efficiency of extreme
learning machines (ELMs) so as to translate, in a personalized fashion, the
derived patterns into a listener's score. NeuroPicks method may find
applications as an integral part of contemporary music recommendation systems,
while NeuroPicksVQ can control the selection of music tracks. Encouraging
experimental results, from a pragmatic use of the systems, are presented.","['Fotis Kalaganis', 'Dimitrios A. Adamos', 'Nikos Laskaris']",2017-09-04 18:55:35+00:00,2017-09-04 18:55:35+00:00,http://arxiv.org/pdf/1709.01116v1,q-bio.NC,"['q-bio.NC', 'cs.CY', 'cs.HC', 'cs.MM']"
Are there optical communication channels in the brain?,"Despite great progress in neuroscience, there are still fundamental
unanswered questions about the brain, including the origin of subjective
experience and consciousness. Some answers might rely on new physical
mechanisms. Given that biophotons have been discovered in the brain, it is
interesting to explore if neurons use photonic communication in addition to the
well-studied electro-chemical signals. Such photonic communication in the brain
would require waveguides. Here we review recent work [S. Kumar, K. Boone, J.
Tuszynski, P. Barclay, and C. Simon, Scientific Reports 6, 36508 (2016)]
suggesting that myelinated axons could serve as photonic waveguides. The light
transmission in the myelinated axon was modeled, taking into account its
realistic imperfections, and experiments were proposed both in-vivo and
in-vitro to test this hypothesis. Potential implications for quantum biology
are discussed.","['Parisa Zarkeshian', 'Sourabh Kumar', 'Jack Tuszynski', 'Paul Barclay', 'Christoph Simon']",2017-08-23 22:54:52+00:00,2017-08-23 22:54:52+00:00,http://arxiv.org/pdf/1708.08887v1,physics.bio-ph,"['physics.bio-ph', 'physics.optics', 'q-bio.NC', 'quant-ph']"
Multi-task Neural Networks for Personalized Pain Recognition from Physiological Signals,"Pain is a complex and subjective experience that poses a number of
measurement challenges. While self-report by the patient is viewed as the gold
standard of pain assessment, this approach fails when patients cannot verbally
communicate pain intensity or lack normal mental abilities. Here, we present a
pain intensity measurement method based on physiological signals. Specifically,
we implement a multi-task learning approach based on neural networks that
accounts for individual differences in pain responses while still leveraging
data from across the population. We test our method in a dataset containing
multi-modal physiological responses to nociceptive pain.","['Daniel Lopez-Martinez', 'Rosalind Picard']",2017-08-17 05:38:56+00:00,2017-09-04 19:23:11+00:00,http://arxiv.org/pdf/1708.08755v2,cs.CY,"['cs.CY', 'cs.LG', 'q-bio.NC']"
What modern vision science reveals about the awareness puzzle: Summary-statistic encoding plus decision limits underlie the richness of visual perception and its quirky failures,"There is a fundamental puzzle in understanding our awareness of the visual
world. On one hand, our subjective experience is one of a rich visual world,
which we perceive effortlessly. However, when we actually test perception,
observers know surprisingly little. A number of tasks, from search, through
inattentional blindness, to change blindness, suggest that there is
surprisingly little awareness or perception without attention. Meanwhile,
another set of tasks, such as multiple object tracking, dual-task performance,
and visual working memory tasks suggest that both attention and working memory
have low capacity. These two components together - poor perception without
attention, and greatly limited capacity for attention and memory - imply that
perception is impoverished.
  How can we make sense of this awareness puzzle, of the riddle of our rich
subjective experience coupled with poor performance on experimental tasks? I
suggest that, looked at in the right way, there is in fact no awareness puzzle.
In particular, I will argue that the tasks that show limits are inherently
difficult tasks, and that there exists a unified explanation for both the rich
subjective experience and the apparent limits.",['Ruth Rosenholtz'],2017-06-08 20:41:50+00:00,2017-06-08 20:41:50+00:00,http://arxiv.org/pdf/1706.02764v1,q-bio.NC,['q-bio.NC']
The Impact of Flow in an EEG-based Brain Computer Interface,"Major issues in Brain Computer Interfaces (BCIs) include low usability and
poor user performance. This paper tackles them by ensuring the users to be in a
state of immersion, control and motivation, called state of flow. Indeed, in
various disciplines, being in the state of flow was shown to improve
performances and learning. Hence, we intended to draw BCI users in a flow state
to improve both their subjective experience and their performances. In a Motor
Imagery BCI game, we manipulated flow in two ways: 1) by adapting the task
difficulty and 2) by using background music. Results showed that the difficulty
adaptation induced a higher flow state, however music had no effect. There was
a positive correlation between subjective flow scores and offline performance,
although the flow factors had no effect (adaptation) or negative effect (music)
on online performance. Overall, favouring the flow state seems a promising
approach for enhancing users' satisfaction, although its complexity requires
more thorough investigations.","['Jelena Mladenović', 'Jérémy Frey', 'Manon Bonnet-Save', 'Jérémie Mattout', 'Fabien Lotte']",2017-06-06 12:21:44+00:00,2017-06-06 12:21:44+00:00,http://arxiv.org/pdf/1706.01728v1,q-bio.NC,"['q-bio.NC', 'cs.HC']"
The Morphospace of Consciousness,"We construct a complexity-based morphospace to study systems-level properties
of conscious & intelligent systems. The axes of this space label 3 complexity
types: autonomous, cognitive & social. Given recent proposals to synthesize
consciousness, a generic complexity-based conceptualization provides a useful
framework for identifying defining features of conscious & synthetic systems.
Based on current clinical scales of consciousness that measure cognitive
awareness and wakefulness, we take a perspective on how contemporary
artificially intelligent machines & synthetically engineered life forms measure
on these scales. It turns out that awareness & wakefulness can be associated to
computational & autonomous complexity respectively. Subsequently, building on
insights from cognitive robotics, we examine the function that consciousness
serves, & argue the role of consciousness as an evolutionary game-theoretic
strategy. This makes the case for a third type of complexity for describing
consciousness: social complexity. Having identified these complexity types,
allows for a representation of both, biological & synthetic systems in a common
morphospace. A consequence of this classification is a taxonomy of possible
conscious machines. We identify four types of consciousness, based on
embodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii)
group consciousness (resulting from group interactions), & (iv) simulated
consciousness (embodied by virtual agents within a simulated reality). This
taxonomy helps in the investigation of comparative signatures of consciousness
across domains, in order to highlight design principles necessary to engineer
conscious machines. This is particularly relevant in the light of recent
developments at the crossroads of cognitive neuroscience, biomedical
engineering, artificial intelligence & biomimetics.","['Xerxes D. Arsiwalla', 'Ricard Sole', 'Clement Moulin-Frier', 'Ivan Herreros', 'Marti Sanchez-Fibla', 'Paul Verschure']",2017-05-31 17:45:39+00:00,2018-11-24 23:05:40+00:00,http://arxiv.org/pdf/1705.11190v3,q-bio.NC,"['q-bio.NC', 'cond-mat.dis-nn', 'cs.AI', 'physics.bio-ph']"
A Mathematical Framework for Consciousness in Neural Networks,"This paper presents a novel mathematical framework for bridging the
explanatory gap (Levine, 1983) between consciousness and its physical
correlates. Specifically, we propose that qualia correspond to singularities in
the mathematical representations of neural network topology. Crucially, we do
not claim that qualia are singularities or that singularities ""explain"" why
qualia feel as they do. Instead, we propose that singularities serve as
principled, coordinate-invariant markers of points where attempts at purely
quantitative description of a system's dynamics reach an in-principle limit. By
integrating these formal markers of irreducibility into models of the physical
correlates of consciousness, we establish a framework that recognizes qualia as
phenomena inherently beyond reduction to complexity, computation, or
information. This approach draws on insights from philosophy of mind,
mathematics, cognitive neuroscience, and artificial intelligence (AI). It does
not solve the hard problem of consciousness (Chalmers, 1995), but it advances
the discourse by integrating the irreducible nature of qualia into a rigorous,
physicalist framework. While primarily theoretical, these insights also open
avenues for future AI and artificial consciousness (AC) research, suggesting
that recognizing and harnessing irreducible topological features may be an
important unlock in moving beyond incremental, scale-based improvements and
toward artificial general intelligence (AGI) and AC.",['T. R. Lima'],2017-04-04 18:32:58+00:00,2024-12-10 14:40:14+00:00,http://arxiv.org/pdf/1704.01148v6,q-bio.NC,"['q-bio.NC', 'cs.AI']"
An affective computational model for machine consciousness,"In the past, several models of consciousness have become popular and have led
to the development of models for machine consciousness with varying degrees of
success and challenges for simulation and implementations. Moreover, affective
computing attributes that involve emotions, behavior and personality have not
been the focus of models of consciousness as they lacked motivation for
deployment in software applications and robots. The affective attributes are
important factors for the future of machine consciousness with the rise of
technologies that can assist humans. Personality and affection hence can give
an additional flavor for the computational model of consciousness in humanoid
robotics. Recent advances in areas of machine learning with a focus on deep
learning can further help in developing aspects of machine consciousness in
areas that can better replicate human sensory perceptions such as speech
recognition and vision. With such advancements, one encounters further
challenges in developing models that can synchronize different aspects of
affective computing. In this paper, we review some existing models of
consciousnesses and present an affective computational model that would enable
the human touch and feel for robotic systems.",['Rohitash Chandra'],2017-01-02 09:48:47+00:00,2017-01-02 09:48:47+00:00,http://arxiv.org/pdf/1701.00349v1,cs.AI,['cs.AI']
Computing Integrated Information,"Integrated information theory (IIT) has established itself as one of the
leading theories for the study of consciousness. IIT essentially proposes that
quantitative consciousness is identical to maximally integrated conceptual
information, quantified by a measure called $\Phi^{max}$, and that
phenomenological experience corresponds to the associated set of maximally
irreducible cause-effect repertoires of a physical system being in a certain
state. However, in order to ultimately apply the theory to experimental data, a
sufficiently general formulation is needed. With the current work, we provide
this general formulation, which comprehensively and parsimoniously expresses
$\Phi^{max}$ in the language of probabilistic models. Here, the stochastic
process describing a system under scrutiny corresponds to a first-order
time-invariant Markov process, and all necessary mathematical operations for
the definition of $\Phi^{max}$ are fully specified by a system's joint
probability distribution over two adjacent points in discrete time. We present
a detailed constructive rule for the decomposition of a system into two
disjoint subsystems based on flexible marginalization and factorization of this
joint distribution. Furthermore, we suspend the approach of interventional
calculus based on system perturbations, which allows us to omit undefined
conditional distributions and virtualization. We validate our formulation in a
previously established discrete example system, in which we furthermore address
the previously unexplored theoretical issue of quale underdetermination due to
non-uniqueness of maximally irreducible cause-effect repertoires, which in turn
also entails the sensitivity of $\Phi^{max}$ to the shape of the conceptual
structure in qualia space. In constructive spirit, we propose several
modifications of the framework in order to address some of these issues.","['Stephan Krohn', 'Dirk Ostwald']",2016-10-12 07:47:28+00:00,2017-03-03 11:01:11+00:00,http://arxiv.org/pdf/1610.03627v2,q-bio.NC,['q-bio.NC']
Neural correlates of self-generated imagery and cognition throughout the sleep cycle,"Humans have been aware for thousands of years that sleep comes in many forms,
accompanied by different kinds of mental content. We review the first-person
report literature on the frequency and type of content experienced in various
stages of sleep, showing that different sleep stages are dissociable at the
subjective level. We then relate these subjective differences to the growing
literature differentiating the various sleep stages at the neurophysiological
level, including evidence from electrophysiology, neurochemistry, and
functional neuroimaging. We suggest that there is emerging evidence for
relationships between sleep stage, neurophysiological activity, and subjective
experiences. Specifically, we emphasize that functional neuroimaging work
suggests a parallel between activation and deactivation of default network and
visual network brain areas and the varying frequency and intensity of imagery
and dream mentation across sleep stages; additionally, frontoparietal control
network activity across sleep stages may parallel levels of cognitive control
and meta-awareness. Together these findings suggest intriguing brain-mind
isomorphisms and may serve as a first step toward a comprehensive understanding
of the relationship between neurophysiology and psychology in sleep and
dreaming.","['Kieran C. R. Fox', 'Manesh Girn']",2016-10-06 01:27:48+00:00,2016-10-06 01:27:48+00:00,http://arxiv.org/pdf/1610.01704v1,q-bio.NC,['q-bio.NC']
A Consumer BCI for Automated Music Evaluation Within a Popular On-Demand Music Streaming Service - Taking Listener's Brainwaves to Extremes,"We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used for the automated
annotation of music in popular on-demand streaming services. Based on the
established -neuroscientifically sound- concepts of brainwave frequency bands,
activation asymmetry index and cross-frequency-coupling (CFC), we introduce a
Brain Computer Interface (BCI) system that automatically assigns a rating score
to the listened song. Our research operated in two distinct stages: i) a
generic feature engineering stage, in which features from signal-analytics were
ranked and selected based on their ability to associate music induced
perturbations in brainwaves with listener's appraisal of music. ii) a
personalization stage, during which the efficiency of ex- treme learning
machines (ELMs) is exploited so as to translate the derived pat- terns into a
listener's score. Encouraging experimental results, from a pragmatic use of the
system, are presented.","['Fotis Kalaganis', 'Dimitrios A. Adamos', 'Nikos Laskaris']",2016-09-20 22:29:02+00:00,2016-09-30 11:06:37+00:00,http://arxiv.org/pdf/1609.06374v2,cs.AI,"['cs.AI', 'cs.CY', 'cs.HC', 'cs.MM', 'cs.NE']"
How to avoid ethically relevant Machine Consciousness,"This paper discusses the root cause of systems perceiving the self experience
and how to exploit adaptive and learning features without introducing ethically
problematic system properties.",['Aleksander Lodwich'],2016-05-31 21:52:13+00:00,2016-06-06 10:53:16+00:00,http://arxiv.org/pdf/1606.00058v2,cs.AI,['cs.AI']
Memory shapes time perception and intertemporal choices,"There is a consensus that human and non-human subjects experience temporal
distortions in many stages of their perceptual and decision-making systems.
Similarly, intertemporal choice research has shown that decision-makers
undervalue future outcomes relative to immediate ones. Here we combine
techniques from information theory and artificial intelligence to show how both
temporal distortions and intertemporal choice preferences can be explained as a
consequence of the coding efficiency of sensorimotor representation. In
particular, the model implies that interactions that constrain future behavior
are perceived as being both longer in duration and more valuable. Furthermore,
using simulations of artificial agents, we investigate how memory constraints
enforce a renormalization of the perceived timescales. Our results show that
qualitatively different discount functions, such as exponential and hyperbolic
discounting, arise as a consequence of an agent's probabilistic model of the
world.","['Pedro A. Ortega', 'Naftali Tishby']",2016-04-18 13:17:55+00:00,2016-05-29 18:39:52+00:00,http://arxiv.org/pdf/1604.05129v2,q-bio.NC,"['q-bio.NC', 'cs.AI', 'stat.ML']"
Toward a Taxonomy and Computational Models of Abnormalities in Images,"The human visual system can spot an abnormal image, and reason about what
makes it strange. This task has not received enough attention in computer
vision. In this paper we study various types of atypicalities in images in a
more comprehensive way than has been done before. We propose a new dataset of
abnormal images showing a wide range of atypicalities. We design human subject
experiments to discover a coarse taxonomy of the reasons for abnormality. Our
experiments reveal three major categories of abnormality: object-centric,
scene-centric, and contextual. Based on this taxonomy, we propose a
comprehensive computational model that can predict all different types of
abnormality in images and outperform prior arts in abnormality recognition.","['Babak Saleh', 'Ahmed Elgammal', 'Jacob Feldman', 'Ali Farhadi']",2015-12-04 06:29:53+00:00,2015-12-04 06:29:53+00:00,http://arxiv.org/pdf/1512.01325v1,cs.CV,"['cs.CV', 'cs.AI', 'cs.HC', 'cs.IT', 'cs.LG', 'math.IT']"
The method of artificial systems,"This document is written with the intention to describe in detail a method
and means by which a computer program can reason about the world and in so
doing, increase its analogue to a living system. As the literature is rife and
it is apparent we, as scientists and engineers, have not found the solution,
this document will attempt the solution by grounding its intellectual arguments
within tenets of human cognition in Western philosophy. The result will be a
characteristic description of a method to describe an artificial system
analogous to that performed for a human. The approach was the substance of my
Master's thesis, explored more deeply during the course of my postdoc research.
It focuses primarily on context awareness and choice set within a boundary of
available epistemology, which serves to describe it. Expanded upon, such a
description strives to discover agreement with Kant's critique of reason to
understand how it could be applied to define the architecture of its design.
The intention has never been to mimic human or biological systems, rather, to
understand the profoundly fundamental rules, when leveraged correctly, results
in an artificial consciousness as noumenon while in keeping with the perception
of it as phenomenon.",['Christopher A. Tucker'],2015-07-06 10:52:08+00:00,2017-05-21 13:37:02+00:00,http://arxiv.org/pdf/1507.01384v2,cs.AI,['cs.AI']
Significance of the levels of spectral valleys with application to front/back distinction of vowel sounds,"An objective critical distance (OCD) has been defined as that spacing between
adjacent formants, when the level of the valley between them reaches the mean
spectral level. The measured OCD lies in the same range (viz., 3-3.5 bark) as
the critical distance determined by subjective experiments for similar
experimental conditions. The level of spectral valley serves a purpose similar
to that of the spacing between the formants with an added advantage that it can
be measured from the spectral envelope without an explicit knowledge of formant
frequencies. Based on the relative spacing of formant frequencies, the level of
the spectral valley, VI (between F1 and F2) is much higher than the level of
VII (spectral valley between F2 and F3) for back vowels and vice-versa for
front vowels. Classification of vowels into front/back distinction with the
difference (VI-VII) as an acoustic feature, tested using TIMIT, NTIMIT, Tamil
and Kannada language databases gives, on the average, an accuracy of about 95%,
which is comparable to the accuracy (90.6%) obtained using a neural network
classifier trained and tested using MFCC as the feature vector for TIMIT
database. The acoustic feature (VI-VII) has also been tested for its robustness
on the TIMIT database for additive white and babble noise and an accuracy of
about 95% has been obtained for SNRs down to 25 dB for both types of noise.","['T. V. Ananthapadmanabha', 'A. G. Ramakrishnan', 'Shubham Sharma']",2015-06-16 04:03:06+00:00,2015-10-05 12:44:54+00:00,http://arxiv.org/pdf/1506.04828v2,cs.CL,"['cs.CL', 'cs.SD']"
The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification,"We present the Bayesian Case Model (BCM), a general framework for Bayesian
case-based reasoning (CBR) and prototype classification and clustering. BCM
brings the intuitive power of CBR to a Bayesian generative framework. The BCM
learns prototypes, the ""quintessential"" observations that best represent
clusters in a dataset, by performing joint inference on cluster labels,
prototypes and important features. Simultaneously, BCM pursues sparsity by
learning subspaces, the sets of features that play important roles in the
characterization of the prototypes. The prototype and subspace representation
provides quantitative benefits in interpretability while preserving
classification accuracy. Human subject experiments verify statistically
significant improvements to participants' understanding when using explanations
produced by BCM, compared to those given by prior art.","['Been Kim', 'Cynthia Rudin', 'Julie Shah']",2015-03-03 23:25:55+00:00,2015-03-03 23:25:55+00:00,http://arxiv.org/pdf/1503.01161v1,stat.ML,"['stat.ML', 'cs.LG']"
"Comment on ""Clustering by fast search and find of density peaks""","In [1], a clustering algorithm was given to find the centers of clusters
quickly. However, the accuracy of this algorithm heavily depend on the
threshold value of d-c. Furthermore, [1] has not provided any efficient way to
select the threshold value of d-c, that is, one can have to estimate the value
of d_c depend on one's subjective experience. In this paper, based on the data
field [2], we propose a new way to automatically extract the threshold value of
d_c from the original data set by using the potential entropy of data field.
For any data set to be clustered, the most reasonable value of d_c can be
objectively calculated from the data set by using our proposed method. The same
experiments in [1] are redone with our proposed method on the same experimental
data set used in [1], the results of which shows that the problem to calculate
the threshold value of d_c in [1] has been solved by using our method.","['Shuliang Wang', 'Dakui Wang', 'Caoyuan Li', 'Yan Li']",2015-01-18 05:15:55+00:00,2015-01-20 03:41:28+00:00,http://arxiv.org/pdf/1501.04267v2,cs.LG,['cs.LG']
Text to Multi-level MindMaps: A Novel Method for Hierarchical Visual Abstraction of Natural Language Text,"MindMapping is a well-known technique used in note taking, which encourages
learning and studying. MindMapping has been manually adopted to help present
knowledge and concepts in a visual form. Unfortunately, there is no reliable
automated approach to generate MindMaps from Natural Language text. This work
firstly introduces MindMap Multilevel Visualization concept which is to jointly
visualize and summarize textual information. The visualization is achieved
pictorially across multiple levels using semantic information (i.e. ontology),
while the summarization is achieved by the information in the highest levels as
they represent abstract information in the text. This work also presents the
first automated approach that takes a text input and generates a MindMap
visualization out of it. The approach could visualize text documents in
multilevel MindMaps, in which a high-level MindMap node could be expanded into
child MindMaps. \ignore{ As far as we know, this is the first work that view
MindMapping as a new approach to jointly summarize and visualize textual
information.} The proposed method involves understanding of the input text and
converting it into intermediate Detailed Meaning Representation (DMR). The DMR
is then visualized with two modes; Single level or Multiple levels, which is
convenient for larger text. The generated MindMaps from both approaches were
evaluated based on Human Subject experiments performed on Amazon Mechanical
Turk with various parameter settings.","['Mohamed Elhoseiny', 'Ahmed Elgammal']",2014-08-01 03:18:56+00:00,2014-12-23 06:27:03+00:00,http://arxiv.org/pdf/1408.1031v2,cs.CL,"['cs.CL', 'cs.HC']"
Efficient Model Learning for Human-Robot Collaborative Tasks,"We present a framework for learning human user models from joint-action
demonstrations that enables the robot to compute a robust policy for a
collaborative task with a human. The learning takes place completely
automatically, without any human intervention. First, we describe the
clustering of demonstrated action sequences into different human types using an
unsupervised learning algorithm. These demonstrated sequences are also used by
the robot to learn a reward function that is representative for each type,
through the employment of an inverse reinforcement learning algorithm. The
learned model is then used as part of a Mixed Observability Markov Decision
Process formulation, wherein the human type is a partially observable variable.
With this framework, we can infer, either offline or online, the human type of
a new user that was not included in the training set, and can compute a policy
for the robot that will be aligned to the preference of this new user and will
be robust to deviations of the human actions from prior demonstrations. Finally
we validate the approach using data collected in human subject experiments, and
conduct proof-of-concept demonstrations in which a person performs a
collaborative task with a small industrial robot.","['Stefanos Nikolaidis', 'Keren Gu', 'Ramya Ramakrishnan', 'Julie Shah']",2014-05-24 20:44:26+00:00,2014-05-24 20:44:26+00:00,http://arxiv.org/pdf/1405.6341v1,cs.RO,"['cs.RO', 'cs.AI', 'cs.LG', 'cs.SY', 'I.2.6; I.2.8; I.2.9']"
What Is It Like to Be a Brain Simulation?,"We frame the question of what kind of subjective experience a brain
simulation would have in contrast to a biological brain. We discuss the brain
prosthesis thought experiment. We evaluate how the experience of the brain
simulation might differ from the biological, according to a number of
hypotheses about experience and the properties of simulation. Then, we identify
finer questions relating to the original inquiry, and answer them from both a
general physicalist, and panexperientialist perspective.",['Eray Özkural'],2014-02-01 17:19:53+00:00,2014-02-01 17:19:53+00:00,http://arxiv.org/pdf/1402.5379v1,cs.AI,"['cs.AI', '68T01']"
Stochastic Collapsed Variational Bayesian Inference for Latent Dirichlet Allocation,"In the internet era there has been an explosion in the amount of digital text
information available, leading to difficulties of scale for traditional
inference algorithms for topic models. Recent advances in stochastic
variational inference algorithms for latent Dirichlet allocation (LDA) have
made it feasible to learn topic models on large-scale corpora, but these
methods do not currently take full advantage of the collapsed representation of
the model. We propose a stochastic algorithm for collapsed variational Bayesian
inference for LDA, which is simpler and more efficient than the state of the
art method. We show connections between collapsed variational Bayesian
inference and MAP estimation for LDA, and leverage these connections to prove
convergence properties of the proposed algorithm. In experiments on large-scale
text corpora, the algorithm was found to converge faster and often to a better
solution than the previous method. Human-subject experiments also demonstrated
that the method can learn coherent topics in seconds on small corpora,
facilitating the use of topic models in interactive document analysis software.","['James Foulds', 'Levi Boyles', 'Christopher Dubois', 'Padhraic Smyth', 'Max Welling']",2013-05-10 23:06:47+00:00,2013-05-10 23:06:47+00:00,http://arxiv.org/pdf/1305.2452v1,cs.LG,['cs.LG']
Using qualia information to identify lexical semantic classes in an unsupervised clustering task,"Acquiring lexical information is a complex problem, typically approached by
relying on a number of contexts to contribute information for classification.
One of the first issues to address in this domain is the determination of such
contexts. The work presented here proposes the use of automatically obtained
FORMAL role descriptors as features used to draw nouns from the same lexical
semantic class together in an unsupervised clustering task. We have dealt with
three lexical semantic classes (HUMAN, LOCATION and EVENT) in English. The
results obtained show that it is possible to discriminate between elements from
different lexical semantic classes using only FORMAL role information, hence
validating our initial hypothesis. Also, iterating our method accurately
accounts for fine-grained distinctions within lexical classes, namely
distinctions involving ambiguous expressions. Moreover, a filtering and
bootstrapping strategy employed in extracting FORMAL role descriptors proved to
minimize effects of sparse data and noise in our task.","['Lauren Romeo', 'Sara Mendes', 'Núria Bel']",2013-03-11 08:21:48+00:00,2013-03-11 08:21:48+00:00,http://arxiv.org/pdf/1303.2449v1,cs.CL,['cs.CL']
Mining Determinism in Human Strategic Behavior,"This work lies in the fusion of experimental economics and data mining. It
continues author's previous work on mining behaviour rules of human subjects
from experimental data, where game-theoretic predictions partially fail to
work. Game-theoretic predictions aka equilibria only tend to success with
experienced subjects on specific games, what is rarely given. Apart from game
theory, contemporary experimental economics offers a number of alternative
models. In relevant literature, these models are always biased by psychological
and near-psychological theories and are claimed to be proven by the data. This
work introduces a data mining approach to the problem without using vast
psychological background. Apart from determinism, no other biases are regarded.
Two datasets from different human subject experiments are taken for evaluation.
The first one is a repeated mixed strategy zero sum game and the second -
repeated ultimatum game. As result, the way of mining deterministic
regularities in human strategic behaviour is described and evaluated. As future
work, the design of a new representation formalism is discussed.",['Rustam Tagiew'],2012-11-11 11:27:01+00:00,2012-11-11 11:27:01+00:00,http://arxiv.org/pdf/1211.2399v1,cs.GT,"['cs.GT', 'cs.AI']"
Intrinsic adaptation in autonomous recurrent neural networks,"A massively recurrent neural network responds on one side to input stimuli
and is autonomously active, on the other side, in the absence of sensory
inputs. Stimuli and information processing depends crucially on the qualia of
the autonomous-state dynamics of the ongoing neural activity. This default
neural activity may be dynamically structured in time and space, showing
regular, synchronized, bursting or chaotic activity patterns.
  We study the influence of non-synaptic plasticity on the default dynamical
state of recurrent neural networks. The non-synaptic adaption considered acts
on intrinsic neural parameters, such as the threshold and the gain, and is
driven by the optimization of the information entropy. We observe, in the
presence of the intrinsic adaptation processes, three distinct and globally
attracting dynamical regimes, a regular synchronized, an overall chaotic and an
intermittent bursting regime. The intermittent bursting regime is characterized
by intervals of regular flows, which are quite insensitive to external stimuli,
interseeded by chaotic bursts which respond sensitively to input signals. We
discuss these finding in the context of self-organized information processing
and critical brain dynamics.","['Dimitrije Markovic', 'Claudius Gros']",2011-10-14 09:42:06+00:00,2011-10-14 09:42:06+00:00,http://arxiv.org/pdf/1110.3161v1,cond-mat.dis-nn,"['cond-mat.dis-nn', 'nlin.AO', 'nlin.CD', 'q-bio.NC']"
Conscious Machines and Consciousness Oriented Programming,"In this paper, we investigate the following question: how could you write
such computer programs that can work like conscious beings? The motivation
behind this question is that we want to create such applications that can see
the future. The aim of this paper is to provide an overall conceptual framework
for this new approach to machine consciousness. So we introduce a new
programming paradigm called Consciousness Oriented Programming (COP).",['Norbert Bátfai'],2011-08-14 12:27:39+00:00,2011-08-14 12:27:39+00:00,http://arxiv.org/pdf/1108.2865v1,cs.AI,"['cs.AI', '68T35', 'I.2.5; F.1.1']"
Not only a lack of right definitions: Arguments for a shift in information-processing paradigm,"Machine Consciousness and Machine Intelligence are not simply new buzzwords
that occupy our imagination. Over the last decades, we witness an unprecedented
rise in attempts to create machines with human-like features and capabilities.
However, despite widespread sympathy and abundant funding, progress in these
enterprises is far from being satisfactory. The reasons for this are twofold:
First, the notions of cognition and intelligence (usually borrowed from human
behavior studies) are notoriously blurred and ill-defined, and second, the
basic concepts underpinning the whole discourse are by themselves either
undefined or defined very vaguely. That leads to improper and inadequate
research goals determination, which I will illustrate with some examples drawn
from recent documents issued by DARPA and the European Commission. On the other
hand, I would like to propose some remedies that, I hope, would improve the
current state-of-the-art disgrace.",['Emanuel Diamant'],2010-09-01 02:37:54+00:00,2010-09-01 02:37:54+00:00,http://arxiv.org/pdf/1009.0077v1,cs.AI,"['cs.AI', 'q-bio.NC']"
Efficient statistical analysis of large correlated multivariate datasets: a case study on brain connectivity matrices,"In neuroimaging, a large number of correlated tests are routinely performed
to detect active voxels in single-subject experiments or to detect regions that
differ between individuals belonging to different groups. In order to bound the
probability of a false discovery of pair-wise differences, a Bonferroni or
other correction for multiplicity is necessary. These corrections greatly
reduce the power of the comparisons which means that small signals
(differences) remain hidden and therefore have been more or less successful
depending on the application. We introduce a method that improves the power of
a family of correlated statistical tests by reducing their number in an orderly
fashion using our a-priori understanding of the problem . The tests are grouped
by blocks that respect the data structure and only one or a few tests per group
are performed. For each block we construct an appropriate summary statistic
that characterizes a meaningful feature of the block. The comparisons are based
on these summary statistics by a block-wise approach. We contrast this method
with the one based on the individual measures in terms of power. Finally, we
apply the method to compare brain connectivity matrices. Although the method is
used in this study on the particular case of imaging, the proposed strategy can
be applied to a large variety of problems that involves multiple comparisons
when the tests can be grouped according to attributes that depend on the
specific problem. Keywords and phrases: Multiple comparisons ; Family-wise
error rate; False discovery rate; Bonferroni procedure; Human brain
connectivity; Brain connectivity matrices.","['Djalel Eddine Meskaldji', 'Leila Cammoun', 'Patric Hagmann', 'Reto Meuli', 'Jean Philippe Thiran', 'Stephan Morgenthaler']",2010-08-11 14:01:13+00:00,2010-08-11 14:01:13+00:00,http://arxiv.org/pdf/1008.1909v1,stat.ME,"['stat.ME', 'math.ST', 'q-bio.NC', 'stat.TH']"
Logical Evaluation of Consciousness: For Incorporating Consciousness into Machine Architecture,"Machine Consciousness is the study of consciousness in a biological,
philosophical, mathematical and physical perspective and designing a model that
can fit into a programmable system architecture. Prime objective of the study
is to make the system architecture behave consciously like a biological model
does. Present work has developed a feasible definition of consciousness, that
characterizes consciousness with four parameters i.e., parasitic, symbiotic,
self referral and reproduction. Present work has also developed a biologically
inspired consciousness architecture that has following layers: quantum layer,
cellular layer, organ layer and behavioral layer and traced the characteristics
of consciousness at each layer. Finally, the work has estimated physical and
algorithmic architecture to devise a system that can behave consciously.","['C. N. Padhy', 'R. R. Panda']",2010-02-01 04:07:34+00:00,2010-02-01 04:07:34+00:00,http://arxiv.org/pdf/1002.0177v1,cs.AI,['cs.AI']
Quantum formalism to describe binocular rivalry,"On the basis of the general character and operation of the process of
perception, a formalism is sought to mathematically describe the subjective or
abstract/mental process of perception. It is shown that the formalism of
orthodox quantum theory of measurement, where the observer plays a key role, is
a broader mathematical foundation which can be adopted to describe the dynamics
of the subjective experience. The mathematical formalism describes the
psychophysical dynamics of the subjective or cognitive experience as
communicated to us by the subject. Subsequently, the formalism is used to
describe simple perception processes and, in particular, to describe the
probability distribution of dominance duration obtained from the testimony of
subjects experiencing binocular rivalry. Using this theory and parameters based
on known values of neuronal oscillation frequencies and firing rates, the
calculated probability distribution of dominance duration of rival states in
binocular rivalry under various conditions is found to be in good agreement
with available experimental data. This theory naturally explains an observed
marked increase in dominance duration in binocular rivalry upon periodic
interruption of stimulus and yields testable predictions for the distribution
of perceptual alteration in time.",['Efstratios Manousakis'],2007-09-28 02:17:02+00:00,2009-10-13 19:09:22+00:00,http://arxiv.org/pdf/0709.4516v2,q-bio.NC,['q-bio.NC']
Biological nonlocality and the mind-brain interaction problem: comments on a new empirical approach,"Up to now, we have been faced with an age old fundamental dilemma posed by
the mind-brain interaction problem, i.e. how is it that the mind which is
subjective and immaterial, can interact with the brain which is objective and
material? Analysis of recent experiments appears to indicate that quantum
mechanics may have a role to play in the resolution of the mind-brain
interaction problem in the form of biological entanglement and nonlocality.
This analysis, when coupled with ongoing and proposed experiments, may help us
to simultaneously resolve related issues such as whether mental events can
initiate neural events, the transference of conscious subjective experience,
the measurement problem and the binding problem.",['Fred Thaheld'],2005-10-19 13:30:25+00:00,2005-10-19 13:30:25+00:00,http://arxiv.org/pdf/q-bio/0510039v1,q-bio.NC,"['q-bio.NC', 'quant-ph']"
The Physics of 'Now',"The world is four-dimensional according to fundamental physics, governed by
basic laws that operate in a spacetime that has no unique division into space
and time. Yet our subjective experience is divided into present, past, and
future. This paper discusses the origin of this division in terms of simple
models of information gathering and utilizing systems (IGUSes). Past, present,
and future are not properties of four-dimensional spacetime but notions
describing how individual IGUSes process information. Their origin is to be
found in how these IGUSes evolved or were constructed. The past, present, and
future of an IGUS is consistent with the four-dimensional laws of physics and
can be described in four-dimensional terms. The present, for instance, is not a
moment of time in the sense of a spacelike surface in spacetime. Rather there
is a localized notion of present at each point along an IGUS' world line. The
common present of many localized IGUSes is an approximate notion appropriate
when they are sufficiently close to each other and have relative velocities
much less than that of light. But modes of organization that are different from
present, past and future can be imagined that are consistent with the physical
laws. We speculate why the present, past, and future organization might be
favored by evolution and therefore a cognitive universal.",['James B. Hartle'],2004-02-27 21:59:47+00:00,2004-05-21 22:45:51+00:00,http://arxiv.org/pdf/gr-qc/0403001v2,gr-qc,"['gr-qc', 'physics.pop-ph', 'q-bio.NC']"
Processing Metonymy: a Domain-Model Heuristic Graph Traversal Approach,"We address here the treatment of metonymic expressions from a knowledge
representation perspective, that is, in the context of a text understanding
system which aims to build a conceptual representation from texts according to
a domain model expressed in a knowledge representation formalism.
  We focus in this paper on the part of the semantic analyser which deals with
semantic composition. We explain how we use the domain model to handle metonymy
dynamically, and more generally, to underlie semantic composition, using the
knowledge descriptions attached to each concept of our ontology as a kind of
concept-level, multiple-role qualia structure.
  We rely for this on a heuristic path search algorithm that exploits the
graphic aspects of the conceptual graphs formalism. The methods described have
been implemented and applied on French texts in the medical domain.","['Jacques Bouaud', 'Bruno Bachimont', 'Pierre Zweigenbaum']",1996-04-26 15:11:15+00:00,1996-04-26 15:11:15+00:00,http://arxiv.org/pdf/cmp-lg/9604016v1,cmp-lg,"['cmp-lg', 'cs.CL']"
Bi-Lexical Rules for Multi-Lexeme Translation in Lexicalist MT,"The paper presents a prototype lexicalist Machine Translation system (based
on the so-called `Shake-and-Bake' approach of Whitelock (1992) consisting of an
analysis component, a dynamic bilingual lexicon, and a generation component,
and shows how it is applied to a range of MT problems. Multi-Lexeme
translations are handled through bi-lexical rules which map bilingual lexical
signs into new bilingual lexical signs. It is argued that much translation can
be handled by equating translationally equivalent lists of lexical signs,
either directly in the bilingual lexicon, or by deriving them through
bi-lexical rules. Lexical semantic information organized as Qualia structures
(Pustejovsky 1991) is used as a mechanism for restricting the domain of the
rules.",['Arturo Trujillo'],1995-08-12 13:42:24+00:00,1995-08-12 13:42:24+00:00,http://arxiv.org/pdf/cmp-lg/9508006v1,cmp-lg,"['cmp-lg', 'cs.CL']"
A Compositional Treatment of Polysemous Arguments in Categorial Grammar,"We discuss an extension of the standard logical rules (functional application
and abstraction) in Categorial Grammar (CG), in order to deal with some
specific cases of polysemy. We borrow from Generative Lexicon theory which
proposes the mechanism of {\em coercion}, next to a rich nominal lexical
semantic structure called {\em qualia structure}.
  In a previous paper we introduced coercion into the framework of {\em
sign-based} Categorial Grammar and investigated its impact on traditional
Fregean compositionality. In this paper we will elaborate on this idea, mostly
working towards the introduction of a new semantic dimension. Where in current
versions of sign-based Categorial Grammar only two representations are derived:
a prosodic one (form) and a logical one (modelling), here we introduce also a
more detaled representation of the lexical semantics. This extra knowledge will
serve to account for linguistic phenomena like {\em metonymy\/}.","['Anne-Marie Mineur', 'Paul Buitelaar']",1995-08-02 15:09:04+00:00,1995-09-10 16:33:42+00:00,http://arxiv.org/pdf/cmp-lg/9508002v2,cmp-lg,"['cmp-lg', 'cs.CL']"
