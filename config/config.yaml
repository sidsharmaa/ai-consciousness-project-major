# Configuration for the data processing pipeline
data_source:
  kaggle_dataset: "Cornell-University/arxiv"

processing:
  keywords:
    - "consciousness"
    - "sentience"
    - "awareness"
    - "self-awareness"
    - "mind"
    - "experience"

# Paths for the Kaggle pipeline
paths:
  download_dir: "data/01_raw/kaggle_arxiv" 
  output_path: "data/02_intermediate/filtered_papers.csv"

# Configuration for processing the local JSON snapshot
local_json_processing:
  input_path: "data/01_raw/arxiv-metadata-oai-snapshot.json"
  output_path: "data/02_intermediate/filtered_arxiv_metadata.parquet"
  
  filter_keywords:
    - "consciousness"
    - "sentience"
    - "self-awareness"
    - "subjective experience"
    - "qualia"
      
  target_categories:
    - "cs.AI"
    - "phil.CO"
    - "q-bio.NC"
    - "cs.LG"
    - "cs.CL"

  max_title_len: 300
  max_abstract_len: 1000

# Configuration for the vector store creation pipeline
embedding_pipeline:
  # Paths to specific source text files
  transcript_sources:
    - "data/01_raw/anirban_bandopadhyay.txt"
    - "data/01_raw/bernardo_kastrup.txt"
    - "data/01_raw/david_chalmers.txt"
    - "data/01_raw/sir_roger_penrose.txt"
    - "data/01_raw/stuart_hameroff.txt"
  
  # Path to the processed parquet file
  parquet_source: "data/02_intermediate/filtered_arxiv_metadata.parquet"
  
  # Path to save the final FAISS index
  faiss_index_path: "data/06_models/faiss_index"

  # Model and text splitting parameters
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  text_splitter:
    chunk_size: 500
    chunk_overlap: 50

# Configuration for the RAG chatbot application
rag_application:
  # Use paths from our standardized project structure
  faiss_index_path: "data/06_models/faiss_index"
  log_path: "chatbot.log" # Log file will be in the project root

  # Models
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  llm:
    model_name: "mistral"
    base_url: "http://localhost:11434"

  # RAG Chain parameters
  prompt_template: >
    Use the following pieces of context to answer the user's question.
    If you don't know the answer, or if the question is not related to 
    AI consciousness or consciousness, just say that you don't know or 
    that the question is outside the scope of this knowledge base.
    Do not try to make up an answer.

    Context:
    {context}

    Question: {question}

    Answer:
  
  # User preference mapping
  answer_length_map:
    short: 100
    medium: 250
    long: 500